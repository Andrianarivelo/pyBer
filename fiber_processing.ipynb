{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-17T13:27:17.311893Z",
     "start_time": "2025-12-17T13:27:16.157240Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "try:\n",
    "    from sklearn.linear_model import Lasso\n",
    "except Exception:\n",
    "    Lasso = None\n",
    "from pybaselines import Baseline\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 4)\n",
    "plt.rcParams[\"axes.grid\"] = True\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T13:27:18.777369Z",
     "start_time": "2025-12-17T13:27:18.765372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def list_doric_channels(path):\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        base = f[\"DataAcquisition\"][\"FPConsole\"][\"Signals\"][\"Series0001\"]\n",
    "        chans = []\n",
    "        if \"LockInAOUT02\" in base:\n",
    "            for k in base[\"LockInAOUT02\"].keys():\n",
    "                if k.startswith(\"AIN\"):\n",
    "                    chans.append(k)\n",
    "        chans = sorted(chans)\n",
    "\n",
    "        digital = []\n",
    "        if \"DigitalIO\" in base:\n",
    "            for k in base[\"DigitalIO\"].keys():\n",
    "                if k.startswith(\"DIO\"):\n",
    "                    digital.append(k)\n",
    "        return chans, digital\n",
    "\n",
    "def load_doric(path, channel=\"AIN01\", signal_folder=\"LockInAOUT02\", ref_folder=\"LockInAOUT01\",\n",
    "              trigger_name=None):\n",
    "    \"\"\"\n",
    "    Returns dict with:\n",
    "      time, sig465, ref405, fs, (optional) trig_time, trig\n",
    "    \"\"\"\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        base = f[\"DataAcquisition\"][\"FPConsole\"][\"Signals\"][\"Series0001\"]\n",
    "\n",
    "        sig = np.asarray(base[signal_folder][channel][()], float)\n",
    "        ref = np.asarray(base[ref_folder][channel][()], float)\n",
    "\n",
    "        # time: prefer the matching folder time if size matches\n",
    "        t_sig = np.asarray(base[signal_folder][\"Time\"][()], float) if \"Time\" in base[signal_folder] else np.array([])\n",
    "        t_ref = np.asarray(base[ref_folder][\"Time\"][()], float) if \"Time\" in base[ref_folder] else np.array([])\n",
    "\n",
    "        if t_sig.size == sig.size:\n",
    "            t = t_sig\n",
    "        elif t_ref.size == sig.size:\n",
    "            t = t_ref\n",
    "        else:\n",
    "            # fallback\n",
    "            dt = np.nanmedian(np.diff(t_sig)) if t_sig.size > 2 else 1/1000\n",
    "            t = np.arange(sig.size) * dt\n",
    "\n",
    "        # if ref length differs, interpolate onto t if possible\n",
    "        if ref.size != sig.size:\n",
    "            if t_ref.size == ref.size:\n",
    "                ref = np.interp(t, t_ref, ref)\n",
    "            else:\n",
    "                ref = np.resize(ref, sig.size)\n",
    "\n",
    "        # sampling rate\n",
    "        fs = 1.0 / float(np.nanmedian(np.diff(t))) if t.size > 2 else np.nan\n",
    "\n",
    "        # optional digital trigger overlay\n",
    "        trig_time = None\n",
    "        trig = None\n",
    "        if trigger_name:\n",
    "            if \"DigitalIO\" in base and trigger_name in base[\"DigitalIO\"]:\n",
    "                dio = base[\"DigitalIO\"]\n",
    "                trig = np.asarray(dio[trigger_name][()], float)\n",
    "                trig_time = np.asarray(dio[\"Time\"][()], float) if \"Time\" in dio else None\n",
    "\n",
    "                # if lengths mismatch, interpolate signals to trigger time (like your Doric logic)\n",
    "                if trig_time is not None and trig_time.size and trig_time.size != t.size:\n",
    "                    sig = np.interp(trig_time, t, sig)\n",
    "                    ref = np.interp(trig_time, t, ref)\n",
    "                    t = trig_time\n",
    "                    fs = 1.0 / float(np.nanmedian(np.diff(t))) if t.size > 2 else fs\n",
    "\n",
    "    out = {\"time\": t, \"sig465\": sig, \"ref405\": ref, \"fs\": fs}\n",
    "    if trig is not None and trig_time is not None:\n",
    "        out[\"trig_time\"] = trig_time\n",
    "        out[\"trig\"] = trig\n",
    "    return out\n",
    "import numpy as np\n",
    "\n",
    "def ols_fit(x, y):\n",
    "    x = np.asarray(x, float)\n",
    "    y = np.asarray(y, float)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    if np.sum(m) < 10:\n",
    "        return 1.0, 0.0\n",
    "    X = np.vstack([x[m], np.ones(np.sum(m))]).T\n",
    "    coef, *_ = np.linalg.lstsq(X, y[m], rcond=None)\n",
    "    return float(coef[0]), float(coef[1])\n",
    "\n",
    "\n",
    "\n",
    "def compute_arpls_baselines(\n",
    "    baseline_fitter,\n",
    "    sig_f,\n",
    "    ref_f,\n",
    "    lam=1e9,\n",
    "    diff_order=2,\n",
    "    max_iter=50,\n",
    "    tol=1e-3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute arPLS baselines for signal and reference.\n",
    "\n",
    "    Parameters:\n",
    "        baseline_fitter: pybaselines.Baseline instance, already set up with x_data.\n",
    "        sig_f: 1D array-like, preprocessed signal channel.\n",
    "        ref_f: 1D array-like, preprocessed reference channel.\n",
    "        lam: smoothing parameter.\n",
    "        diff_order: difference order for the penalty.\n",
    "        max_iter: maximum iterations for arPLS.\n",
    "        tol: convergence tolerance.\n",
    "\n",
    "    Returns:\n",
    "        b_sig_arpls, b_ref_arpls\n",
    "    \"\"\"\n",
    "    b_sig_arpls, _ = baseline_fitter.arpls(\n",
    "        sig_f, lam=lam, diff_order=diff_order,\n",
    "        max_iter=max_iter, tol=tol\n",
    "    )\n",
    "    b_ref_arpls, _ = baseline_fitter.arpls(\n",
    "        ref_f, lam=lam, diff_order=diff_order,\n",
    "        max_iter=max_iter, tol=tol\n",
    "    )\n",
    "    return b_sig_arpls, b_ref_arpls\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_motion_corrected_dff(sig_f, ref_f, b_sig, b_ref):\n",
    "    \"\"\"\n",
    "    Computes motion-corrected dF/F using the 'Standardized' method:\n",
    "    1) Calculate dF/F for both signal and reference channels separately.\n",
    "       dff_sig_raw = (sig - b_sig) / b_sig\n",
    "       dff_ref_raw = (ref - b_ref) / b_ref\n",
    "    2) Fit dff_ref_raw to dff_sig_raw using OLS (y = ax + b).\n",
    "    3) Subtract the fitted reference from the signal dF/F.\n",
    "       dff_mc = dff_sig_raw - (a * dff_ref_raw + b)\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1. Calculate raw dF/F for each channel ---\n",
    "    # Prepare denominators (avoid division by zero)\n",
    "    den_sig = np.asarray(b_sig, float).copy()\n",
    "    den_sig[np.abs(den_sig) < 1e-12] = np.nan\n",
    "\n",
    "    den_ref = np.asarray(b_ref, float).copy()\n",
    "    den_ref[np.abs(den_ref) < 1e-12] = np.nan\n",
    "\n",
    "    # Calculate standard dF/F (percent change) for each\n",
    "    dff_sig_raw = (sig_f - b_sig) / den_sig\n",
    "    dff_ref_raw = (ref_f - b_ref) / den_ref\n",
    "\n",
    "    # --- 2. Fit Reference dF/F to Signal dF/F ---\n",
    "    # We fit: dff_sig_raw ~ a * dff_ref_raw + b\n",
    "    a, b = ols_fit(dff_ref_raw, dff_sig_raw)\n",
    "\n",
    "    # --- 3. Subtract to get Motion-Corrected dF/F ---\n",
    "    # The fitted reference represents the motion/artifact component in dF/F space\n",
    "    fitted_ref = (a * dff_ref_raw + b)\n",
    "    dff_mc = dff_sig_raw - fitted_ref\n",
    "\n",
    "    # Return dictionary with keys compatible with your analysis pipeline\n",
    "    # Note: 'sig_det' and 'ref_det' now refer to the raw dF/F traces\n",
    "    return {\n",
    "        \"sig_det\": dff_sig_raw,   # Now holds raw dF/F of signal\n",
    "        \"ref_det\": dff_ref_raw,   # Now holds raw dF/F of reference\n",
    "        \"a\": a,                   # Slope of the regression in dF/F space\n",
    "        \"b\": b,                   # Intercept of the regression\n",
    "        \"delta_mc\": dff_mc,       # The final motion-corrected dF/F\n",
    "        \"dff\": dff_mc,            # Same as delta_mc (kept for compatibility)\n",
    "    }\n",
    "\n"
   ],
   "id": "16606b8d9a8214c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T13:27:23.987419Z",
     "start_time": "2025-12-17T13:27:23.971961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = r\"C:\\Analysis\\fiber_photometry_app\\test_data\\30545-lick_0002.doric\"\n",
    "\n",
    "channels, dio = list_doric_channels(path)\n",
    "channels, dio"
   ],
   "id": "1831a43717d24a59",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['AIN01'], ['DIO01', 'DIO02'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f2eacc3b29f3440e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
