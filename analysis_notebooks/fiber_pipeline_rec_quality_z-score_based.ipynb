{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-07T17:08:51.111905Z",
     "start_time": "2026-01-07T17:08:51.107049Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "try:\n",
    "    from sklearn.linear_model import Lasso\n",
    "except Exception:\n",
    "    Lasso = None\n",
    "from pybaselines import Baseline\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 4)\n",
    "plt.rcParams[\"axes.grid\"] = True\n"
   ],
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T17:08:51.124633Z",
     "start_time": "2026-01-07T17:08:51.116039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def list_doric_channels(path):\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        base = f[\"DataAcquisition\"][\"FPConsole\"][\"Signals\"][\"Series0001\"]\n",
    "        chans = []\n",
    "        if \"LockInAOUT02\" in base:\n",
    "            for k in base[\"LockInAOUT02\"].keys():\n",
    "                if k.startswith(\"AIN\"):\n",
    "                    chans.append(k)\n",
    "        chans = sorted(chans)\n",
    "\n",
    "        digital = []\n",
    "        if \"DigitalIO\" in base:\n",
    "            for k in base[\"DigitalIO\"].keys():\n",
    "                if k.startswith(\"DIO\"):\n",
    "                    digital.append(k)\n",
    "        return chans, digital\n",
    "def list_doric_files(folder_path):\n",
    "    \"\"\"\n",
    "    Return a list of full paths to all .doric files in the given folder.\n",
    "    \"\"\"\n",
    "    doric_files = []\n",
    "    for fname in os.listdir(folder_path):\n",
    "        if fname.lower().endswith(\".doric\"):\n",
    "            doric_files.append(os.path.join(folder_path, fname))\n",
    "    return doric_files\n",
    "\n",
    "def load_doric(path, channel=\"AIN01\", signal_folder=\"LockInAOUT02\", ref_folder=\"LockInAOUT01\",\n",
    "              trigger_name=None):\n",
    "    \"\"\"\n",
    "    Returns dict with:\n",
    "      time, sig465, ref405, fs, (optional) trig_time, trig\n",
    "    \"\"\"\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        base = f[\"DataAcquisition\"][\"FPConsole\"][\"Signals\"][\"Series0001\"]\n",
    "\n",
    "        sig = np.asarray(base[signal_folder][channel][()], float)\n",
    "        ref = np.asarray(base[ref_folder][channel][()], float)\n",
    "\n",
    "        # time: prefer the matching folder time if size matches\n",
    "        t_sig = np.asarray(base[signal_folder][\"Time\"][()], float) if \"Time\" in base[signal_folder] else np.array([])\n",
    "        t_ref = np.asarray(base[ref_folder][\"Time\"][()], float) if \"Time\" in base[ref_folder] else np.array([])\n",
    "\n",
    "        if t_sig.size == sig.size:\n",
    "            t = t_sig\n",
    "        elif t_ref.size == sig.size:\n",
    "            t = t_ref\n",
    "        else:\n",
    "            # fallback\n",
    "            dt = np.nanmedian(np.diff(t_sig)) if t_sig.size > 2 else 1/1000\n",
    "            t = np.arange(sig.size) * dt\n",
    "\n",
    "        # if ref length differs, interpolate onto t if possible\n",
    "        if ref.size != sig.size:\n",
    "            if t_ref.size == ref.size:\n",
    "                ref = np.interp(t, t_ref, ref)\n",
    "            else:\n",
    "                ref = np.resize(ref, sig.size)\n",
    "\n",
    "        # sampling rate\n",
    "        fs = 1.0 / float(np.nanmedian(np.diff(t))) if t.size > 2 else np.nan\n",
    "\n",
    "        # optional digital trigger overlay\n",
    "        trig_time = None\n",
    "        trig = None\n",
    "        if trigger_name:\n",
    "            if \"DigitalIO\" in base and trigger_name in base[\"DigitalIO\"]:\n",
    "                dio = base[\"DigitalIO\"]\n",
    "                trig = np.asarray(dio[trigger_name][()], float)\n",
    "                trig_time = np.asarray(dio[\"Time\"][()], float) if \"Time\" in dio else None\n",
    "\n",
    "                # if lengths mismatch, interpolate signals to trigger time (like your Doric logic)\n",
    "                if trig_time is not None and trig_time.size and trig_time.size != t.size:\n",
    "                    sig = np.interp(trig_time, t, sig)\n",
    "                    ref = np.interp(trig_time, t, ref)\n",
    "                    t = trig_time\n",
    "                    fs = 1.0 / float(np.nanmedian(np.diff(t))) if t.size > 2 else fs\n",
    "\n",
    "    out = {\"time\": t, \"sig465\": sig, \"ref405\": ref, \"fs\": fs}\n",
    "    if trig is not None and trig_time is not None:\n",
    "        out[\"trig_time\"] = trig_time\n",
    "        out[\"trig\"] = trig\n",
    "    return out\n"
   ],
   "id": "b5ec1e01d83bb5f0",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T17:08:51.138784Z",
     "start_time": "2026-01-07T17:08:51.128634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "# =========================\n",
    "# Cell 2 — Helpers + Robust Fit\n",
    "# =========================\n",
    "def _as_float_1d(a):\n",
    "    return np.asarray(a, dtype=float).ravel()\n",
    "\n",
    "def mad_sigma(r):\n",
    "    med = np.median(r)\n",
    "    return 1.4826 * np.median(np.abs(r - med)) + 1e-12\n",
    "\n",
    "def huber_irls(x, y, delta=1.5, max_iter=50, tol=1e-10):\n",
    "    \"\"\"\n",
    "    Robust linear fit y ~ a*x + b using Huber IRLS.\n",
    "    Returns (a, b, sigma_robust).\n",
    "    \"\"\"\n",
    "    x = _as_float_1d(x)\n",
    "    y = _as_float_1d(y)\n",
    "    X = np.column_stack([x, np.ones_like(x)])\n",
    "    beta = np.linalg.lstsq(X, y, rcond=None)[0]  # initial OLS\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        r = y - X @ beta\n",
    "        s = mad_sigma(r)\n",
    "        u = r / (s * delta)\n",
    "\n",
    "        w = np.ones_like(u)\n",
    "        mask = np.abs(u) > 1\n",
    "        w[mask] = 1.0 / (np.abs(u[mask]) + 1e-12)\n",
    "\n",
    "        Xw = X * w[:, None]\n",
    "        yw = y * w\n",
    "        beta_new = np.linalg.lstsq(Xw, yw, rcond=None)[0]\n",
    "\n",
    "        if np.max(np.abs(beta_new - beta)) < tol:\n",
    "            beta = beta_new\n",
    "            break\n",
    "        beta = beta_new\n",
    "\n",
    "    r = y - X @ beta\n",
    "    s = mad_sigma(r)\n",
    "    return float(beta[0]), float(beta[1]), float(s)\n",
    "\n",
    "def rolling_corr(x, y, win):\n",
    "    \"\"\"\n",
    "    Rolling Pearson correlation in non-overlapping windows of size win.\n",
    "    Returns corr array and window centers (indices).\n",
    "    \"\"\"\n",
    "    n = min(len(x), len(y))\n",
    "    nwin = n // win\n",
    "    if nwin < 2:\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    x2 = x[:nwin * win].reshape(nwin, win)\n",
    "    y2 = y[:nwin * win].reshape(nwin, win)\n",
    "\n",
    "    xmu = x2.mean(axis=1, keepdims=True)\n",
    "    ymu = y2.mean(axis=1, keepdims=True)\n",
    "    xv = x2 - xmu\n",
    "    yv = y2 - ymu\n",
    "    num = np.sum(xv * yv, axis=1)\n",
    "    den = np.sqrt(np.sum(xv * xv, axis=1) * np.sum(yv * yv, axis=1)) + 1e-12\n",
    "    c = num / den\n",
    "\n",
    "    centers = (np.arange(nwin) * win + win / 2.0)\n",
    "    return c, centers\n",
    "\n",
    "def clipping_fraction(a, lo_q=0.001, hi_q=0.999):\n",
    "    \"\"\"\n",
    "    Heuristic clipping: fraction of samples extremely close to extreme quantiles.\n",
    "    Works even if you don't know ADC min/max.\n",
    "    \"\"\"\n",
    "    a = _as_float_1d(a)\n",
    "    a = a[np.isfinite(a)]\n",
    "    if a.size < 10:\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "    lo = np.quantile(a, lo_q)\n",
    "    hi = np.quantile(a, hi_q)\n",
    "    span = (hi - lo) + 1e-12\n",
    "    eps = 0.001 * span\n",
    "    frac_lo = np.mean(a <= (lo + eps))\n",
    "    frac_hi = np.mean(a >= (hi - eps))\n",
    "    return float(frac_lo + frac_hi), float(lo), float(hi)\n",
    "\n",
    "def flatline_fraction(a, tol=1e-12):\n",
    "    \"\"\"\n",
    "    Fraction of successive differences that are ~0 (flatlining / stuck values).\n",
    "    \"\"\"\n",
    "    a = _as_float_1d(a)\n",
    "    a = a[np.isfinite(a)]\n",
    "    if a.size < 3:\n",
    "        return np.nan\n",
    "    d = np.diff(a)\n",
    "    return float(np.mean(np.abs(d) < tol))\n"
   ],
   "id": "3b9868b583a7c044",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T17:08:51.153857Z",
     "start_time": "2026-01-07T17:08:51.141810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Cell 3 — Artifact Detection + Removal (Adaptive MAD)\n",
    "# =========================\n",
    "def adaptive_mad_artifact_mask(\n",
    "    y: np.ndarray,\n",
    "    fs: float,\n",
    "    *,\n",
    "    k: float = 6.0,\n",
    "    window_s: float = 1.0,\n",
    "    pad_s: float = 0.2,\n",
    "    use_derivative: bool = True,\n",
    "    min_mad: float = 1e-12,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build an artifact mask using Adaptive MAD (windowed).\n",
    "\n",
    "    Detection is performed on dx=diff(y) if use_derivative=True, else directly on y.\n",
    "    Within each non-overlapping window, compute median and MAD, then flag samples where:\n",
    "        |x - median| > k * MAD\n",
    "\n",
    "    Mask is returned at signal sample resolution (len(y)).\n",
    "    \"\"\"\n",
    "    y = np.asarray(y, float)\n",
    "    n = y.size\n",
    "    if n == 0:\n",
    "        return np.zeros((0,), dtype=bool)\n",
    "\n",
    "    if not np.isfinite(fs) or fs <= 0:\n",
    "        raise ValueError(f\"adaptive_mad_artifact_mask: invalid fs={fs}\")\n",
    "\n",
    "    x = np.diff(y) if use_derivative else y.copy()\n",
    "    nx = x.size\n",
    "    if nx == 0:\n",
    "        return np.zeros((n,), dtype=bool)\n",
    "\n",
    "    win = int(round(window_s * fs))\n",
    "    win = max(5, win)\n",
    "\n",
    "    flagged_x = np.zeros((nx,), dtype=bool)\n",
    "\n",
    "    for start in range(0, nx, win):\n",
    "        stop = min(start + win, nx)\n",
    "        seg = x[start:stop]\n",
    "\n",
    "        seg_f = seg[np.isfinite(seg)]\n",
    "        if seg_f.size < 5:\n",
    "            continue\n",
    "\n",
    "        med = np.median(seg_f)\n",
    "        mad = np.median(np.abs(seg_f - med))\n",
    "        mad = max(float(mad), float(min_mad))\n",
    "\n",
    "        flagged_x[start:stop] = np.abs(seg - med) > (k * mad)\n",
    "\n",
    "    mask = np.zeros((n,), dtype=bool)\n",
    "    if use_derivative:\n",
    "        hit = np.where(flagged_x)[0]\n",
    "        mask[hit] = True\n",
    "        mask[hit + 1] = True\n",
    "    else:\n",
    "        mask[:nx] = flagged_x\n",
    "\n",
    "    pad_n = int(round(pad_s * fs))\n",
    "    if pad_n > 0 and np.any(mask):\n",
    "        kernel = np.ones((2 * pad_n + 1,), dtype=int)\n",
    "        mask = (np.convolve(mask.astype(int), kernel, mode=\"same\") > 0)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def _nan_interp_1d(y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Linearly interpolate NaNs in a 1D array.\n",
    "    Edge NaNs are filled with nearest valid value.\n",
    "    \"\"\"\n",
    "    y = np.asarray(y, float).copy()\n",
    "    n = y.size\n",
    "    if n == 0:\n",
    "        return y\n",
    "\n",
    "    isnan = ~np.isfinite(y)\n",
    "    if not np.any(isnan):\n",
    "        return y\n",
    "\n",
    "    x = np.arange(n)\n",
    "    good = np.isfinite(y)\n",
    "    if np.sum(good) == 0:\n",
    "        return y\n",
    "\n",
    "    y[isnan] = np.interp(x[isnan], x[good], y[good])\n",
    "    return y\n",
    "\n",
    "def remove_artifacts_adaptive_mad(\n",
    "    time: np.ndarray,\n",
    "    sig465: np.ndarray,\n",
    "    ref405: np.ndarray,\n",
    "    fs: float = None,\n",
    "    *,\n",
    "    k: float = 6.0,\n",
    "    window_s: float = 1.0,\n",
    "    pad_s: float = 0.2,\n",
    "    union_channels: bool = True,\n",
    "    use_derivative: bool = True,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Detect + remove artifacts using adaptive MAD (windowed) with padding.\n",
    "\n",
    "    By default, artifacts are detected on BOTH channels and unioned (recommended),\n",
    "    then removed from BOTH channels consistently.\n",
    "\n",
    "    Returns a dict with cleaned signals and the artifact mask/regions.\n",
    "    \"\"\"\n",
    "    t = np.asarray(time, float)\n",
    "    s = np.asarray(sig465, float)\n",
    "    r = np.asarray(ref405, float)\n",
    "\n",
    "    n = min(t.size, s.size, r.size)\n",
    "    t, s, r = t[:n], s[:n], r[:n]\n",
    "\n",
    "    if fs is None:\n",
    "        fs = 1.0 / float(np.nanmedian(np.diff(t))) if t.size > 2 else np.nan\n",
    "    if not np.isfinite(fs) or fs <= 0:\n",
    "        raise ValueError(f\"remove_artifacts_adaptive_mad: invalid fs={fs}\")\n",
    "\n",
    "    m_s = adaptive_mad_artifact_mask(\n",
    "        s, fs, k=k, window_s=window_s, pad_s=pad_s, use_derivative=use_derivative\n",
    "    )\n",
    "    m_r = adaptive_mad_artifact_mask(\n",
    "        r, fs, k=k, window_s=window_s, pad_s=pad_s, use_derivative=use_derivative\n",
    "    )\n",
    "    mask = (m_s | m_r) if union_channels else m_s\n",
    "\n",
    "    s_clean = s.copy()\n",
    "    r_clean = r.copy()\n",
    "    s_clean[mask] = np.nan\n",
    "    r_clean[mask] = np.nan\n",
    "\n",
    "    s_clean = _nan_interp_1d(s_clean)\n",
    "    r_clean = _nan_interp_1d(r_clean)\n",
    "\n",
    "    regions = []\n",
    "    if np.any(mask):\n",
    "        idx = np.where(mask)[0]\n",
    "        breaks = np.where(np.diff(idx) > 1)[0]\n",
    "        starts = np.r_[idx[0], idx[breaks + 1]]\n",
    "        ends   = np.r_[idx[breaks], idx[-1]]\n",
    "        for a, b in zip(starts, ends):\n",
    "            regions.append((float(t[a]), float(t[b])))\n",
    "\n",
    "    return {\n",
    "        \"time\": t,\n",
    "        \"sig465_clean\": s_clean,\n",
    "        \"ref405_clean\": r_clean,\n",
    "        \"artifact_mask\": mask,\n",
    "        \"artifact_regions_s\": regions,\n",
    "        \"fs\": float(fs),\n",
    "    }\n",
    "\n"
   ],
   "id": "2f01bdcbffa12b02",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T17:08:51.160989Z",
     "start_time": "2026-01-07T17:08:51.156955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Cell A — Z-score helper (median + std)\n",
    "# =========================\n",
    "def zscore_median_std(x, eps=1e-12, ddof=0):\n",
    "    \"\"\"\n",
    "    Z-score using median centering and (classical) std scaling:\n",
    "        z = (x - median(x)) / std(x)\n",
    "\n",
    "    Notes:\n",
    "      - This is not a robust scale estimator (unlike MAD), but matches your requested definition.\n",
    "      - If you want robust scaling, replace std with mad_sigma(x - median).\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, float)\n",
    "    m = np.isfinite(x)\n",
    "    if np.sum(m) < 10:\n",
    "        return np.full_like(x, np.nan, dtype=float)\n",
    "\n",
    "    med = np.median(x[m])\n",
    "    sd = np.std(x[m], ddof=ddof)\n",
    "    sd = sd if np.isfinite(sd) and sd > 0 else eps\n",
    "    z = (x - med) / (sd + eps)\n",
    "    return z\n"
   ],
   "id": "a4b89ad943a56b06",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T17:08:51.170007Z",
     "start_time": "2026-01-07T17:08:51.164490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Cell B — dF/F computation (baseline via low-pass; stable, no extra deps)\n",
    "# =========================\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def lowpass_baseline(x, fs, cutoff_hz=0.01, order=2):\n",
    "    \"\"\"\n",
    "    Smooth baseline using a low-pass Butterworth filter (zero-phase filtfilt).\n",
    "    cutoff_hz should be small (e.g., 0.005–0.05 Hz) depending on session length.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, float)\n",
    "    m = np.isfinite(x)\n",
    "    if np.sum(m) < 10 or not np.isfinite(fs) or fs <= 0:\n",
    "        return np.full_like(x, np.nan)\n",
    "\n",
    "    # fill NaNs for filtering\n",
    "    x_f = x.copy()\n",
    "    x_f[~m] = np.interp(np.flatnonzero(~m), np.flatnonzero(m), x[m])\n",
    "\n",
    "    nyq = 0.5 * fs\n",
    "    cutoff = min(max(cutoff_hz / nyq, 1e-6), 0.99)\n",
    "    b, a = butter(order, cutoff, btype=\"low\")\n",
    "    base = filtfilt(b, a, x_f)\n",
    "    return base\n",
    "\n",
    "def dff_from_baseline(x, fs, cutoff_hz=0.01, eps=1e-12):\n",
    "    \"\"\"\n",
    "    dF/F = (x - baseline) / baseline\n",
    "    \"\"\"\n",
    "    base = lowpass_baseline(x, fs, cutoff_hz=cutoff_hz)\n",
    "    dff = (x - base) / (base + eps)\n",
    "    return dff, base\n"
   ],
   "id": "58311bdd12b83811",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T17:08:51.203574Z",
     "start_time": "2026-01-07T17:08:51.172893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Cell C — QC on z-scored dF/F (z_ref vs z_sig; Z = z_sig - z_ref)\n",
    "# =========================\n",
    "def qc_one_file_zscore(\n",
    "    path,\n",
    "    rec,\n",
    "    outdir,\n",
    "    *,\n",
    "    # artifact removal params\n",
    "    do_artifact_removal=True,\n",
    "    ar_k=6.0,\n",
    "    ar_window_s=1.0,\n",
    "    ar_pad_s=0.2,\n",
    "    ar_union_channels=True,\n",
    "    ar_use_derivative=True,\n",
    "    # dF/F baseline params\n",
    "    baseline_cutoff_hz=0.01,\n",
    "    # QC params\n",
    "    corr_win_seconds=10.0,\n",
    "    max_plot_points=150_000,\n",
    "):\n",
    "    \"\"\"\n",
    "    QC in z-score space:\n",
    "      - artifact removal on raw sig/ref\n",
    "      - compute dff_sig, dff_ref from low-pass baseline\n",
    "      - compute z_sig, z_ref with zscore_median_std\n",
    "      - define Z = z_sig - z_ref\n",
    "      - correlate z_ref vs z_sig\n",
    "      - plot Z distribution as PDF and annotate metrics\n",
    "    \"\"\"\n",
    "    # --- load raw ---\n",
    "    t_raw = _as_float_1d(rec[\"time\"])\n",
    "    sig_raw = _as_float_1d(rec[\"sig465\"])\n",
    "    ref_raw = _as_float_1d(rec[\"ref405\"])\n",
    "    fs = float(rec.get(\"fs\", np.nan))\n",
    "\n",
    "    n0 = min(len(t_raw), len(sig_raw), len(ref_raw))\n",
    "    t_raw, sig_raw, ref_raw = t_raw[:n0], sig_raw[:n0], ref_raw[:n0]\n",
    "\n",
    "    finite = np.isfinite(t_raw) & np.isfinite(sig_raw) & np.isfinite(ref_raw)\n",
    "    t_raw, sig_raw, ref_raw = t_raw[finite], sig_raw[finite], ref_raw[finite]\n",
    "    n = len(t_raw)\n",
    "\n",
    "    # --- time sanity ---\n",
    "    dt = np.diff(t_raw)\n",
    "    dt_med = np.median(dt) if dt.size else np.nan\n",
    "    nonmono_frac = float(np.mean(dt <= 0)) if dt.size else np.nan\n",
    "\n",
    "    # --- artifact removal ---\n",
    "    if do_artifact_removal:\n",
    "        ar = remove_artifacts_adaptive_mad(\n",
    "            t_raw,\n",
    "            sig_raw,\n",
    "            ref_raw,\n",
    "            fs=fs if np.isfinite(fs) and fs > 0 else None,\n",
    "            k=ar_k,\n",
    "            window_s=ar_window_s,\n",
    "            pad_s=ar_pad_s,\n",
    "            union_channels=ar_union_channels,\n",
    "            use_derivative=ar_use_derivative,\n",
    "        )\n",
    "        t = ar[\"time\"]\n",
    "        sig = ar[\"sig465_clean\"]\n",
    "        ref = ar[\"ref405_clean\"]\n",
    "        art_mask = ar[\"artifact_mask\"]\n",
    "        art_regions = ar[\"artifact_regions_s\"]\n",
    "        fs_eff = ar[\"fs\"]\n",
    "    else:\n",
    "        t, sig, ref = t_raw, sig_raw, ref_raw\n",
    "        art_mask = np.zeros_like(t, dtype=bool)\n",
    "        art_regions = []\n",
    "        fs_eff = fs if np.isfinite(fs) else (1.0 / np.nanmedian(np.diff(t)) if t.size > 2 else np.nan)\n",
    "\n",
    "    art_frac = float(np.mean(art_mask)) if art_mask.size else 0.0\n",
    "\n",
    "    # --- dF/F for each channel ---\n",
    "    dff_sig, base_sig = dff_from_baseline(sig, fs_eff, cutoff_hz=baseline_cutoff_hz)\n",
    "    dff_ref, base_ref = dff_from_baseline(ref, fs_eff, cutoff_hz=baseline_cutoff_hz)\n",
    "\n",
    "    # --- z-score each dF/F ---\n",
    "    z_sig = zscore_median_std(dff_sig)\n",
    "    z_ref = zscore_median_std(dff_ref)\n",
    "\n",
    "    # --- your Z trace definition ---\n",
    "    Z = z_sig - z_ref\n",
    "\n",
    "    # --- correlation + robust regression in z-space ---\n",
    "    m = np.isfinite(z_sig) & np.isfinite(z_ref)\n",
    "    if np.sum(m) >= 10:\n",
    "        r_global, p_global = pearsonr(z_ref[m], z_sig[m])\n",
    "        a, b, s_rob = huber_irls(z_ref[m], z_sig[m], delta=1.5)\n",
    "    else:\n",
    "        r_global, p_global = np.nan, np.nan\n",
    "        a, b, s_rob = np.nan, np.nan, np.nan\n",
    "\n",
    "    # --- rolling correlation (z_ref vs z_sig) ---\n",
    "    if np.isfinite(fs_eff) and fs_eff > 0:\n",
    "        win = int(max(10, round(fs_eff * corr_win_seconds)))\n",
    "    else:\n",
    "        win = 5000\n",
    "\n",
    "    # Use full arrays (rolling_corr expects aligned arrays)\n",
    "    r_roll, centers = rolling_corr(z_ref, z_sig, win=win)\n",
    "    r_roll_med = float(np.nanmedian(r_roll)) if r_roll.size else np.nan\n",
    "    r_roll_min = float(np.nanmin(r_roll)) if r_roll.size else np.nan\n",
    "    pct_roll_gt_05 = float(np.mean(r_roll > 0.5) * 100.0) if r_roll.size else np.nan\n",
    "\n",
    "    # --- Z distribution metrics ---\n",
    "    Zf = Z[np.isfinite(Z)]\n",
    "    if Zf.size:\n",
    "        q25, q50, q75 = np.quantile(Zf, [0.25, 0.50, 0.75])\n",
    "        iqr = q75 - q25\n",
    "        halfwidth = 0.5 * iqr\n",
    "        frac_gt3 = float(np.mean(np.abs(Zf) > 3.0) * 100.0)\n",
    "        frac_gt5 = float(np.mean(np.abs(Zf) > 5.0) * 100.0)\n",
    "    else:\n",
    "        q25 = q50 = q75 = iqr = halfwidth = np.nan\n",
    "        frac_gt3 = frac_gt5 = np.nan\n",
    "\n",
    "    # --- Z AUC metrics (per second is most comparable) ---\n",
    "    if t.size >= 2 and np.isfinite(Z).any():\n",
    "        auc_signed = float(np.trapz(np.nan_to_num(Z, nan=0.0), t))\n",
    "        auc_abs = float(np.trapz(np.abs(np.nan_to_num(Z, nan=0.0)), t))\n",
    "        duration = float(t[-1] - t[0])\n",
    "        auc_signed_per_s = auc_signed / duration if duration > 0 else np.nan\n",
    "        auc_abs_per_s = auc_abs / duration if duration > 0 else np.nan\n",
    "    else:\n",
    "        auc_signed = auc_abs = auc_signed_per_s = auc_abs_per_s = np.nan\n",
    "\n",
    "    # --- additional useful QC metric: Z rolling variability ---\n",
    "    # Use same windowing as rolling corr, compute windowed std of Z\n",
    "    zstd_roll = np.array([])\n",
    "    if win and Z.size >= win * 2:\n",
    "        nwin = (len(Z) // win)\n",
    "        Z2 = Z[:nwin * win].reshape(nwin, win)\n",
    "        zstd_roll = np.nanstd(Z2, axis=1)\n",
    "\n",
    "    zstd_med = float(np.nanmedian(zstd_roll)) if zstd_roll.size else np.nan\n",
    "\n",
    "    # -----------------------------\n",
    "    # Plotting\n",
    "    # -----------------------------\n",
    "    fname = Path(path).stem\n",
    "    outdir = Path(outdir)\n",
    "    outdir = Path(outdir)\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if n > max_plot_points:\n",
    "        idx = np.linspace(0, n - 1, max_plot_points).astype(int)\n",
    "    else:\n",
    "        idx = np.arange(n)\n",
    "\n",
    "    # scatter downsample\n",
    "    idx_sc = idx\n",
    "    z_ref_sc = z_ref[idx_sc]\n",
    "    z_sig_sc = z_sig[idx_sc]\n",
    "    m_sc = np.isfinite(z_ref_sc) & np.isfinite(z_sig_sc)\n",
    "    z_ref_sc = z_ref_sc[m_sc]\n",
    "    z_sig_sc = z_sig_sc[m_sc]\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 10), dpi=150)\n",
    "    gs = fig.add_gridspec(4, 3, height_ratios=[1.0, 1.0, 1.0, 1.0])\n",
    "\n",
    "    ax0 = fig.add_subplot(gs[0, :])     # z_sig, z_ref, Z\n",
    "    ax1 = fig.add_subplot(gs[1, 0:2])   # scatter z_ref vs z_sig\n",
    "    ax2 = fig.add_subplot(gs[1, 2])     # Z PDF\n",
    "    ax3 = fig.add_subplot(gs[2, :])     # Z over time (with AUC)\n",
    "    ax4 = fig.add_subplot(gs[3, 0])     # rolling corr\n",
    "    ax5 = fig.add_subplot(gs[3, 1])     # rolling std of Z\n",
    "    ax6 = fig.add_subplot(gs[3, 2])     # dff overview (optional sanity)\n",
    "\n",
    "    # A) z traces\n",
    "    ax0.plot(t[idx], z_sig[idx], lw=0.7, color=\"C0\", label=\"z_sig = z(dff_sig)\")\n",
    "    ax0.plot(t[idx], z_ref[idx], lw=0.7, color=\"C1\", label=\"z_ref = z(dff_ref)\")\n",
    "    # ax0.plot(t[idx], Z[idx],     lw=0.9, color=\"k\",  alpha=0.7, label=\"Z = z_sig - z_ref\")\n",
    "\n",
    "    if do_artifact_removal and art_regions:\n",
    "        for (t0, t1) in art_regions[:20]:\n",
    "            ax0.axvspan(t0, t1, color=\"crimson\", alpha=0.05)\n",
    "\n",
    "    ax0.set_title(f\"{fname} | z-space QC | art_removed={art_frac*100:.2f}% | baseline_cutoff={baseline_cutoff_hz} Hz\")\n",
    "    ax0.set_xlabel(\"time (s)\")\n",
    "    ax0.set_ylabel(\"z units\")\n",
    "    ax0.grid(True, alpha=0.25)\n",
    "    ax0.legend(loc=\"upper right\", ncols=3, fontsize=8)\n",
    "\n",
    "    # B) scatter z_ref vs z_sig + robust fit\n",
    "    ax1.scatter(z_ref_sc, z_sig_sc, s=6, alpha=0.25, edgecolor=\"none\")\n",
    "    if np.isfinite(a) and np.isfinite(b) and z_ref_sc.size:\n",
    "        xline = np.linspace(np.nanmin(z_ref_sc), np.nanmax(z_ref_sc), 200)\n",
    "        ax1.plot(xline, a * xline + b, lw=2.0, color=\"C3\", label=\"robust fit\")\n",
    "    ax1.set_xlabel(\"z_ref\")\n",
    "    ax1.set_ylabel(\"z_sig\")\n",
    "    ax1.set_title(\"Correlation in z-space\")\n",
    "    ax1.grid(True, alpha=0.25)\n",
    "\n",
    "    stats_txt = (\n",
    "        f\"Pearson r={r_global:.4f}\\n\"\n",
    "        f\"rolling r med={r_roll_med:.3f}, min={r_roll_min:.3f}\\n\"\n",
    "        f\"% windows r>0.5={pct_roll_gt_05:.1f}%\\n\"\n",
    "        f\"fit: z_sig={a:.3g}*z_ref + {b:.3g}\\n\"\n",
    "        f\"dt_med={dt_med:.6g}  nonmono={nonmono_frac*100:.3f}%\\n\"\n",
    "        f\"Z roll-std median={zstd_med:.3g}\"\n",
    "    )\n",
    "    ax1.text(\n",
    "        0.02, 0.98, stats_txt,\n",
    "        transform=ax1.transAxes, va=\"top\", ha=\"left\",\n",
    "        bbox=dict(boxstyle=\"round,pad=0.35\", facecolor=\"white\", alpha=0.9, edgecolor=\"0.7\"),\n",
    "        fontsize=8\n",
    "    )\n",
    "\n",
    "    # C) Z distribution as PDF (hist density + optional KDE)\n",
    "    ax2.set_title(\"Z distribution (PDF)\")\n",
    "    ax2.set_xlabel(\"Z = z_sig - z_ref\")\n",
    "    ax2.set_ylabel(\"density\")\n",
    "    ax2.grid(True, alpha=0.25)\n",
    "\n",
    "    pdf_area_hist = np.nan\n",
    "    pdf_area_kde = np.nan\n",
    "    pdf_peak_kde = np.nan\n",
    "    pdf_entropy_kde = np.nan\n",
    "\n",
    "    if Zf.size:\n",
    "        # histogram PDF + area\n",
    "        hist_density, edges = np.histogram(Zf, bins=80, density=True)\n",
    "        bw = np.diff(edges)\n",
    "        centers_h = edges[:-1] + bw / 2\n",
    "        pdf_area_hist = float(np.sum(hist_density * bw))  # should be ~1.0\n",
    "        ax2.bar(centers_h, hist_density, width=bw, color=\"0.6\", alpha=0.55, edgecolor=\"none\", label=\"hist PDF\")\n",
    "\n",
    "        # KDE over central range (0.1%–99.9%) and area over that truncated range\n",
    "        try:\n",
    "            from scipy.stats import gaussian_kde\n",
    "            kde = gaussian_kde(Zf)\n",
    "            x_lo = float(np.quantile(Zf, 0.001))\n",
    "            x_hi = float(np.quantile(Zf, 0.999))\n",
    "            xs = np.linspace(x_lo, x_hi, 500)\n",
    "            ys = kde(xs)\n",
    "\n",
    "            pdf_area_kde = float(np.trapz(ys, xs))          # < 1 because truncated\n",
    "            pdf_peak_kde = float(np.max(ys))\n",
    "\n",
    "            # entropy over the plotted range (normalized)\n",
    "            ys_norm = ys / (pdf_area_kde + 1e-12)\n",
    "            pdf_entropy_kde = float(-np.trapz(ys_norm * np.log(ys_norm + 1e-12), xs))\n",
    "\n",
    "            ax2.plot(xs, ys, color=\"C0\", lw=2, label=\"KDE\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # quantiles overlay\n",
    "        ax2.axvline(q50, color=\"C0\", lw=2, label=\"median\")\n",
    "        ax2.axvspan(q25, q75, color=\"C0\", alpha=0.12, label=\"25–75%\")\n",
    "\n",
    "        pdf_txt = (\n",
    "            f\"Hist area≈{pdf_area_hist:.5f} (≈1.0 expected)\\n\"\n",
    "            f\"KDE area (0.1–99.9%)≈{pdf_area_kde:.5f}\\n\"\n",
    "            f\"peak KDE={pdf_peak_kde:.4g}\\n\"\n",
    "            f\"entropy KDE={pdf_entropy_kde:.4g}\\n\"\n",
    "            f\"median={q50:.3g}\\n\"\n",
    "            f\"IQR={iqr:.3g}  halfwidth={halfwidth:.3g}\\n\"\n",
    "            f\"|Z|>3: {frac_gt3:.2f}%  |Z|>5: {frac_gt5:.2f}%\"\n",
    "        )\n",
    "        ax2.text(\n",
    "            0.02, 0.98, pdf_txt,\n",
    "            transform=ax2.transAxes, va=\"top\", ha=\"left\",\n",
    "            bbox=dict(boxstyle=\"round,pad=0.30\", facecolor=\"white\", alpha=0.9, edgecolor=\"0.7\"),\n",
    "            fontsize=8\n",
    "        )\n",
    "        ax2.legend(loc=\"best\", fontsize=8)\n",
    "\n",
    "    # D) Z over time + AUC annotation\n",
    "    ax3.plot(t[idx], Z[idx], lw=0.7, color=\"k\", alpha=0.9)\n",
    "    ax3.axhline(0, color=\"k\", lw=1, alpha=0.4)\n",
    "    ax3.set_title(\"Z over time\")\n",
    "    ax3.set_xlabel(\"time (s)\")\n",
    "    ax3.set_ylabel(\"Z (z units)\")\n",
    "    ax3.grid(True, alpha=0.25)\n",
    "\n",
    "    auc_txt = (\n",
    "        f\"AUC signed={auc_signed:.4g}\\n\"\n",
    "        f\"AUC abs={auc_abs:.4g}\\n\"\n",
    "        f\"signed/s={auc_signed_per_s:.4g}\\n\"\n",
    "        f\"abs/s={auc_abs_per_s:.4g}\"\n",
    "    )\n",
    "    ax3.text(\n",
    "        0.02, 0.98, auc_txt,\n",
    "        transform=ax3.transAxes, va=\"top\", ha=\"left\",\n",
    "        bbox=dict(boxstyle=\"round,pad=0.30\", facecolor=\"white\", alpha=0.9, edgecolor=\"0.7\"),\n",
    "        fontsize=8\n",
    "    )\n",
    "\n",
    "    # E) rolling corr\n",
    "    ax4.set_title(f\"Rolling corr(z_ref, z_sig) ({corr_win_seconds:.0f}s windows)\")\n",
    "    ax4.set_xlabel(\"time (s)\")\n",
    "    ax4.set_ylabel(\"r\")\n",
    "    ax4.grid(True, alpha=0.25)\n",
    "    if r_roll.size:\n",
    "        t_cent = t[(centers.astype(int)).clip(0, n - 1)]\n",
    "        ax4.plot(t_cent, r_roll, lw=1.0)\n",
    "        ax4.axhline(0.5, color=\"0.3\", lw=1, ls=\"--\", alpha=0.7)\n",
    "        ax4.set_ylim(-1.05, 1.05)\n",
    "        ax4.text(\n",
    "            0.02, 0.98,\n",
    "            f\"% windows r>0.5: {pct_roll_gt_05:.1f}%\",\n",
    "            transform=ax4.transAxes, va=\"top\", ha=\"left\",\n",
    "            bbox=dict(boxstyle=\"round,pad=0.25\", facecolor=\"white\", alpha=0.9, edgecolor=\"0.7\"),\n",
    "            fontsize=8,\n",
    "        )\n",
    "\n",
    "    # F) rolling std(Z)\n",
    "    ax5.set_title(\"Rolling std(Z)\")\n",
    "    ax5.set_xlabel(\"window #\")\n",
    "    ax5.set_ylabel(\"std\")\n",
    "    ax5.grid(True, alpha=0.25)\n",
    "    if zstd_roll.size:\n",
    "        ax5.plot(zstd_roll, lw=1.0)\n",
    "        ax5.axhline(zstd_med, color=\"C3\", lw=1.2, ls=\"--\", alpha=0.8, label=f\"median={zstd_med:.3g}\")\n",
    "        ax5.legend(loc=\"best\", fontsize=8)\n",
    "\n",
    "    # G) dF/F sanity (downsample)\n",
    "    ax6.set_title(\"dF/F sanity (sig vs ref)\")\n",
    "    ax6.plot(t[idx], dff_sig[idx], lw=0.7, color=\"C0\", alpha=0.8, label=\"dff_sig\")\n",
    "    ax6.plot(t[idx], dff_ref[idx], lw=0.7, color=\"C1\", alpha=0.8, label=\"dff_ref\")\n",
    "    ax6.axhline(0, color=\"k\", lw=1, alpha=0.4)\n",
    "    ax6.set_xlabel(\"time (s)\")\n",
    "    ax6.set_ylabel(\"dF/F\")\n",
    "    ax6.grid(True, alpha=0.25)\n",
    "    ax6.legend(loc=\"best\", fontsize=8)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    outpath = outdir / f\"{fname}_QC_zscore.png\"\n",
    "    fig.savefig(outpath, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    return dict(\n",
    "        file=Path(path).name,\n",
    "        n=n,\n",
    "        fs=fs_eff,\n",
    "        dt_median=dt_med,\n",
    "        nonmono_frac=nonmono_frac,\n",
    "        artifact_frac=art_frac,\n",
    "        n_artifact_regions=len(art_regions),\n",
    "\n",
    "        # z-space correlation metrics\n",
    "        pearson_r_z=r_global,\n",
    "        pearson_p_z=p_global,\n",
    "        rolling_r_median_z=r_roll_med,\n",
    "        rolling_r_min_z=r_roll_min,\n",
    "        rolling_pct_gt_05_z=pct_roll_gt_05,\n",
    "        fit_slope_z=a,\n",
    "        fit_intercept_z=b,\n",
    "\n",
    "        # Z distribution metrics\n",
    "        Z_median=q50,\n",
    "        Z_q25=q25,\n",
    "        Z_q75=q75,\n",
    "        Z_iqr=iqr,\n",
    "        Z_halfwidth=halfwidth,\n",
    "        Z_tail_frac_gt3=frac_gt3,\n",
    "        Z_tail_frac_gt5=frac_gt5,\n",
    "\n",
    "        # Z AUC\n",
    "        Z_auc_signed=auc_signed,\n",
    "        Z_auc_abs=auc_abs,\n",
    "        Z_auc_signed_per_s=auc_signed_per_s,\n",
    "        Z_auc_abs_per_s=auc_abs_per_s,\n",
    "\n",
    "        # PDF metrics\n",
    "        Z_pdf_area_hist=pdf_area_hist,                  # ~1.0 (sanity check)\n",
    "        Z_pdf_area_kde_001_999=pdf_area_kde,            # area over truncated range\n",
    "        Z_pdf_peak_kde=pdf_peak_kde,\n",
    "        Z_pdf_entropy_kde=pdf_entropy_kde,\n",
    "\n",
    "        # rolling Z variability\n",
    "        Z_roll_std_median=zstd_med,\n",
    "\n",
    "        qc_figure=str(outpath),\n",
    "    )\n"
   ],
   "id": "941e5dcdd3ee5cb0",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T17:08:51.211693Z",
     "start_time": "2026-01-07T17:08:51.208176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Cell D — Folder runner (z-score QC)\n",
    "# =========================\n",
    "def qc_folder_zscore(\n",
    "    folder,\n",
    "    doric_paths,\n",
    "    load_doric,\n",
    "    *,\n",
    "    out_subdir=\"QC_reports_zscore\",\n",
    "    do_artifact_removal=True,\n",
    "    ar_k=6.0,\n",
    "    ar_window_s=1.0,\n",
    "    ar_pad_s=0.2,\n",
    "    ar_union_channels=True,\n",
    "    ar_use_derivative=True,\n",
    "    baseline_cutoff_hz=0.01,\n",
    "    corr_win_seconds=10.0,\n",
    "    max_plot_points=150_000,\n",
    "):\n",
    "    folder = Path(folder)\n",
    "    outdir = folder / out_subdir\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    all_metrics = []\n",
    "    for path in doric_paths:\n",
    "        rec = load_doric(path)\n",
    "        m = qc_one_file_zscore(\n",
    "            path, rec, outdir,\n",
    "            do_artifact_removal=do_artifact_removal,\n",
    "            ar_k=ar_k, ar_window_s=ar_window_s, ar_pad_s=ar_pad_s,\n",
    "            ar_union_channels=ar_union_channels, ar_use_derivative=ar_use_derivative,\n",
    "            baseline_cutoff_hz=baseline_cutoff_hz,\n",
    "            corr_win_seconds=corr_win_seconds,\n",
    "            max_plot_points=max_plot_points,\n",
    "        )\n",
    "        all_metrics.append(m)\n",
    "        print(\n",
    "            f\"{m['file']:<22s} \"\n",
    "            f\"r_z={m['pearson_r_z']:.3f} \"\n",
    "            f\"roll_med={m['rolling_r_median_z']:.3f} \"\n",
    "            f\"%r>0.5={m['rolling_pct_gt_05_z']:.1f}% \"\n",
    "            f\"|Z|>3={m['Z_tail_frac_gt3']:.2f}% \"\n",
    "            f\"art%={100*m['artifact_frac']:.2f} \"\n",
    "            f\"fig={Path(m['qc_figure']).name}\"\n",
    "        )\n",
    "\n",
    "    return all_metrics\n"
   ],
   "id": "2ff0dbd4a841e967",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T17:09:10.189548Z",
     "start_time": "2026-01-07T17:08:51.217107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Cell E — Run (z-score QC)\n",
    "# =========================\n",
    "folder = r\"C:\\Analysis\\fiber_photometry_app\\test_data\\batch1_test\"\n",
    "doric_paths = list_doric_files(folder)\n",
    "\n",
    "metrics_z = qc_folder_zscore(\n",
    "    folder,\n",
    "    doric_paths,\n",
    "    load_doric,\n",
    "    out_subdir=\"QC_reports_zscore\",\n",
    "    do_artifact_removal=True,\n",
    "    ar_k=6.0,\n",
    "    ar_window_s=1.0,\n",
    "    ar_pad_s=0.2,\n",
    "    baseline_cutoff_hz=0.01,   # tune based on session length\n",
    "    corr_win_seconds=10.0,\n",
    ")\n"
   ],
   "id": "878a00c7baa1453f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andrianj\\AppData\\Local\\Temp\\ipykernel_4458404\\4125328070.py:122: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  auc_signed = float(np.trapz(np.nan_to_num(Z, nan=0.0), t))\n",
      "C:\\Users\\andrianj\\AppData\\Local\\Temp\\ipykernel_4458404\\4125328070.py:123: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  auc_abs = float(np.trapz(np.abs(np.nan_to_num(Z, nan=0.0)), t))\n",
      "C:\\Users\\andrianj\\AppData\\Local\\Temp\\ipykernel_4458404\\4125328070.py:240: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  pdf_area_kde = float(np.trapz(ys, xs))          # < 1 because truncated\n",
      "C:\\Users\\andrianj\\AppData\\Local\\Temp\\ipykernel_4458404\\4125328070.py:245: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  pdf_entropy_kde = float(-np.trapz(ys_norm * np.log(ys_norm + 1e-12), xs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30546-test_0005.doric  r_z=0.803 roll_med=0.748 %r>0.5=66.7% |Z|>3=0.00% art%=0.00 fig=30546-test_0005_QC_zscore.png\n",
      "30547-test_0006.doric  r_z=0.477 roll_med=-0.222 %r>0.5=6.9% |Z|>3=0.64% art%=0.00 fig=30547-test_0006_QC_zscore.png\n",
      "30550-test_0001.doric  r_z=0.918 roll_med=0.813 %r>0.5=88.9% |Z|>3=0.00% art%=0.00 fig=30550-test_0001_QC_zscore.png\n",
      "30551-test_0001.doric  r_z=0.805 roll_med=0.807 %r>0.5=100.0% |Z|>3=0.00% art%=0.00 fig=30551-test_0001_QC_zscore.png\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T17:09:10.218072Z",
     "start_time": "2026-01-07T17:09:10.214075Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e12b0365b482c687",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T17:09:10.225507Z",
     "start_time": "2026-01-07T17:09:10.222507Z"
    }
   },
   "cell_type": "code",
   "source": "\n",
   "id": "f414c640b0ef9184",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T17:09:10.234758Z",
     "start_time": "2026-01-07T17:09:10.230758Z"
    }
   },
   "cell_type": "code",
   "source": "\n",
   "id": "2fecea5556bebd03",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T17:09:10.242757Z",
     "start_time": "2026-01-07T17:09:10.239757Z"
    }
   },
   "cell_type": "code",
   "source": "\n",
   "id": "246324379d2cc361",
   "outputs": [],
   "execution_count": 70
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
