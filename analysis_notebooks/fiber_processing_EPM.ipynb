{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T20:26:27.246568Z",
     "start_time": "2025-12-19T20:26:27.241054Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "try:\n",
    "    from sklearn.linear_model import Lasso\n",
    "except Exception:\n",
    "    Lasso = None\n",
    "from pybaselines import Baseline\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 4)\n",
    "plt.rcParams[\"axes.grid\"] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16606b8d9a8214c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T20:26:27.293109Z",
     "start_time": "2025-12-19T20:26:27.254905Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt, decimate\n",
    "def list_doric_channels(path):\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        base = f[\"DataAcquisition\"][\"FPConsole\"][\"Signals\"][\"Series0001\"]\n",
    "        chans = []\n",
    "        if \"LockInAOUT02\" in base:\n",
    "            for k in base[\"LockInAOUT02\"].keys():\n",
    "                if k.startswith(\"AIN\"):\n",
    "                    chans.append(k)\n",
    "        chans = sorted(chans)\n",
    "\n",
    "        digital = []\n",
    "        if \"DigitalIO\" in base:\n",
    "            for k in base[\"DigitalIO\"].keys():\n",
    "                if k.startswith(\"DIO\"):\n",
    "                    digital.append(k)\n",
    "        return chans, digital\n",
    "\n",
    "def load_doric(path, channel=\"AIN01\", signal_folder=\"LockInAOUT02\", ref_folder=\"LockInAOUT01\",\n",
    "              trigger_name=None):\n",
    "    \"\"\"\n",
    "    Returns dict with:\n",
    "      time, sig465, ref405, fs, (optional) trig_time, trig\n",
    "    \"\"\"\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        base = f[\"DataAcquisition\"][\"FPConsole\"][\"Signals\"][\"Series0001\"]\n",
    "\n",
    "        sig = np.asarray(base[signal_folder][channel][()], float)\n",
    "        ref = np.asarray(base[ref_folder][channel][()], float)\n",
    "\n",
    "        # time: prefer the matching folder time if size matches\n",
    "        t_sig = np.asarray(base[signal_folder][\"Time\"][()], float) if \"Time\" in base[signal_folder] else np.array([])\n",
    "        t_ref = np.asarray(base[ref_folder][\"Time\"][()], float) if \"Time\" in base[ref_folder] else np.array([])\n",
    "\n",
    "        if t_sig.size == sig.size:\n",
    "            t = t_sig\n",
    "        elif t_ref.size == sig.size:\n",
    "            t = t_ref\n",
    "        else:\n",
    "            # fallback\n",
    "            dt = np.nanmedian(np.diff(t_sig)) if t_sig.size > 2 else 1/1000\n",
    "            t = np.arange(sig.size) * dt\n",
    "\n",
    "        # if ref length differs, interpolate onto t if possible\n",
    "        if ref.size != sig.size:\n",
    "            if t_ref.size == ref.size:\n",
    "                ref = np.interp(t, t_ref, ref)\n",
    "            else:\n",
    "                ref = np.resize(ref, sig.size)\n",
    "\n",
    "        # sampling rate\n",
    "        fs = 1.0 / float(np.nanmedian(np.diff(t))) if t.size > 2 else np.nan\n",
    "\n",
    "        # optional digital trigger overlay\n",
    "        trig_time = None\n",
    "        trig = None\n",
    "        if trigger_name:\n",
    "            if \"DigitalIO\" in base and trigger_name in base[\"DigitalIO\"]:\n",
    "                dio = base[\"DigitalIO\"]\n",
    "                trig = np.asarray(dio[trigger_name][()], float)\n",
    "                trig_time = np.asarray(dio[\"Time\"][()], float) if \"Time\" in dio else None\n",
    "\n",
    "                # if lengths mismatch, interpolate signals to trigger time (like your Doric logic)\n",
    "                if trig_time is not None and trig_time.size and trig_time.size != t.size:\n",
    "                    sig = np.interp(trig_time, t, sig)\n",
    "                    ref = np.interp(trig_time, t, ref)\n",
    "                    t = trig_time\n",
    "                    fs = 1.0 / float(np.nanmedian(np.diff(t))) if t.size > 2 else fs\n",
    "\n",
    "    out = {\"time\": t, \"sig465\": sig, \"ref405\": ref, \"fs\": fs}\n",
    "    if trig is not None and trig_time is not None:\n",
    "        out[\"trig_time\"] = trig_time\n",
    "        out[\"trig\"] = trig\n",
    "    return out\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "\n",
    "def _nan_interp_1d(y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Linearly interpolate NaNs in a 1D array.\n",
    "    Edge NaNs are filled with nearest valid value.\n",
    "    \"\"\"\n",
    "    y = np.asarray(y, float).copy()\n",
    "    n = y.size\n",
    "    if n == 0:\n",
    "        return y\n",
    "\n",
    "    isnan = ~np.isfinite(y)\n",
    "    if not np.any(isnan):\n",
    "        return y\n",
    "\n",
    "    x = np.arange(n)\n",
    "    good = np.isfinite(y)\n",
    "    if np.sum(good) == 0:\n",
    "        # nothing to interpolate from\n",
    "        return y\n",
    "\n",
    "    y[isnan] = np.interp(x[isnan], x[good], y[good])\n",
    "    return y\n",
    "\n",
    "\n",
    "def adaptive_mad_artifact_mask(\n",
    "    y: np.ndarray,\n",
    "    fs: float,\n",
    "    *,\n",
    "    k: float = 6.0,\n",
    "    window_s: float = 1.0,\n",
    "    pad_s: float = 0.2,\n",
    "    use_derivative: bool = True,\n",
    "    min_mad: float = 1e-12,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build an artifact mask using Adaptive MAD (windowed).\n",
    "\n",
    "    Detection is performed on dx=diff(y) if use_derivative=True, else directly on y.\n",
    "    Within each non-overlapping window, compute median and MAD, then flag samples where:\n",
    "        |x - median| > k * MAD\n",
    "\n",
    "    Mask is returned at signal sample resolution (len(y)).\n",
    "    \"\"\"\n",
    "    y = np.asarray(y, float)\n",
    "    n = y.size\n",
    "    if n == 0:\n",
    "        return np.zeros((0,), dtype=bool)\n",
    "\n",
    "    if not np.isfinite(fs) or fs <= 0:\n",
    "        raise ValueError(f\"adaptive_mad_artifact_mask: invalid fs={fs}\")\n",
    "\n",
    "    x = np.diff(y) if use_derivative else y.copy()\n",
    "    # x length is n-1 if derivative else n\n",
    "    nx = x.size\n",
    "    if nx == 0:\n",
    "        return np.zeros((n,), dtype=bool)\n",
    "\n",
    "    win = int(round(window_s * fs))\n",
    "    win = max(5, win)  # avoid tiny windows\n",
    "\n",
    "    flagged_x = np.zeros((nx,), dtype=bool)\n",
    "\n",
    "    # Process non-overlapping windows (fast, “adaptive” across time)\n",
    "    for start in range(0, nx, win):\n",
    "        stop = min(start + win, nx)\n",
    "        seg = x[start:stop]\n",
    "\n",
    "        # Ignore non-finite values in stats\n",
    "        seg_f = seg[np.isfinite(seg)]\n",
    "        if seg_f.size < 5:\n",
    "            continue\n",
    "\n",
    "        med = np.median(seg_f)\n",
    "        mad = np.median(np.abs(seg_f - med))\n",
    "        mad = max(float(mad), float(min_mad))\n",
    "\n",
    "        flagged_x[start:stop] = np.abs(seg - med) > (k * mad)\n",
    "\n",
    "    # Map flagged_x back to signal sample mask (len(y))\n",
    "    mask = np.zeros((n,), dtype=bool)\n",
    "    if use_derivative:\n",
    "        # A large dx affects both samples around the step\n",
    "        hit = np.where(flagged_x)[0]\n",
    "        mask[hit] = True\n",
    "        mask[hit + 1] = True\n",
    "    else:\n",
    "        mask[:nx] = flagged_x  # nx == n in this mode\n",
    "\n",
    "    # Pad mask by pad_s seconds\n",
    "    pad_n = int(round(pad_s * fs))\n",
    "    if pad_n > 0 and np.any(mask):\n",
    "        kernel = np.ones((2 * pad_n + 1,), dtype=int)\n",
    "        mask = (np.convolve(mask.astype(int), kernel, mode=\"same\") > 0)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional\n",
    "\n",
    "def remove_artifacts_adaptive_mad(\n",
    "    time: np.ndarray,\n",
    "    sig465: np.ndarray,\n",
    "    ref405: np.ndarray,\n",
    "    fs: float = None,\n",
    "    *,\n",
    "    k: float = 7.0,\n",
    "    window_s: float = 1.0,\n",
    "    pad_s: float = 0.2,\n",
    "    union_channels: bool = True,\n",
    "    use_derivative: bool = True,\n",
    "    # --- NEW plotting options ---\n",
    "    plot: bool = True,\n",
    "    plot_decim: int = 1,\n",
    "    plot_show_mask: bool = True,\n",
    "    plot_alpha_mask: float = 0.20,\n",
    "    plot_xlim= None,\n",
    "    plot_title=None,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Detect + remove artifacts using adaptive MAD (windowed) with padding.\n",
    "\n",
    "    By default, artifacts are detected on BOTH channels and unioned (recommended),\n",
    "    then removed from BOTH channels consistently.\n",
    "\n",
    "    Plotting:\n",
    "      - plot=True: show before/after for both channels + (optional) artifact mask shading.\n",
    "\n",
    "    Returns a dict:\n",
    "      {\n",
    "        \"time\": time,\n",
    "        \"sig465_clean\": ...,\n",
    "        \"ref405_clean\": ...,\n",
    "        \"artifact_mask\": ...,\n",
    "        \"artifact_regions_s\": [(t0,t1), ...],\n",
    "        \"fs\": fs\n",
    "      }\n",
    "    \"\"\"\n",
    "    t = np.asarray(time, float)\n",
    "    s = np.asarray(sig465, float)\n",
    "    r = np.asarray(ref405, float)\n",
    "\n",
    "    n = min(t.size, s.size, r.size)\n",
    "    t, s, r = t[:n], s[:n], r[:n]\n",
    "\n",
    "    if fs is None:\n",
    "        fs = 1.0 / float(np.nanmedian(np.diff(t))) if t.size > 2 else np.nan\n",
    "    if not np.isfinite(fs) or fs <= 0:\n",
    "        raise ValueError(f\"remove_artifacts_adaptive_mad: invalid fs={fs}\")\n",
    "\n",
    "    m_s = adaptive_mad_artifact_mask(s, fs, k=k, window_s=window_s, pad_s=pad_s, use_derivative=use_derivative)\n",
    "    m_r = adaptive_mad_artifact_mask(r, fs, k=k, window_s=window_s, pad_s=pad_s, use_derivative=use_derivative)\n",
    "\n",
    "    mask = (m_s | m_r) if union_channels else m_s\n",
    "\n",
    "    # Keep a copy for plotting / debugging\n",
    "    s_raw = s.copy()\n",
    "    r_raw = r.copy()\n",
    "\n",
    "    # Remove artifacts and interpolate\n",
    "    s_clean = s_raw.copy()\n",
    "    r_clean = r_raw.copy()\n",
    "    s_clean[mask] = np.nan\n",
    "    r_clean[mask] = np.nan\n",
    "\n",
    "    s_clean = _nan_interp_1d(s_clean)\n",
    "    r_clean = _nan_interp_1d(r_clean)\n",
    "\n",
    "    # Build contiguous regions in seconds\n",
    "    regions = []\n",
    "    if np.any(mask):\n",
    "        idx = np.where(mask)[0]\n",
    "        breaks = np.where(np.diff(idx) > 1)[0]\n",
    "        starts = np.r_[idx[0], idx[breaks + 1]]\n",
    "        ends   = np.r_[idx[breaks], idx[-1]]\n",
    "        for a, b in zip(starts, ends):\n",
    "            regions.append((float(t[a]), float(t[b])))\n",
    "\n",
    "    # --- NEW: plotting ---\n",
    "    if plot:\n",
    "        d = max(int(plot_decim), 1)\n",
    "        tt = t[::d]\n",
    "        sr = s_raw[::d]\n",
    "        sc = s_clean[::d]\n",
    "        rr = r_raw[::d]\n",
    "        rc = r_clean[::d]\n",
    "        mm = mask[::d]\n",
    "\n",
    "        fig, axs = plt.subplots(2, 1, figsize=(14, 6.5), sharex=True, constrained_layout=True)\n",
    "\n",
    "        # 465\n",
    "        ax = axs[0]\n",
    "        ax.plot(tt, sr, color=\"0.55\", lw=1.0, label=\"465 raw\")\n",
    "        ax.plot(tt, sc, color=\"red\", lw=1.2, label=\"465 cleaned\")\n",
    "        ax.set_ylabel(\"Signal 465\")\n",
    "        ax.grid(True, alpha=0.15)\n",
    "        ax.legend(frameon=False, loc=\"upper right\")\n",
    "\n",
    "        # apply shading AFTER limits exist (force draw-limits)\n",
    "        ax.relim(); ax.autoscale_view()\n",
    "\n",
    "\n",
    "        # 405\n",
    "        ax = axs[1]\n",
    "        ax.plot(tt, rr, color=\"0.55\", lw=1.0, label=\"405 raw\")\n",
    "        ax.plot(tt, rc, color=\"red\", lw=1.2, label=\"405 cleaned\")\n",
    "        ax.set_ylabel(\"Reference 405\")\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        ax.grid(True, alpha=0.15)\n",
    "        ax.legend(frameon=False, loc=\"upper right\")\n",
    "\n",
    "        ax.relim(); ax.autoscale_view()\n",
    "\n",
    "\n",
    "        if plot_xlim is not None:\n",
    "            axs[1].set_xlim(plot_xlim)\n",
    "\n",
    "        if plot_title is None:\n",
    "            plot_title = f\"Artifact removal (k={k}, window={window_s}s, pad={pad_s}s, union={union_channels}, deriv={use_derivative})\"\n",
    "        fig.suptitle(plot_title, y=1.02, fontsize=12)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    return {\n",
    "        \"time\": t,\n",
    "        \"sig465_clean\": s_clean,\n",
    "        \"ref405_clean\": r_clean,\n",
    "        \"artifact_mask\": mask,\n",
    "        \"artifact_regions_s\": regions,\n",
    "        \"fs\": fs,\n",
    "    }\n",
    "\n",
    "\n",
    "def ols_fit(x, y):\n",
    "    x = np.asarray(x, float)\n",
    "    y = np.asarray(y, float)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    if np.sum(m) < 10:\n",
    "        return 1.0, 0.0\n",
    "    X = np.vstack([x[m], np.ones(np.sum(m))]).T\n",
    "    coef, *_ = np.linalg.lstsq(X, y[m], rcond=None)\n",
    "    return float(coef[0]), float(coef[1])\n",
    "def preprocess_signal(sig, fs_raw, target_fs=100, lpf_cutoff=3):\n",
    "    \"\"\"\n",
    "    1\\) Low-pass filter (Butterworth, lpf_cutoff Hz)\n",
    "    2\\) Decimate to target sampling rate (target_fs Hz)\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * fs_raw\n",
    "    normal_cutoff = lpf_cutoff / nyquist\n",
    "    b, a = butter(N=2, Wn=normal_cutoff, btype=\"low\", analog=False)\n",
    "    sig_filtered = filtfilt(b, a, sig)\n",
    "\n",
    "    q = int(fs_raw / target_fs)\n",
    "    if q > 1:\n",
    "        sig_downsampled = decimate(sig_filtered, q)\n",
    "        real_fs = fs_raw / q\n",
    "    else:\n",
    "        sig_downsampled = sig_filtered\n",
    "        real_fs = fs_raw\n",
    "\n",
    "    return sig_downsampled, real_fs\n",
    "\n",
    "\n",
    "def compute_arpls_baselines(\n",
    "    baseline_fitter,\n",
    "    sig_f,\n",
    "    ref_f,\n",
    "    lam=1e9,\n",
    "    diff_order=2,\n",
    "    max_iter=50,\n",
    "    tol=1e-3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute arPLS baselines for signal and reference.\n",
    "\n",
    "    Parameters:\n",
    "        baseline_fitter: pybaselines.Baseline instance, already set up with x_data.\n",
    "        sig_f: 1D array-like, preprocessed signal channel.\n",
    "        ref_f: 1D array-like, preprocessed reference channel.\n",
    "        lam: smoothing parameter.\n",
    "        diff_order: difference order for the penalty.\n",
    "        max_iter: maximum iterations for arPLS.\n",
    "        tol: convergence tolerance.\n",
    "\n",
    "    Returns:\n",
    "        b_sig_arpls, b_ref_arpls\n",
    "    \"\"\"\n",
    "    b_sig_arpls, _ = baseline_fitter.arpls(\n",
    "        sig_f, lam=lam, diff_order=diff_order,\n",
    "        max_iter=max_iter, tol=tol\n",
    "    )\n",
    "    b_ref_arpls, _ = baseline_fitter.arpls(\n",
    "        ref_f, lam=lam, diff_order=diff_order,\n",
    "        max_iter=max_iter, tol=tol\n",
    "    )\n",
    "    return b_sig_arpls, b_ref_arpls\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def compute_motion_corrected_dff_robust(sig_f, ref_f, b_sig, b_ref):\n",
    "    \"\"\"\n",
    "    Computes motion-corrected dF/F using dF/F-first strategy and Robust Regression.\n",
    "    \"\"\"\n",
    "    # --- 1. Calculate raw dF/F for each channel ---\n",
    "    # Safe division\n",
    "    den_sig = np.asarray(b_sig, float).copy()\n",
    "    den_sig[np.abs(den_sig) < 1e-12] = np.nan\n",
    "    dff_sig_raw = (sig_f - b_sig) / den_sig\n",
    "\n",
    "    den_ref = np.asarray(b_ref, float).copy()\n",
    "    den_ref[np.abs(den_ref) < 1e-12] = np.nan\n",
    "    dff_ref_raw = (ref_f - b_ref) / den_ref\n",
    "\n",
    "    # Handle NaNs created by division (optional but recommended)\n",
    "    valid_mask = ~np.isnan(dff_sig_raw) & ~np.isnan(dff_ref_raw)\n",
    "\n",
    "    # --- 2. Fit Reference to Signal using Robust Linear Model (IRLS) ---\n",
    "    # Prepare data for statsmodels (needs constant for intercept)\n",
    "    X = dff_ref_raw[valid_mask]\n",
    "    Y = dff_sig_raw[valid_mask]\n",
    "    X_const = sm.add_constant(X)\n",
    "\n",
    "    # RLM with HuberT weighting reduces impact of calcium spikes\n",
    "    model = sm.RLM(Y, X_const, M=sm.robust.norms.HuberT())\n",
    "    results = model.fit()\n",
    "\n",
    "    b_fit, a_fit = results.params  # Intercept (b), Slope (a)\n",
    "\n",
    "    # --- 3. Subtract Fitted Reference ---\n",
    "    # fitted_ref = slope * ref + intercept\n",
    "    fitted_ref = a_fit * dff_ref_raw + b_fit\n",
    "    dff_mc = dff_sig_raw - fitted_ref\n",
    "\n",
    "    return {\n",
    "        \"sig_det\": dff_sig_raw,\n",
    "        \"ref_det\": dff_ref_raw,\n",
    "        \"a\": a_fit,\n",
    "        \"b\": b_fit,\n",
    "        \"dff\": dff_mc\n",
    "    }\n",
    "\n",
    "def list_doric_files(folder_path):\n",
    "    \"\"\"\n",
    "    Return a list of full paths to all .doric files in the given folder.\n",
    "    \"\"\"\n",
    "    doric_files = []\n",
    "    for fname in os.listdir(folder_path):\n",
    "        if fname.lower().endswith(\".doric\"):\n",
    "            doric_files.append(os.path.join(folder_path, fname))\n",
    "    return doric_files\n",
    "def list_labels_files(folder_path):\n",
    "    \"\"\"\n",
    "    Return a list of full paths to all .doric files in the given folder.\n",
    "    \"\"\"\n",
    "    doric_files = []\n",
    "    for fname in os.listdir(folder_path):\n",
    "        if fname.lower().endswith(\".csv\"):\n",
    "            doric_files.append(os.path.join(folder_path, fname))\n",
    "    return doric_files\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def qc_sig_ref_correlation(sig, ref, title=\"\", max_points=8000, ax=None):\n",
    "    \"\"\"\n",
    "    Scatter sig vs ref with OLS fit + Pearson R, R^2.\n",
    "    Downsamples points for plotting but computes stats on full data.\n",
    "    Returns dict with r, r2, slope, intercept, n.\n",
    "    \"\"\"\n",
    "    sig = np.asarray(sig, float)\n",
    "    ref = np.asarray(ref, float)\n",
    "\n",
    "    m = np.isfinite(sig) & np.isfinite(ref)\n",
    "    sig = sig[m]\n",
    "    ref = ref[m]\n",
    "    n = int(sig.size)\n",
    "\n",
    "    out = {\"r\": np.nan, \"r2\": np.nan, \"slope\": np.nan, \"intercept\": np.nan, \"n\": n}\n",
    "\n",
    "    if n < 10:\n",
    "        return out\n",
    "\n",
    "    # Pearson R\n",
    "    s0 = sig - np.mean(sig)\n",
    "    r0 = ref - np.mean(ref)\n",
    "    denom = np.sqrt(np.sum(s0**2) * np.sum(r0**2))\n",
    "    if denom > 0:\n",
    "        r = float(np.sum(s0 * r0) / denom)\n",
    "    else:\n",
    "        r = np.nan\n",
    "    out[\"r\"] = r\n",
    "    out[\"r2\"] = float(r**2) if np.isfinite(r) else np.nan\n",
    "\n",
    "    # OLS fit sig = a*ref + b\n",
    "    X = np.vstack([ref, np.ones_like(ref)]).T\n",
    "    coef, *_ = np.linalg.lstsq(X, sig, rcond=None)\n",
    "    a, b = float(coef[0]), float(coef[1])\n",
    "    out[\"slope\"] = a\n",
    "    out[\"intercept\"] = b\n",
    "\n",
    "    # Plot\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(4.2, 3.6))\n",
    "\n",
    "    # downsample points for display\n",
    "    if n > max_points:\n",
    "        idx = np.random.default_rng(0).choice(n, size=max_points, replace=False)\n",
    "        xs = ref[idx]\n",
    "        ys = sig[idx]\n",
    "    else:\n",
    "        xs, ys = ref, sig\n",
    "\n",
    "    ax.scatter(xs, ys, s=6, alpha=0.25, edgecolors=\"none\")\n",
    "\n",
    "    # fit line over displayed x-range\n",
    "    xlo, xhi = np.nanpercentile(ref, [1, 99])\n",
    "    xx = np.linspace(xlo, xhi, 200)\n",
    "    yy = a * xx + b\n",
    "    ax.plot(xx, yy, lw=1.8)\n",
    "\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    ax.set_xlabel(\"Reference 405 (a.u.)\")\n",
    "    ax.set_ylabel(\"Signal 465 (a.u.)\")\n",
    "\n",
    "    # cosmetics\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.grid(True, alpha=0.15)\n",
    "\n",
    "    ax.text(\n",
    "        0.02, 0.98,\n",
    "        f\"R = {out['r']:.3f}\\nR² = {out['r2']:.3f}\\na = {a:.3g}\",\n",
    "        transform=ax.transAxes, va=\"top\", ha=\"left\", fontsize=9\n",
    "    )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0727c4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Supposed extra functions (IDK they were nowhere to be found)\n",
    "def clean_velocity_data(beh_df):\n",
    "    \"\"\"\n",
    "    Clean the velocity data in the behavior dataframe.\n",
    "    If 'velocity' column exists, convert to numeric and interpolate NaNs.\n",
    "    \"\"\"\n",
    "    if 'velocity' in beh_df.columns:\n",
    "        # Convert to numeric, coercing errors to NaN\n",
    "        beh_df['velocity'] = pd.to_numeric(beh_df['velocity'], errors='coerce')\n",
    "        # Interpolate NaNs\n",
    "        beh_df['velocity'] = beh_df['velocity'].interpolate(method='linear')\n",
    "    return beh_df\n",
    "\n",
    "def _find_velocity_column(beh_df):\n",
    "    \"\"\"\n",
    "    Find the velocity column in the behavior dataframe.\n",
    "    \"\"\"\n",
    "    if 'velocity' in beh_df.columns:\n",
    "        # Check if it can be converted to numeric\n",
    "        try:\n",
    "            pd.to_numeric(beh_df['velocity'], errors='coerce')\n",
    "            return 'velocity'\n",
    "        except:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def _compute_event_locked_matrix(\n",
    "    t: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    event_times: np.ndarray,\n",
    "    window: Tuple[float, float],\n",
    "    resample_hz: float,\n",
    "    smooth_sigma_s: float = 0.0,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute event-locked matrix without baseline normalization (for velocity).\n",
    "    Returns:\n",
    "      tvec (relative time), mat (n_events x n_samples) with NaNs if missing\n",
    "    \"\"\"\n",
    "    t = np.asarray(t, float)\n",
    "    y = np.asarray(y, float)\n",
    "    ev = np.asarray(event_times, float)\n",
    "    ev = ev[np.isfinite(ev)]\n",
    "    if ev.size == 0:\n",
    "        return np.array([], float), np.zeros((0, 0), float)\n",
    "\n",
    "    dt = 1.0 / float(resample_hz)\n",
    "    tvec = np.arange(window[0], window[1] + 0.5 * dt, dt)\n",
    "\n",
    "    mat = np.full((ev.size, tvec.size), np.nan, float)\n",
    "\n",
    "    for i, et in enumerate(ev):\n",
    "        # extract window\n",
    "        wmask = (t >= et + window[0]) & (t <= et + window[1])\n",
    "        tw = t[wmask] - et\n",
    "        yw = y[wmask]\n",
    "        good = np.isfinite(tw) & np.isfinite(yw)\n",
    "        if np.sum(good) < 2:\n",
    "            continue\n",
    "        # interpolate onto tvec\n",
    "        mat[i, :] = np.interp(tvec, tw[good], yw[good])\n",
    "\n",
    "    if smooth_sigma_s and smooth_sigma_s > 0:\n",
    "        # gaussian smoothing along time axis\n",
    "        sigma = smooth_sigma_s * resample_hz\n",
    "        mat = gaussian_filter1d(mat, sigma=sigma, axis=1, mode=\"nearest\")\n",
    "\n",
    "    return tvec, mat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1831a43717d24a59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T20:26:27.304340Z",
     "start_time": "2025-12-19T20:26:27.300833Z"
    }
   },
   "outputs": [],
   "source": [
    "folder = r'/home/snap/Documents/UNIGE/Bellone_Lab/FP_in_DCN/test_data/EPM'\n",
    "doric_paths = list_doric_files(folder)\n",
    "labels_paths = list_labels_files(folder)\n",
    "print(doric_paths)\n",
    "print(labels_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f2eacc3b29f3440e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T20:26:27.347664Z",
     "start_time": "2025-12-19T20:26:27.330150Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_epm_labels(path):\n",
    "    \"\"\"\n",
    "    Robust EPM label reader:\n",
    "      - handles tab-separated\n",
    "      - handles decimal commas in 'time'\n",
    "    Expected columns: time, trigger, ttl, open, closed\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, sep=None, engine=\"python\", decimal=\",\")\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "    # required columns (case-insensitive)\n",
    "    required = {\"time\", \"ttl\", \"open\", \"closed\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"{os.path.basename(path)} missing columns: {missing}. Found: {list(df.columns)}\")\n",
    "\n",
    "    # force numeric\n",
    "    for c in [\"time\", \"ttl\", \"open\", \"closed\"]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # optional columns\n",
    "    if \"trigger\" in df.columns:\n",
    "        df[\"trigger\"] = pd.to_numeric(df[\"trigger\"], errors=\"coerce\")\n",
    "    else:\n",
    "        df[\"trigger\"] = np.nan\n",
    "\n",
    "    df = df.dropna(subset=[\"time\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def rising_edges(t, x, threshold=0.5, min_isi_s=0.4):\n",
    "    \"\"\"\n",
    "    Return rising-edge times (0->1 transitions) in x(t).\n",
    "    min_isi_s merges edges closer than this.\n",
    "    \"\"\"\n",
    "    t = np.asarray(t, float)\n",
    "    x = np.asarray(x, float)\n",
    "    m = np.isfinite(t) & np.isfinite(x)\n",
    "    t = t[m]\n",
    "    x = x[m]\n",
    "    if t.size < 3:\n",
    "        return np.array([], float)\n",
    "\n",
    "    b = x > threshold\n",
    "    db = np.diff(b.astype(int))\n",
    "    idx = np.where(db == 1)[0] + 1\n",
    "    edges = t[idx]\n",
    "\n",
    "    # merge close edges\n",
    "    if edges.size > 1 and min_isi_s is not None and min_isi_s > 0:\n",
    "        keep = [0]\n",
    "        for i in range(1, edges.size):\n",
    "            if (edges[i] - edges[keep[-1]]) >= float(min_isi_s):\n",
    "                keep.append(i)\n",
    "        edges = edges[keep]\n",
    "\n",
    "    return edges\n",
    "\n",
    "\n",
    "def fit_affine_time_map_from_edges(fiber_edges, video_edges, max_shift=6, min_pairs=6):\n",
    "    \"\"\"\n",
    "    Fit t_video ≈ a*t_fiber + b using rising edges.\n",
    "    Robust to extra pulses at start by scanning small index shifts.\n",
    "    Returns dict with a,b, rmse, n_pairs, shift_fiber, shift_video.\n",
    "    \"\"\"\n",
    "    fiber_edges = np.asarray(fiber_edges, float)\n",
    "    video_edges = np.asarray(video_edges, float)\n",
    "\n",
    "    best = None\n",
    "\n",
    "    if fiber_edges.size < min_pairs or video_edges.size < min_pairs:\n",
    "        return {\n",
    "            \"ok\": False, \"a\": np.nan, \"b\": np.nan, \"rmse\": np.nan,\n",
    "            \"n_pairs\": 0, \"shift_fiber\": 0, \"shift_video\": 0\n",
    "        }\n",
    "\n",
    "    # try aligning by trimming a few edges from either series\n",
    "    for sf in range(0, max_shift + 1):\n",
    "        for sv in range(0, max_shift + 1):\n",
    "            fe = fiber_edges[sf:]\n",
    "            ve = video_edges[sv:]\n",
    "            L = min(fe.size, ve.size)\n",
    "            if L < min_pairs:\n",
    "                continue\n",
    "\n",
    "            fe = fe[:L]\n",
    "            ve = ve[:L]\n",
    "\n",
    "            # linear fit ve = a*fe + b\n",
    "            a, b = np.polyfit(fe, ve, 1)\n",
    "            pred = a * fe + b\n",
    "            rmse = float(np.sqrt(np.nanmean((pred - ve) ** 2)))\n",
    "\n",
    "            cand = {\"a\": float(a), \"b\": float(b), \"rmse\": rmse, \"n_pairs\": int(L),\n",
    "                    \"shift_fiber\": int(sf), \"shift_video\": int(sv)}\n",
    "\n",
    "            if best is None or cand[\"rmse\"] < best[\"rmse\"]:\n",
    "                best = cand\n",
    "\n",
    "    if best is None:\n",
    "        return {\n",
    "            \"ok\": False, \"a\": np.nan, \"b\": np.nan, \"rmse\": np.nan,\n",
    "            \"n_pairs\": 0, \"shift_fiber\": 0, \"shift_video\": 0\n",
    "        }\n",
    "\n",
    "    best[\"ok\"] = True\n",
    "    return best\n",
    "\n",
    "\n",
    "def _binary_runs(time, binary_vec, thr=0.5):\n",
    "    \"\"\"\n",
    "    Return list of (t_start, t_end) for contiguous True runs.\n",
    "    \"\"\"\n",
    "    time = np.asarray(time, float)\n",
    "    b = np.asarray(binary_vec, float) > thr\n",
    "    if time.size == 0 or b.size == 0 or time.size != b.size:\n",
    "        return []\n",
    "\n",
    "    db = np.diff(b.astype(int))\n",
    "    starts = np.where(db == 1)[0] + 1\n",
    "    ends   = np.where(db == -1)[0] + 1\n",
    "\n",
    "    if b[0]:\n",
    "        starts = np.r_[0, starts]\n",
    "    if b[-1]:\n",
    "        ends = np.r_[ends, b.size]\n",
    "\n",
    "    runs = []\n",
    "    for s, e in zip(starts, ends):\n",
    "        t0 = float(time[s])\n",
    "        t1 = float(time[e-1]) if e-1 < time.size else float(time[-1])\n",
    "        runs.append((t0, t1))\n",
    "    return runs\n",
    "\n",
    "\n",
    "def plot_epm_aligned(beh_time, z_aligned, open_vec, closed_vec, *, title=\"\", xlim=None):\n",
    "    \"\"\"\n",
    "    Plot aligned Z-score with shaded open/closed epochs.\n",
    "    \"\"\"\n",
    "    beh_time = np.asarray(beh_time, float)\n",
    "    z_aligned = np.asarray(z_aligned, float)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    ax.plot(beh_time, z_aligned, lw=1.2, label=\"Fiber z-score (aligned)\")\n",
    "\n",
    "    # shade open/closed\n",
    "    open_runs = _binary_runs(beh_time, open_vec, thr=0.5)\n",
    "    closed_runs = _binary_runs(beh_time, closed_vec, thr=0.5)\n",
    "\n",
    "    for (t0, t1) in open_runs:\n",
    "        ax.axvspan(t0, t1, alpha=0.18, color=\"tab:green\", label=\"_open\")\n",
    "    for (t0, t1) in closed_runs:\n",
    "        ax.axvspan(t0, t1, alpha=0.18, color=\"tab:red\", label=\"_closed\")\n",
    "\n",
    "    # legend proxies (avoid duplicates)\n",
    "    handles = [\n",
    "        plt.Line2D([0],[0], color=\"k\", lw=1.2, label=\"Z-score\"),\n",
    "        plt.Line2D([0],[0], color=\"tab:green\", lw=8, alpha=0.18, label=\"Open arm\"),\n",
    "        plt.Line2D([0],[0], color=\"tab:red\", lw=8, alpha=0.18, label=\"Closed arm\"),\n",
    "    ]\n",
    "    ax.legend(handles=handles, frameon=False, loc=\"upper right\")\n",
    "\n",
    "    ax.set_title(title, fontsize=12)\n",
    "    ax.set_xlabel(\"Time (video, s)\")\n",
    "    ax.set_ylabel(\"Z\")\n",
    "    ax.grid(True, alpha=0.15)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d4a3c9a61518aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T20:26:30.432399Z",
     "start_time": "2025-12-19T20:26:27.357700Z"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Parameters\n",
    "# -----------------------------\n",
    "target_fs = 30\n",
    "lpf_cutoff = 3\n",
    "lam = 1e12\n",
    "diff_order = 2\n",
    "max_iter = 50\n",
    "tol = 1e-3\n",
    "\n",
    "# Artifact removal\n",
    "art_k = 8.0\n",
    "art_window_s = 1.0\n",
    "art_pad_s = 0.2\n",
    "art_union_channels = True\n",
    "art_use_derivative = False\n",
    "\n",
    "# Plot window (video-time after alignment)\n",
    "plot_window = [10, 100]   # set None for full\n",
    "# plot_window = None\n",
    "\n",
    "def apply_plot_window(t, *series, plot_window=None):\n",
    "    t = np.asarray(t, float)\n",
    "    if plot_window is None:\n",
    "        mask = np.ones_like(t, dtype=bool)\n",
    "        return (t, *series, mask)\n",
    "\n",
    "    lo, hi = float(plot_window[0]), float(plot_window[1])\n",
    "    if lo > hi:\n",
    "        lo, hi = hi, lo\n",
    "    mask = (t >= lo) & (t <= hi)\n",
    "    t2 = t[mask]\n",
    "    series2 = [np.asarray(s)[mask] if s is not None else None for s in series]\n",
    "    return (t2, *series2, mask)\n",
    "\n",
    "# -----------------------------\n",
    "# Map label files by animal\n",
    "# Adjust parsing here if your EMP csv filenames differ\n",
    "# -----------------------------\n",
    "label_by_animal = {}\n",
    "for lp in labels_paths:\n",
    "    base = os.path.splitext(os.path.basename(lp))[0]\n",
    "    # Common cases: \"030545\" or \"030545_EPM\" etc.\n",
    "    animal_id = base.split(\"_\")[0].split(\"-\")[0]\n",
    "    label_by_animal[animal_id] = lp\n",
    "\n",
    "# -----------------------------\n",
    "# Outputs\n",
    "# -----------------------------\n",
    "epm_result_list = []\n",
    "epm_align_qc = []  # TTL alignment quality per recording\n",
    "qc_list = []       # sig/ref QC if you keep it\n",
    "\n",
    "for path in doric_paths:\n",
    "    filename = os.path.basename(path)\n",
    "    file_name = os.path.splitext(filename)[0]\n",
    "    animal_id = file_name.split(\"_\")[0].split(\"-\")[0]\n",
    "    condition = \"EPM\"  # single condition\n",
    "\n",
    "    if animal_id not in label_by_animal:\n",
    "        print(f\"Skipping {animal_id}: no label csv found.\")\n",
    "        continue\n",
    "\n",
    "    label_path = label_by_animal[animal_id]\n",
    "    print(f\"Processing: {filename} | animal={animal_id} | labels={os.path.basename(label_path)}\")\n",
    "\n",
    "    # -------------------- Load photometry (with DIO02) --------------------\n",
    "    rec = load_doric(path, trigger_name=\"DIO02\")\n",
    "    t_raw = rec[\"time\"]\n",
    "    sig_raw = rec[\"sig465\"]\n",
    "    ref_raw = rec[\"ref405\"]\n",
    "    fs_raw = rec[\"fs\"]\n",
    "\n",
    "    dio_raw = rec.get(\"trig\", None)\n",
    "    dio_time = rec.get(\"trig_time\", None)\n",
    "\n",
    "    # -------------------- Artifact removal FIRST --------------------\n",
    "    art = remove_artifacts_adaptive_mad(\n",
    "        t_raw, sig_raw, ref_raw, fs_raw,\n",
    "        k=art_k, window_s=art_window_s, pad_s=art_pad_s,\n",
    "        union_channels=art_union_channels,\n",
    "        use_derivative=art_use_derivative\n",
    "    )\n",
    "\n",
    "    sig = art[\"sig465_clean\"]\n",
    "    ref = art[\"ref405_clean\"]\n",
    "    t_raw = art[\"time\"]\n",
    "    fs = art[\"fs\"]\n",
    "\n",
    "    # -------------------- Preprocess & downsample --------------------\n",
    "    sig_f, fs_sig = preprocess_signal(sig, fs, target_fs=target_fs, lpf_cutoff=lpf_cutoff)\n",
    "    ref_f, fs_ref = preprocess_signal(ref, fs, target_fs=target_fs, lpf_cutoff=lpf_cutoff)\n",
    "\n",
    "    # QC scatter (optional)\n",
    "    qc_title = f\"{animal_id} | {condition} | sig_f vs ref_f\"\n",
    "    fig_qc, ax_qc = plt.subplots(figsize=(4.6, 3.8))\n",
    "    qc = qc_sig_ref_correlation(sig_f, ref_f, title=qc_title, ax=ax_qc)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    qc.update({\n",
    "        \"animal\": animal_id,\n",
    "        \"condition\": condition,\n",
    "        \"file\": filename,\n",
    "        \"artifact_fraction\": float(np.mean(art[\"artifact_mask\"])) if art[\"artifact_mask\"].size else 0.0,\n",
    "        \"fs_used\": float(fs_sig),\n",
    "        \"sig_std\": float(np.nanstd(sig_f)),\n",
    "        \"ref_std\": float(np.nanstd(ref_f)),\n",
    "    })\n",
    "    qc_list.append(qc)\n",
    "\n",
    "    # photometry time after decimation\n",
    "    dt_ds = 1.0 / fs_sig\n",
    "    t_ds = np.arange(sig_f.size) * dt_ds\n",
    "\n",
    "    # baseline + dff\n",
    "    baseline_fitter = Baseline(x_data=t_ds)\n",
    "    b_sig, b_ref = compute_arpls_baselines(\n",
    "        baseline_fitter, sig_f, ref_f,\n",
    "        lam=lam, diff_order=diff_order, max_iter=max_iter, tol=tol\n",
    "    )\n",
    "    dff_results = compute_motion_corrected_dff_robust(sig_f, ref_f, b_sig, b_ref)\n",
    "    dff_mc = dff_results[\"dff\"]\n",
    "    dff_z = (dff_mc - np.nanmean(dff_mc)) / np.nanstd(dff_mc)\n",
    "\n",
    "    # resample DIO to t_ds\n",
    "    if dio_raw is not None and dio_time is not None and np.size(dio_raw) and np.size(dio_time):\n",
    "        dio_ds = np.interp(t_ds, dio_time, np.asarray(dio_raw, float))\n",
    "    else:\n",
    "        dio_ds = np.zeros_like(t_ds)\n",
    "\n",
    "    # -------------------- Load EPM labels --------------------\n",
    "    beh = read_epm_labels(label_path)\n",
    "    beh_time = beh[\"time\"].to_numpy(dtype=float)\n",
    "    ttl_video = beh[\"ttl\"].to_numpy(dtype=float)\n",
    "    open_vec = beh[\"open\"].to_numpy(dtype=float)\n",
    "    closed_vec = beh[\"closed\"].to_numpy(dtype=float)\n",
    "\n",
    "    # -------------------- TTL alignment (video ttl vs photometry dio2) --------------------\n",
    "    video_edges = rising_edges(beh_time, ttl_video, threshold=0.5, min_isi_s=0.4)\n",
    "    fiber_edges = rising_edges(t_ds, dio_ds, threshold=0.5, min_isi_s=0.4)\n",
    "\n",
    "    align = fit_affine_time_map_from_edges(\n",
    "        fiber_edges, video_edges,\n",
    "        max_shift=8, min_pairs=6\n",
    "    )\n",
    "\n",
    "    if not align[\"ok\"]:\n",
    "        print(f\"  Alignment failed for {animal_id}. Edges: fiber={fiber_edges.size}, video={video_edges.size}\")\n",
    "        continue\n",
    "\n",
    "    # map fiber time -> video time\n",
    "    a, b = align[\"a\"], align[\"b\"]\n",
    "    t_ds_video = a * t_ds + b\n",
    "\n",
    "    # interpolate zscore onto video time vector (behavior sampling)\n",
    "    # (fiber defined on t_ds_video, want z at beh_time)\n",
    "    m = np.isfinite(t_ds_video) & np.isfinite(dff_z)\n",
    "    t_map = t_ds_video[m]\n",
    "    z_map = dff_z[m]\n",
    "    # ensure monotonic for interp\n",
    "    order = np.argsort(t_map)\n",
    "    t_map = t_map[order]\n",
    "    z_map = z_map[order]\n",
    "\n",
    "    z_aligned = np.interp(beh_time, t_map, z_map, left=np.nan, right=np.nan)\n",
    "    beh = beh.copy()\n",
    "    beh[\"fiber_zscore_aligned\"] = z_aligned\n",
    "\n",
    "    # alignment QC: edge RMSE on matched pulses\n",
    "    epm_align_qc.append({\n",
    "        \"animal\": animal_id,\n",
    "        \"file\": filename,\n",
    "        \"label_file\": os.path.basename(label_path),\n",
    "        \"a\": float(a),\n",
    "        \"b\": float(b),\n",
    "        \"rmse_s\": float(align[\"rmse\"]),\n",
    "        \"n_pairs\": int(align[\"n_pairs\"]),\n",
    "        \"shift_fiber\": int(align[\"shift_fiber\"]),\n",
    "        \"shift_video\": int(align[\"shift_video\"]),\n",
    "        \"n_edges_fiber\": int(fiber_edges.size),\n",
    "        \"n_edges_video\": int(video_edges.size),\n",
    "    })\n",
    "\n",
    "    # -------------------- Store results for later analysis --------------------\n",
    "    out = {\n",
    "        \"animal\": animal_id,\n",
    "        \"condition\": condition,\n",
    "        # photometry\n",
    "        \"t_fiber\": t_ds,\n",
    "        \"t_fiber_in_video\": t_ds_video,\n",
    "        \"dff\": dff_mc,\n",
    "        \"zscore\": dff_z,\n",
    "        \"dio2\": dio_ds,\n",
    "        \"artifact_regions_s\": art[\"artifact_regions_s\"],\n",
    "        \"artifact_fraction\": float(np.mean(art[\"artifact_mask\"])) if art[\"artifact_mask\"].size else 0.0,\n",
    "        # behavior (video timebase)\n",
    "        \"behavior\": beh,   # includes open/closed/ttl/trigger + fiber_zscore_aligned\n",
    "        # time alignment params\n",
    "        \"ttl_align\": {\n",
    "            \"a\": float(a),\n",
    "            \"b\": float(b),\n",
    "            \"rmse_s\": float(align[\"rmse\"]),\n",
    "            \"n_pairs\": int(align[\"n_pairs\"]),\n",
    "            \"shift_fiber\": int(align[\"shift_fiber\"]),\n",
    "            \"shift_video\": int(align[\"shift_video\"]),\n",
    "            \"fiber_edges_s\": fiber_edges,\n",
    "            \"video_edges_s\": video_edges,\n",
    "        }\n",
    "    }\n",
    "    epm_result_list.append(out)\n",
    "\n",
    "    # -------------------- Plot (Z-score + open/closed shading) --------------------\n",
    "    t_plot, z_plot, open_plot, closed_plot, _ = apply_plot_window(\n",
    "        beh_time, z_aligned, open_vec, closed_vec, plot_window=plot_window\n",
    "    )\n",
    "\n",
    "    plot_epm_aligned(\n",
    "        t_plot, z_plot, open_plot, closed_plot,\n",
    "        title=f\"{animal_id} — EPM | TTL-align rmse={align['rmse']:.3f}s (n={align['n_pairs']})\",\n",
    "        xlim=None\n",
    "    )\n",
    "\n",
    "print(f\"Done. Stored EPM results for {len(epm_result_list)} recordings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c391089ddfdc2313",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T20:26:31.152762Z",
     "start_time": "2025-12-19T20:26:31.142706Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def _compute_psth_matrix(\n",
    "    t: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    event_times: np.ndarray,\n",
    "    window: Tuple[float, float],\n",
    "    baseline_win: Tuple[float, float],\n",
    "    resample_hz: float,\n",
    "    smooth_sigma_s: float = 0.0,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      tvec (relative time), mat (n_events x n_samples) with NaNs if missing\n",
    "    \"\"\"\n",
    "    t = np.asarray(t, float)\n",
    "    y = np.asarray(y, float)\n",
    "    ev = np.asarray(event_times, float)\n",
    "    ev = ev[np.isfinite(ev)]\n",
    "    if ev.size == 0:\n",
    "        return np.array([], float), np.zeros((0, 0), float)\n",
    "\n",
    "    dt = 1.0 / float(resample_hz)\n",
    "    tvec = np.arange(window[0], window[1] + 0.5 * dt, dt)\n",
    "\n",
    "    mat = np.full((ev.size, tvec.size), np.nan, float)\n",
    "\n",
    "    for i, et in enumerate(ev):\n",
    "        # baseline\n",
    "        bmask = (t >= et + baseline_win[0]) & (t <= et + baseline_win[1])\n",
    "        base = y[bmask]\n",
    "        if base.size < 5 or not np.any(np.isfinite(base)):\n",
    "            continue\n",
    "        bmean = np.nanmean(base)\n",
    "        bstd = np.nanstd(base)\n",
    "        if not np.isfinite(bstd) or bstd <= 1e-12:\n",
    "            bstd = 1.0\n",
    "\n",
    "        # extract window and interpolate onto tvec\n",
    "        wmask = (t >= et + window[0]) & (t <= et + window[1])\n",
    "        tw = t[wmask] - et\n",
    "        yw = y[wmask]\n",
    "        good = np.isfinite(tw) & np.isfinite(yw)\n",
    "        if np.sum(good) < 5:\n",
    "            continue\n",
    "        # sparse interpolation\n",
    "        mat[i, :] = np.interp(tvec, tw[good], (yw[good] - bmean) / bstd)\n",
    "\n",
    "    if smooth_sigma_s and smooth_sigma_s > 0:\n",
    "        # simple gaussian smoothing along time axis\n",
    "        sigma = smooth_sigma_s * resample_hz\n",
    "        mat = gaussian_filter1d(mat, sigma=sigma, axis=1, mode=\"nearest\")\n",
    "\n",
    "    return tvec, mat\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d3c0c010c4dd2e29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T20:26:31.186658Z",
     "start_time": "2025-12-19T20:26:31.159773Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def extract_transition_events_epm(\n",
    "    beh_df,\n",
    "    thr=0.5,\n",
    "    drop_first=True,\n",
    "    min_state_dur_s=None,\n",
    "    drop_unpaired=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract transition events from EPM behavior vectors, with optional filtering of\n",
    "    short state bouts by duration.\n",
    "\n",
    "    Returns dict:\n",
    "      {\n",
    "        \"open_entry\":   np.ndarray of times (s),\n",
    "        \"open_exit\":    np.ndarray of times (s),\n",
    "        \"closed_entry\": np.ndarray of times (s),\n",
    "        \"closed_exit\":  np.ndarray of times (s),\n",
    "      }\n",
    "\n",
    "    Definitions (based on binary state):\n",
    "      open_entry   = open rises (0->1)   = closed falls (1->0)\n",
    "      open_exit    = open falls (1->0)   = closed rises (0->1)\n",
    "      closed_entry = closed rises (0->1) = open falls (1->0)\n",
    "      closed_exit  = closed falls (1->0) = open rises (0->1)\n",
    "\n",
    "    Optional bout-duration filtering:\n",
    "      - If min_state_dur_s is not None, events defining a bout shorter than\n",
    "        min_state_dur_s seconds are removed.\n",
    "        * open bouts:  (open_entry -> next open_exit)\n",
    "        * closed bouts:(open_exit  -> next open_entry)\n",
    "      - If drop_unpaired is True, events without a subsequent corresponding transition\n",
    "        (e.g., last open_entry with no later open_exit) are dropped when filtering.\n",
    "\n",
    "    Notes:\n",
    "      - Filtering is performed using the 'open' transitions primarily, then mirrored\n",
    "        to 'closed' to maintain symmetry.\n",
    "    \"\"\"\n",
    "    if \"time\" not in beh_df.columns or \"open\" not in beh_df.columns or \"closed\" not in beh_df.columns:\n",
    "        raise ValueError(\"beh_df must contain columns: time, open, closed\")\n",
    "\n",
    "    t = beh_df[\"time\"].to_numpy(dtype=float)\n",
    "    openv = beh_df[\"open\"].to_numpy(dtype=float)\n",
    "    closedv = beh_df[\"closed\"].to_numpy(dtype=float)\n",
    "\n",
    "    good = np.isfinite(t) & np.isfinite(openv) & np.isfinite(closedv)\n",
    "    t = t[good]\n",
    "    openv = openv[good]\n",
    "    closedv = closedv[good]\n",
    "\n",
    "    # Binarize\n",
    "    o = openv > thr\n",
    "    c = closedv > thr\n",
    "\n",
    "    # Transitions from open\n",
    "    do = np.diff(o.astype(int))\n",
    "    open_entry_idx = np.where(do == 1)[0] + 1   # 0->1\n",
    "    open_exit_idx  = np.where(do == -1)[0] + 1  # 1->0\n",
    "\n",
    "    open_entry = t[open_entry_idx]\n",
    "    open_exit  = t[open_exit_idx]\n",
    "\n",
    "    # Transitions from closed (for symmetry)\n",
    "    dc = np.diff(c.astype(int))\n",
    "    closed_entry_idx = np.where(dc == 1)[0] + 1\n",
    "    closed_exit_idx  = np.where(dc == -1)[0] + 1\n",
    "\n",
    "    closed_entry = t[closed_entry_idx]\n",
    "    closed_exit  = t[closed_exit_idx]\n",
    "\n",
    "    # Optional: drop first event of each type\n",
    "    if drop_first:\n",
    "        if open_entry.size:  open_entry  = open_entry[1:]\n",
    "        if open_exit.size:   open_exit   = open_exit[1:]\n",
    "        if closed_entry.size:closed_entry= closed_entry[1:]\n",
    "        if closed_exit.size: closed_exit = closed_exit[1:]\n",
    "\n",
    "    # Optional: filter out short bouts using open transitions\n",
    "    if min_state_dur_s is not None:\n",
    "        min_state_dur_s = float(min_state_dur_s)\n",
    "\n",
    "        def _forward_duration(a, b):\n",
    "            \"\"\"Duration from each time in a to the next strictly later time in b.\"\"\"\n",
    "            a = np.asarray(a, float)\n",
    "            b = np.asarray(b, float)\n",
    "            dur = np.full(a.shape, np.nan, dtype=float)\n",
    "            if a.size == 0 or b.size == 0:\n",
    "                return dur\n",
    "            idx = np.searchsorted(b, a, side=\"right\")\n",
    "            ok = idx < b.size\n",
    "            dur[ok] = b[idx[ok]] - a[ok]\n",
    "            return dur\n",
    "\n",
    "        # open-bout durations: entry -> next exit\n",
    "        d_open = _forward_duration(open_entry, open_exit)\n",
    "        # closed-bout durations: exit -> next entry\n",
    "        d_closed = _forward_duration(open_exit, open_entry)\n",
    "\n",
    "        keep_open_entry = np.isfinite(d_open) & (d_open >= min_state_dur_s)\n",
    "        keep_open_exit  = np.isfinite(d_closed) & (d_closed >= min_state_dur_s)\n",
    "\n",
    "        if not drop_unpaired:\n",
    "            # If not dropping unpaired, keep NaNs (unpaired) in addition to passing durations\n",
    "            keep_open_entry = (~np.isfinite(d_open)) | keep_open_entry\n",
    "            keep_open_exit  = (~np.isfinite(d_closed)) | keep_open_exit\n",
    "\n",
    "        open_entry_f = open_entry[keep_open_entry]\n",
    "        open_exit_f  = open_exit[keep_open_exit]\n",
    "\n",
    "        # Mirror to closed events for symmetry:\n",
    "        # open_entry == closed_exit ; open_exit == closed_entry (in ideal data)\n",
    "        # We'll filter closed_exit using the same mask as open_entry, and closed_entry using open_exit mask.\n",
    "        # Because arrays may differ slightly in real data, use time-based intersection instead of index masks.\n",
    "        open_entry_set = set(np.round(open_entry_f, 6))\n",
    "        open_exit_set  = set(np.round(open_exit_f, 6))\n",
    "\n",
    "        closed_exit_f  = np.array([x for x in closed_exit  if np.round(x, 6) in open_entry_set], dtype=float)\n",
    "        closed_entry_f = np.array([x for x in closed_entry if np.round(x, 6) in open_exit_set],  dtype=float)\n",
    "\n",
    "        # Replace\n",
    "        open_entry, open_exit = open_entry_f, open_exit_f\n",
    "        closed_entry, closed_exit = closed_entry_f, closed_exit_f\n",
    "\n",
    "    return {\n",
    "        \"open_entry\": open_entry,\n",
    "        \"open_exit\": open_exit,\n",
    "        \"closed_entry\": closed_entry,\n",
    "        \"closed_exit\": closed_exit,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def plot_psth_heatmap_and_mean(tvec, mat, title=\"\", vmin=-3, vmax=3, cmap=\"viridis\"):\n",
    "    \"\"\"\n",
    "    Standard: heatmap over trials + mean±SEM underneath, aligned at 0.\n",
    "    \"\"\"\n",
    "    if mat.size == 0 or tvec.size == 0:\n",
    "        fig, ax = plt.subplots(figsize=(7, 2.0))\n",
    "        ax.axis(\"off\")\n",
    "        ax.text(0.02, 0.5, f\"{title}\\n(no valid trials)\", transform=ax.transAxes, va=\"center\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "    mat = mat[~np.isnan(mat).all(axis=1)]\n",
    "    if mat.shape[0] == 0:\n",
    "        fig, ax = plt.subplots(figsize=(7, 2.0))\n",
    "        ax.axis(\"off\")\n",
    "        ax.text(0.02, 0.5, f\"{title}\\n(no valid trials after bounds)\", transform=ax.transAxes, va=\"center\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "    mean_trace = np.nanmean(mat, axis=0)\n",
    "    sem_trace = np.nanstd(mat, axis=0) / np.sqrt(mat.shape[0])\n",
    "\n",
    "    fig, (ax_hm, ax_mu) = plt.subplots(\n",
    "        2, 1, figsize=(8.5, 6.5), sharex=True,\n",
    "        gridspec_kw={\"height_ratios\": [2.2, 1.0], \"hspace\": 0.08}\n",
    "    )\n",
    "\n",
    "    im = ax_hm.imshow(\n",
    "        mat,\n",
    "        aspect=\"auto\",\n",
    "        origin=\"lower\",\n",
    "        extent=[tvec[0], tvec[-1], 0, mat.shape[0]],\n",
    "        cmap=cmap,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        interpolation=\"nearest\"\n",
    "    )\n",
    "    ax_hm.axvline(0, color=\"w\", linestyle=\"--\", lw=1, alpha=0.9)\n",
    "    ax_hm.set_ylabel(\"Trial\")\n",
    "    ax_hm.set_title(f\"{title}  (n={mat.shape[0]})\", fontsize=11)\n",
    "    ax_hm.spines[\"top\"].set_visible(False)\n",
    "    ax_hm.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    cbar = fig.colorbar(im, ax=ax_hm, fraction=0.04, pad=0.02)\n",
    "    cbar.set_label(\"Z\", rotation=90)\n",
    "\n",
    "    ax_mu.plot(tvec, mean_trace, lw=2.0, color=\"k\")\n",
    "    ax_mu.fill_between(tvec, mean_trace - sem_trace, mean_trace + sem_trace, color=\"k\", alpha=0.2, linewidth=0)\n",
    "    ax_mu.axvline(0, color=\"r\", linestyle=\"--\", lw=1, alpha=0.85)\n",
    "    ax_mu.axhline(0, color=\"gray\", linestyle=\":\", lw=1, alpha=0.6)\n",
    "    ax_mu.set_xlabel(\"Time from event (s)\")\n",
    "    ax_mu.set_ylabel(\"Z\")\n",
    "    ax_mu.grid(True, alpha=0.15)\n",
    "    ax_mu.spines[\"top\"].set_visible(False)\n",
    "    ax_mu.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7414885f6ef2f14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T20:26:32.384150Z",
     "start_time": "2025-12-19T20:26:31.193608Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d  # needed by _compute_psth_matrix\n",
    "\n",
    "# -----------------------------\n",
    "# PSTH parameters\n",
    "# -----------------------------\n",
    "window = (-3, 10)\n",
    "baseline_win = (-3, -1)\n",
    "resample_hz = 30.0       # use 30 Hz (matches your target_fs and is clean for EPM)\n",
    "smooth_sigma_s = 0.10\n",
    "\n",
    "min_trials = 2\n",
    "vmin, vmax = -3, 3\n",
    "cmap = \"viridis\"\n",
    "\n",
    "# Store psth outputs for later analysis\n",
    "epm_psth_results = {}\n",
    "# structure:\n",
    "# epm_psth_results[animal_id][event_name] = {tvec, mat, mean, sem, n_trials, event_times}\n",
    "\n",
    "# iterate per recording in epm_result_list\n",
    "for rec in epm_result_list:\n",
    "    animal_id = rec[\"animal\"]\n",
    "    beh = rec[\"behavior\"]\n",
    "\n",
    "    if \"fiber_zscore_aligned\" not in beh.columns:\n",
    "        print(f\"{animal_id}: missing fiber_zscore_aligned; skipping\")\n",
    "        continue\n",
    "\n",
    "    t = beh[\"time\"].to_numpy(dtype=float)\n",
    "    y = beh[\"fiber_zscore_aligned\"].to_numpy(dtype=float)\n",
    "\n",
    "    # extract transition events (drop first event as requested)\n",
    "    ev = extract_transition_events_epm(beh, thr=0.5, drop_first=True, min_state_dur_s=1)\n",
    "\n",
    "    # init container\n",
    "    if animal_id not in epm_psth_results:\n",
    "        epm_psth_results[animal_id] = {}\n",
    "\n",
    "    # plot 4 event types for this animal\n",
    "    for event_name in [\"open_entry\", \"open_exit\", \"closed_entry\", \"closed_exit\"]:\n",
    "        event_times = ev[event_name]\n",
    "        if event_times.size < min_trials:\n",
    "            # store empty\n",
    "            epm_psth_results[animal_id][event_name] = {\n",
    "                \"tvec\": np.array([], float),\n",
    "                \"mat\": np.zeros((0, 0), float),\n",
    "                \"mean\": np.array([], float),\n",
    "                \"sem\": np.array([], float),\n",
    "                \"n_trials\": 0,\n",
    "                \"event_times\": event_times,\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        tvec, mat = _compute_psth_matrix(\n",
    "            t=t,\n",
    "            y=y,\n",
    "            event_times=event_times,\n",
    "            window=window,\n",
    "            baseline_win=baseline_win,\n",
    "            resample_hz=resample_hz,\n",
    "            smooth_sigma_s=smooth_sigma_s,\n",
    "        )\n",
    "\n",
    "        # drop all-NaN trials (bounds)\n",
    "        mat = mat[~np.isnan(mat).all(axis=1)]\n",
    "        n_trials = mat.shape[0]\n",
    "\n",
    "        if n_trials < min_trials:\n",
    "            epm_psth_results[animal_id][event_name] = {\n",
    "                \"tvec\": tvec,\n",
    "                \"mat\": mat,\n",
    "                \"mean\": np.nanmean(mat, axis=0) if n_trials else np.array([], float),\n",
    "                \"sem\": (np.nanstd(mat, axis=0) / np.sqrt(n_trials)) if n_trials else np.array([], float),\n",
    "                \"n_trials\": n_trials,\n",
    "                \"event_times\": event_times,\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        mean_trace = np.nanmean(mat, axis=0)\n",
    "        sem_trace = np.nanstd(mat, axis=0) / np.sqrt(n_trials)\n",
    "\n",
    "        epm_psth_results[animal_id][event_name] = {\n",
    "            \"tvec\": tvec,\n",
    "            \"mat\": mat,\n",
    "            \"mean\": mean_trace,\n",
    "            \"sem\": sem_trace,\n",
    "            \"n_trials\": n_trials,\n",
    "            \"event_times\": event_times,\n",
    "        }\n",
    "\n",
    "        # Plot\n",
    "        plot_psth_heatmap_and_mean(\n",
    "            tvec, mat,\n",
    "            title=f\"{animal_id} — {event_name}\",\n",
    "            vmin=vmin, vmax=vmax, cmap=cmap\n",
    "        )\n",
    "\n",
    "print(f\"Done. PSTHs stored in epm_psth_results for {len(epm_psth_results)} animals.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde2c855bfebce34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T20:26:33.214238Z",
     "start_time": "2025-12-19T20:26:32.613707Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _find_velocity_column(beh_df):\n",
    "    \"\"\"\n",
    "    Tries common velocity/speed column names. Returns column name or None.\n",
    "    \"\"\"\n",
    "    candidates = [\"velocity\", \"vel\", \"speed\", \"locomotion_speed\", \"cm_s\", \"v\"]\n",
    "    for c in candidates:\n",
    "        if c in beh_df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def clean_velocity_data(beh_df):\n",
    "    \"\"\"\n",
    "    Finds the velocity column, converts '-' to NaN, ensures numeric type,\n",
    "    and fills missing values with the mean.\n",
    "    \"\"\"\n",
    "    col = _find_velocity_column(beh_df)\n",
    "\n",
    "    if col is not None:\n",
    "        # 1. Replace '-' with NaN explicitly\n",
    "        # (Use regex=False to ensure we match the string literal '-')\n",
    "        beh_df[col] = beh_df[col].replace('-', np.nan)\n",
    "\n",
    "        # 2. Convert to numeric, coercing errors (like empty strings or other text) to NaN\n",
    "        beh_df[col] = pd.to_numeric(beh_df[col], errors='coerce')\n",
    "\n",
    "        # 3. Calculate mean of valid values\n",
    "        mean_val = beh_df[col].mean()\n",
    "\n",
    "        # 4. Fill NaNs with the mean (default to 0.0 if column is entirely empty/NaN)\n",
    "        if pd.isna(mean_val):\n",
    "            mean_val = 0.0\n",
    "\n",
    "        beh_df[col] = beh_df[col].fillna(mean_val)\n",
    "\n",
    "    return beh_df\n",
    "\n",
    "def compute_forward_durations(event_times, next_event_times):\n",
    "    \"\"\"\n",
    "    For each event time, compute duration to the next event of another type.\n",
    "    duration[i] = next_event_times[first index with next_event_times > event_times[i]] - event_times[i]\n",
    "    Returns NaN if no subsequent event exists.\n",
    "    \"\"\"\n",
    "    event_times = np.asarray(event_times, float)\n",
    "    next_event_times = np.asarray(next_event_times, float)\n",
    "\n",
    "    dur = np.full(event_times.shape, np.nan, dtype=float)\n",
    "    if event_times.size == 0 or next_event_times.size == 0:\n",
    "        return dur\n",
    "\n",
    "    # next strictly greater event\n",
    "    idx = np.searchsorted(next_event_times, event_times, side=\"right\")\n",
    "    ok = idx < next_event_times.size\n",
    "    dur[ok] = next_event_times[idx[ok]] - event_times[ok]\n",
    "    return dur\n",
    "\n",
    "\n",
    "def _sort_trials_by_duration(mat, durations, vel_mat=None):\n",
    "    \"\"\"\n",
    "    Sort rows (trials) by duration (ascending): shortest at bottom (origin='lower'), longest at top.\n",
    "    Keeps matrices aligned; drops trials with NaN duration or all-NaN row.\n",
    "    \"\"\"\n",
    "    if mat is None or mat.size == 0:\n",
    "        return mat, durations, vel_mat\n",
    "\n",
    "    mat = np.asarray(mat, float)\n",
    "    durations = None if durations is None else np.asarray(durations, float)\n",
    "\n",
    "    # drop all-NaN rows\n",
    "    keep = ~np.isnan(mat).all(axis=1)\n",
    "\n",
    "    if durations is not None:\n",
    "        keep = keep & np.isfinite(durations)\n",
    "\n",
    "    mat = mat[keep]\n",
    "    if durations is not None:\n",
    "        durations = durations[keep]\n",
    "    if vel_mat is not None and getattr(vel_mat, \"size\", 0):\n",
    "        vel_mat = vel_mat[keep]\n",
    "\n",
    "    if durations is not None and mat.shape[0] > 1:\n",
    "        order = np.argsort(durations)  # ascending\n",
    "        mat = mat[order]\n",
    "        durations = durations[order]\n",
    "        if vel_mat is not None and getattr(vel_mat, \"size\", 0):\n",
    "            vel_mat = vel_mat[order]\n",
    "\n",
    "    return mat, durations, vel_mat\n",
    "def plot_open_entry_exit_column_with_velocity(\n",
    "    tvec,\n",
    "    mat_entry,\n",
    "    mat_exit,\n",
    "    title_prefix=\"\",\n",
    "    vmin=-3, vmax=3, cmap=\"viridis\",\n",
    "    vel_tvec=None,\n",
    "    vel_mat_entry=None,\n",
    "    vel_mat_exit=None,\n",
    "    vel_color=\"tab:blue\",\n",
    "    vel_alpha=0.35,\n",
    "    # NEW: durations used to order heatmap trials\n",
    "    dur_entry=None,\n",
    "    dur_exit=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    2x2 layout:\n",
    "      Row 0: heatmaps (entry | exit) ordered by duration if provided\n",
    "      Row 1: mean±SEM (entry | exit), with velocity overlay on twinx if provided\n",
    "    \"\"\"\n",
    "\n",
    "    # sort trials by duration (also drops NaN-duration trials)\n",
    "    # mat_entry, dur_entry, vel_mat_entry = _sort_trials_by_duration(mat_entry, dur_entry, vel_mat_entry)\n",
    "    # mat_exit,  dur_exit,  vel_mat_exit  = _sort_trials_by_duration(mat_exit,  dur_exit,  vel_mat_exit)\n",
    "\n",
    "    if (mat_entry is None or mat_entry.shape[0] == 0) and (mat_exit is None or mat_exit.shape[0] == 0):\n",
    "        fig, ax = plt.subplots(figsize=(8, 2.0))\n",
    "        ax.axis(\"off\")\n",
    "        ax.text(0.02, 0.5, f\"{title_prefix}\\n(no valid trials)\", transform=ax.transAxes, va=\"center\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        2, 2, figsize=(14, 6.5), sharex=True,\n",
    "        gridspec_kw={\"height_ratios\": [2.2, 1.0], \"hspace\": 0.08, \"wspace\": 0.12}\n",
    "    )\n",
    "    (ax_hm_e, ax_hm_x), (ax_mu_e, ax_mu_x) = axs\n",
    "\n",
    "    # --- Heatmaps ---\n",
    "    def _plot_hm(ax, mat, label, durations):\n",
    "        if mat is None or mat.shape[0] == 0:\n",
    "            ax.axis(\"off\")\n",
    "            ax.text(0.02, 0.5, f\"{label}\\n(no valid trials)\", transform=ax.transAxes, va=\"center\")\n",
    "            return None\n",
    "\n",
    "        im = ax.imshow(\n",
    "            mat, aspect=\"auto\", origin=\"lower\",\n",
    "            extent=[tvec[0], tvec[-1], 0, mat.shape[0]],\n",
    "            cmap=cmap, vmin=vmin, vmax=vmax, interpolation=\"nearest\"\n",
    "        )\n",
    "        ax.axvline(0, color=\"w\", linestyle=\"--\", lw=1, alpha=0.9)\n",
    "        ax.set_ylabel(\"Trial (sorted by duration)\")\n",
    "        if durations is not None and durations.size:\n",
    "            ax.set_title(\n",
    "                f\"{label} (n={mat.shape[0]}; median dur={np.nanmedian(durations):.2f}s)\",\n",
    "                fontsize=11\n",
    "            )\n",
    "        else:\n",
    "            ax.set_title(f\"{label} (n={mat.shape[0]})\", fontsize=11)\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        return im\n",
    "\n",
    "    im1 = _plot_hm(ax_hm_e, mat_entry, f\"{title_prefix} — open_entry\", dur_entry)\n",
    "    im2 = _plot_hm(ax_hm_x, mat_exit,  f\"{title_prefix} — open_exit\",  dur_exit)\n",
    "\n",
    "    ims = [im for im in (im1, im2) if im is not None]\n",
    "    if len(ims) > 0:\n",
    "        cbar = fig.colorbar(ims[0], ax=[ax_hm_e, ax_hm_x], fraction=0.025, pad=0.02)\n",
    "        cbar.set_label(\"Z\", rotation=90)\n",
    "\n",
    "    # --- Means + velocity overlay ---\n",
    "    def _plot_mean(ax, mat, vel_mat, label):\n",
    "        if mat is None or mat.shape[0] == 0:\n",
    "            ax.axis(\"off\")\n",
    "            ax.text(0.02, 0.5, f\"{label}\\n(no valid trials)\", transform=ax.transAxes, va=\"center\")\n",
    "            return\n",
    "\n",
    "        mean_trace = np.nanmean(mat, axis=0)\n",
    "        sem_trace  = np.nanstd(mat, axis=0) / np.sqrt(mat.shape[0])\n",
    "\n",
    "        ax.plot(tvec, mean_trace, lw=2.0, color=\"k\")\n",
    "        ax.fill_between(tvec, mean_trace - sem_trace, mean_trace + sem_trace,\n",
    "                        color=\"k\", alpha=0.2, linewidth=0)\n",
    "        ax.axvline(0, color=\"r\", linestyle=\"--\", lw=1, alpha=0.85)\n",
    "        ax.axhline(0, color=\"gray\", linestyle=\":\", lw=1, alpha=0.6)\n",
    "        ax.set_xlabel(\"Time from event (s)\")\n",
    "        ax.set_ylabel(\"Z\")\n",
    "        ax.grid(True, alpha=0.15)\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "        if vel_tvec is not None and vel_mat is not None and getattr(vel_mat, \"size\", 0):\n",
    "            vel_mat = vel_mat[~np.isnan(vel_mat).all(axis=1)]\n",
    "            if vel_mat.shape[0] > 0:\n",
    "                vmean = np.nanmean(vel_mat, axis=0)\n",
    "                vax = ax.twinx()\n",
    "                vax.plot(vel_tvec, vmean, color=vel_color, lw=2.0, alpha=vel_alpha)\n",
    "                vax.set_ylabel(\"Velocity\", color=vel_color)\n",
    "                vax.tick_params(axis=\"y\", colors=vel_color)\n",
    "                vax.spines[\"top\"].set_visible(False)\n",
    "\n",
    "    _plot_mean(ax_mu_e, mat_entry, vel_mat_entry, \"open_entry\")\n",
    "    _plot_mean(ax_mu_x, mat_exit,  vel_mat_exit,  \"open_exit\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "# In your loop: compute duration per trial and pass into the plot call\n",
    "for rec in epm_result_list:\n",
    "    animal_id = rec[\"animal\"]\n",
    "    beh = rec[\"behavior\"]\n",
    "\n",
    "    if \"fiber_zscore_aligned\" not in beh.columns:\n",
    "        print(f\"{animal_id}: missing fiber_zscore_aligned; skipping\")\n",
    "        continue\n",
    "\n",
    "    # clean velocity first (so _find_velocity_column sees final column)\n",
    "    beh = clean_velocity_data(beh)\n",
    "\n",
    "    t = beh[\"time\"].to_numpy(dtype=float)\n",
    "    y = beh[\"fiber_zscore_aligned\"].to_numpy(dtype=float)\n",
    "\n",
    "    ev = extract_transition_events_epm(beh, thr=0.5, drop_first=True, min_state_dur_s=1)\n",
    "\n",
    "    vel_col = _find_velocity_column(beh)\n",
    "    vel = beh[vel_col].to_numpy(dtype=float) if vel_col is not None else None\n",
    "\n",
    "    # durations (for sorting heatmap trials)\n",
    "    dur_open_entry = compute_forward_durations(ev[\"open_entry\"], ev[\"open_exit\"])  # open-bout durations\n",
    "    dur_open_exit  = compute_forward_durations(ev[\"open_exit\"],  ev[\"open_entry\"]) # closed-bout durations\n",
    "\n",
    "    # compute PSTHs for open_entry and open_exit + velocity matrices\n",
    "    results_pair = {}\n",
    "    vel_pair = {}\n",
    "\n",
    "    for event_name in [\"open_entry\", \"open_exit\"]:\n",
    "        event_times = ev[event_name]\n",
    "\n",
    "        if event_times.size < min_trials:\n",
    "            results_pair[event_name] = (np.array([], float), np.zeros((0, 0), float))\n",
    "            vel_pair[event_name] = (None, None)\n",
    "            continue\n",
    "\n",
    "        # fiber (your existing function)\n",
    "        tvec, mat = _compute_psth_matrix(\n",
    "            t=t, y=y,\n",
    "            event_times=event_times,\n",
    "            window=window,\n",
    "            baseline_win=baseline_win,\n",
    "            resample_hz=resample_hz,\n",
    "            smooth_sigma_s=smooth_sigma_s,\n",
    "        )\n",
    "        results_pair[event_name] = (tvec, mat)\n",
    "\n",
    "        # velocity matrix (no baseline z-scoring; smoothed)\n",
    "        if vel is not None:\n",
    "            vel_tvec, vel_mat = _compute_event_locked_matrix(\n",
    "                t=t, y=vel,\n",
    "                event_times=event_times,\n",
    "                window=window,\n",
    "                resample_hz=resample_hz,\n",
    "                smooth_sigma_s=0.20,\n",
    "            )\n",
    "        else:\n",
    "            vel_tvec, vel_mat = None, None\n",
    "\n",
    "        vel_pair[event_name] = (vel_tvec, vel_mat)\n",
    "\n",
    "    # unpack\n",
    "    tvec_e, mat_e = results_pair[\"open_entry\"]\n",
    "    tvec_x, mat_x = results_pair[\"open_exit\"]\n",
    "\n",
    "    tvec_plot = tvec_e if tvec_e.size else tvec_x\n",
    "\n",
    "    vel_tvec_e, vel_mat_e = vel_pair[\"open_entry\"]\n",
    "    vel_tvec_x, vel_mat_x = vel_pair[\"open_exit\"]\n",
    "\n",
    "    # IMPORTANT: durations need to align to the event_times used for each matrix.\n",
    "    # Here they do, because dur_open_entry and dur_open_exit were computed from ev arrays.\n",
    "\n",
    "    plot_open_entry_exit_column_with_velocity(\n",
    "        tvec=tvec_plot,\n",
    "        mat_entry=mat_e,\n",
    "        mat_exit=mat_x,\n",
    "        title_prefix=animal_id,\n",
    "        vmin=vmin, vmax=vmax, cmap=cmap,\n",
    "        vel_tvec=vel_tvec_e if vel_tvec_e is not None else None,  # same grid expected\n",
    "        vel_mat_entry=vel_mat_e,\n",
    "        vel_mat_exit=vel_mat_x,\n",
    "        vel_color=\"tab:blue\",\n",
    "        vel_alpha=0.35,\n",
    "        dur_entry=dur_open_entry,\n",
    "        dur_exit=dur_open_exit,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efde63aa3890d508",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T20:26:34.129404Z",
     "start_time": "2025-12-19T20:26:33.439226Z"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Drop-in usage inside your loop\n",
    "# -----------------------------\n",
    "# Make sure you have a velocity column (or adjust the candidates list in _find_velocity_column)\n",
    "\n",
    "for rec in epm_result_list:\n",
    "    animal_id = rec[\"animal\"]\n",
    "    beh = rec[\"behavior\"]\n",
    "\n",
    "    if \"fiber_zscore_aligned\" not in beh.columns:\n",
    "        print(f\"{animal_id}: missing fiber_zscore_aligned; skipping\")\n",
    "        continue\n",
    "\n",
    "    t = beh[\"time\"].to_numpy(dtype=float)\n",
    "    y = beh[\"fiber_zscore_aligned\"].to_numpy(dtype=float)\n",
    "\n",
    "    # extract transition events\n",
    "    ev = extract_transition_events_epm(beh, thr=0.5, drop_first=True)\n",
    "\n",
    "    # velocity (optional)\n",
    "    vel_col = _find_velocity_column(beh)\n",
    "    beh=clean_velocity_data(beh)\n",
    "    vel = beh[vel_col].to_numpy(dtype=float) if vel_col is not None else None\n",
    "\n",
    "    # compute fiber PSTHs for open_entry and open_exit\n",
    "    results_pair = {}\n",
    "    vel_pair = {}\n",
    "\n",
    "    for event_name in [\"open_entry\", \"open_exit\"]:\n",
    "        event_times = ev[event_name]\n",
    "\n",
    "        if event_times.size < min_trials:\n",
    "            results_pair[event_name] = (np.array([], float), np.zeros((0, 0), float))\n",
    "            vel_pair[event_name] = (np.array([], float), np.zeros((0, 0), float))\n",
    "            continue\n",
    "\n",
    "        # fiber (your existing function)\n",
    "        tvec, mat = _compute_psth_matrix(\n",
    "            t=t, y=y,\n",
    "            event_times=event_times,\n",
    "            window=window,\n",
    "            baseline_win=baseline_win,\n",
    "            resample_hz=resample_hz,\n",
    "            smooth_sigma_s=smooth_sigma_s,\n",
    "        )\n",
    "        mat = mat[~np.isnan(mat).all(axis=1)]\n",
    "        results_pair[event_name] = (tvec, mat)\n",
    "\n",
    "        # velocity matrix (no baseline z-scoring; smoothed)\n",
    "        if vel is not None:\n",
    "            vel_tvec, vel_mat = _compute_psth_matrix(\n",
    "                t=t, y=vel,\n",
    "                event_times=event_times,\n",
    "                window=window,\n",
    "                   baseline_win=baseline_win,\n",
    "                resample_hz=resample_hz,\n",
    "                smooth_sigma_s=0.20,  # slightly more smoothing often looks better for velocity\n",
    "            )\n",
    "        else:\n",
    "            vel_tvec, vel_mat = None, None\n",
    "\n",
    "        vel_pair[event_name] = (vel_tvec, vel_mat)\n",
    "\n",
    "    # unpack\n",
    "    tvec_e, mat_e = results_pair[\"open_entry\"]\n",
    "    tvec_x, mat_x = results_pair[\"open_exit\"]\n",
    "\n",
    "    # ensure consistent tvec (should be identical if same params)\n",
    "    if tvec_e.size and tvec_x.size and not np.allclose(tvec_e, tvec_x, equal_nan=True):\n",
    "        print(f\"{animal_id}: warning — tvec differs between entry/exit; using entry tvec.\")\n",
    "    tvec_plot = tvec_e if tvec_e.size else tvec_x\n",
    "\n",
    "    vel_tvec_e, vel_mat_e = vel_pair[\"open_entry\"]\n",
    "    vel_tvec_x, vel_mat_x = vel_pair[\"open_exit\"]\n",
    "\n",
    "    # plot both as columns in a single figure (+ velocity overlay on mean plots)\n",
    "    plot_open_entry_exit_column_with_velocity(\n",
    "        tvec=tvec_plot,\n",
    "        mat_entry=mat_e if mat_e.size else np.zeros((0, tvec_plot.size)),\n",
    "        mat_exit=mat_x if mat_x.size else np.zeros((0, tvec_plot.size)),\n",
    "        title_prefix=animal_id,\n",
    "        vmin=vmin, vmax=vmax, cmap=cmap,\n",
    "        vel_tvec=vel_tvec_e if vel_tvec_e is not None else None,   # same grid expected\n",
    "        vel_mat_entry=vel_mat_e,\n",
    "        vel_mat_exit=vel_mat_x,\n",
    "        vel_color=\"tab:blue\",\n",
    "        vel_alpha=0.35,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58412a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Collect mean traces for open_entry and open_exit per animal\n",
    "entry_traces = []\n",
    "exit_traces = []\n",
    "animal_names = []\n",
    "tvec = None\n",
    "for animal, events in epm_psth_results.items():\n",
    "    if 'open_entry' in events and 'open_exit' in events and events['open_entry']['n_trials'] > 0 and events['open_exit']['n_trials'] > 0:\n",
    "        entry_trace = events['open_entry']['mean']\n",
    "        exit_trace = events['open_exit']['mean']\n",
    "        entry_traces.append(entry_trace)\n",
    "        exit_traces.append(exit_trace)\n",
    "        animal_names.append(animal)\n",
    "        if tvec is None:\n",
    "            tvec = events['open_entry']['tvec']\n",
    "\n",
    "if not entry_traces:\n",
    "    print(\"No data for open_entry/open_exit\")\n",
    "else:\n",
    "    # Convert to arrays\n",
    "    entry_array = np.array(entry_traces)\n",
    "    exit_array = np.array(exit_traces)\n",
    "\n",
    "    # Overall means and SEMs\n",
    "    overall_entry = np.nanmean(entry_array, axis=0)\n",
    "    entry_sem = np.nanstd(entry_array, axis=0) / np.sqrt(len(animal_names))\n",
    "    overall_exit = np.nanmean(exit_array, axis=0)\n",
    "    exit_sem = np.nanstd(exit_array, axis=0) / np.sqrt(len(animal_names))\n",
    "    diff_per_animal = entry_array - exit_array\n",
    "    overall_diff = np.nanmean(diff_per_animal, axis=0)\n",
    "    diff_sem = np.nanstd(diff_per_animal, axis=0) / np.sqrt(len(animal_names))\n",
    "\n",
    "    # For heatmap, interleave entry and exit traces for each animal\n",
    "    heatmap_matrix = []\n",
    "    yticklabels = []\n",
    "    for i, animal in enumerate(animal_names):\n",
    "        heatmap_matrix.append(entry_traces[i])\n",
    "        yticklabels.append(f\"{animal} Entry\")\n",
    "        heatmap_matrix.append(exit_traces[i])\n",
    "        yticklabels.append(f\"{animal} Exit\")\n",
    "    heatmap_matrix = np.array(heatmap_matrix)\n",
    "    heatmap_matrix_smoothed = gaussian_filter(heatmap_matrix, sigma=0.5, axes=1)\n",
    "\n",
    "    # Plot\n",
    "    fig, ((ax_entry, ax_exit), (ax_diff, ax_heat)) = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    # Entries plot with SEM\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(animal_names)))\n",
    "    for i, animal in enumerate(animal_names):\n",
    "        ax_entry.plot(tvec, entry_traces[i], color=colors[i], label=animal, linewidth=1, alpha=0.7)\n",
    "    ax_entry.plot(tvec, overall_entry, color='black', linewidth=3, label='Overall Mean')\n",
    "    ax_entry.fill_between(tvec, overall_entry - entry_sem, overall_entry + entry_sem, color='black', alpha=0.2, label='SEM')\n",
    "    ax_entry.axvline(0, color='red', linestyle='--', alpha=0.7)\n",
    "    ax_entry.set_xlabel('Time from event (s)')\n",
    "    ax_entry.set_ylabel('Z-score')\n",
    "    ax_entry.set_title('Open Entries')\n",
    "    ax_entry.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    ax_entry.grid(True, alpha=0.3)\n",
    "\n",
    "    # Exits plot with SEM\n",
    "    for i, animal in enumerate(animal_names):\n",
    "        ax_exit.plot(tvec, exit_traces[i], color=colors[i], label=animal, linewidth=1, alpha=0.7)\n",
    "    ax_exit.plot(tvec, overall_exit, color='black', linewidth=3, label='Overall Mean')\n",
    "    ax_exit.fill_between(tvec, overall_exit - exit_sem, overall_exit + exit_sem, color='black', alpha=0.2, label='SEM')\n",
    "    ax_exit.axvline(0, color='red', linestyle='--', alpha=0.7)\n",
    "    ax_exit.set_xlabel('Time from event (s)')\n",
    "    ax_exit.set_ylabel('Z-score')\n",
    "    ax_exit.set_title('Open Exits')\n",
    "    ax_exit.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    ax_exit.grid(True, alpha=0.3)\n",
    "\n",
    "    # Differences plot with SEM\n",
    "    for i, animal in enumerate(animal_names):\n",
    "        ax_diff.plot(tvec, diff_per_animal[i], color=colors[i], label=animal, linewidth=1, alpha=0.7)\n",
    "    ax_diff.plot(tvec, overall_diff, color='black', linewidth=3, label='Overall Mean')\n",
    "    ax_diff.fill_between(tvec, overall_diff - diff_sem, overall_diff + diff_sem, color='black', alpha=0.2, label='SEM')\n",
    "    ax_diff.axvline(0, color='red', linestyle='--', alpha=0.7)\n",
    "    ax_diff.axhline(0, color='gray', linestyle=':', alpha=0.5)\n",
    "    ax_diff.set_xlabel('Time from event (s)')\n",
    "    ax_diff.set_ylabel('Z-score Difference\\n(Entry - Exit)')\n",
    "    ax_diff.set_title('Differences')\n",
    "    ax_diff.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    ax_diff.grid(True, alpha=0.3)\n",
    "\n",
    "    # Heatmap: smoothed interleaved entry/exit traces for all animals\n",
    "    im = ax_heat.imshow(\n",
    "        heatmap_matrix_smoothed,\n",
    "        aspect='auto',\n",
    "        origin='lower',\n",
    "        extent=[tvec[0], tvec[-1], 0, len(heatmap_matrix)],\n",
    "        cmap='viridis',\n",
    "        vmin=np.nanmin(heatmap_matrix_smoothed),\n",
    "        vmax=np.nanmax(heatmap_matrix_smoothed),\n",
    "        interpolation='nearest'\n",
    "    )\n",
    "    ax_heat.axvline(0, color='white', linestyle='--', alpha=0.9)\n",
    "    ax_heat.grid(False)  # Remove grid, keep only the time locking line\n",
    "    ax_heat.set_xlabel('Time from event (s)')\n",
    "    ax_heat.set_ylabel('Animal & Event')\n",
    "    ax_heat.set_title('Heatmap of Entries & Exits\\n(All Animals, Smoothed)')\n",
    "    ax_heat.set_yticks(np.arange(len(heatmap_matrix)) + 0.5)\n",
    "    ax_heat.set_yticklabels(yticklabels)\n",
    "\n",
    "    # Colorbar\n",
    "    cbar = fig.colorbar(im, ax=ax_heat, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Z-score')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Collect mean traces for open_entry\n",
    "mean_traces = []\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(epm_psth_results)))\n",
    "for i, (animal, events) in enumerate(epm_psth_results.items()):\n",
    "    if 'open_entry' in events and events['open_entry']['n_trials'] > 0:\n",
    "        mean_trace = events['open_entry']['mean']\n",
    "        mean_traces.append(mean_trace)\n",
    "        plt.plot(events['open_entry']['tvec'], mean_trace, color=colors[i], label=animal)\n",
    "# Compute overall mean\n",
    "if mean_traces:\n",
    "    overall_mean = np.nanmean(np.array(mean_traces), axis=0)\n",
    "    tvec = list(epm_psth_results.values())[0]['open_entry']['tvec']  # assume same\n",
    "    plt.plot(tvec, overall_mean, color='black', linewidth=3, label='Mean')\n",
    "plt.xlabel('Time from event (s)')\n",
    "plt.ylabel('Z')\n",
    "plt.title('Mean signal and individual traces for open_entry')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "1a4fc207c30987f3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
