{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:23:45.186634Z",
     "start_time": "2026-01-05T09:23:45.181017Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "try:\n",
    "    from sklearn.linear_model import Lasso\n",
    "except Exception:\n",
    "    Lasso = None\n",
    "from pybaselines import Baseline\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 4)\n",
    "plt.rcParams[\"axes.grid\"] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa2235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = r\"your/path/here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16606b8d9a8214c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:23:45.216444Z",
     "start_time": "2026-01-05T09:23:45.190125Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt, decimate\n",
    "def list_doric_channels(path):\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        base = f[\"DataAcquisition\"][\"FPConsole\"][\"Signals\"][\"Series0001\"]\n",
    "        chans = []\n",
    "        if \"LockInAOUT02\" in base:\n",
    "            for k in base[\"LockInAOUT02\"].keys():\n",
    "                if k.startswith(\"AIN\"):\n",
    "                    chans.append(k)\n",
    "        chans = sorted(chans)\n",
    "\n",
    "        digital = []\n",
    "        if \"DigitalIO\" in base:\n",
    "            for k in base[\"DigitalIO\"].keys():\n",
    "                if k.startswith(\"DIO\"):\n",
    "                    digital.append(k)\n",
    "        return chans, digital\n",
    "\n",
    "def load_doric(path, channel=\"AIN01\", signal_folder=\"LockInAOUT02\", ref_folder=\"LockInAOUT01\",\n",
    "              trigger_name=None):\n",
    "    \"\"\"\n",
    "    Returns dict with:\n",
    "      time, sig465, ref405, fs, (optional) trig_time, trig\n",
    "    \"\"\"\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        base = f[\"DataAcquisition\"][\"FPConsole\"][\"Signals\"][\"Series0001\"]\n",
    "\n",
    "        sig = np.asarray(base[signal_folder][channel][()], float)\n",
    "        ref = np.asarray(base[ref_folder][channel][()], float)\n",
    "\n",
    "        # time: prefer the matching folder time if size matches\n",
    "        t_sig = np.asarray(base[signal_folder][\"Time\"][()], float) if \"Time\" in base[signal_folder] else np.array([])\n",
    "        t_ref = np.asarray(base[ref_folder][\"Time\"][()], float) if \"Time\" in base[ref_folder] else np.array([])\n",
    "\n",
    "        if t_sig.size == sig.size:\n",
    "            t = t_sig\n",
    "        elif t_ref.size == sig.size:\n",
    "            t = t_ref\n",
    "        else:\n",
    "            # fallback\n",
    "            dt = np.nanmedian(np.diff(t_sig)) if t_sig.size > 2 else 1/1000\n",
    "            t = np.arange(sig.size) * dt\n",
    "\n",
    "        # if ref length differs, interpolate onto t if possible\n",
    "        if ref.size != sig.size:\n",
    "            if t_ref.size == ref.size:\n",
    "                ref = np.interp(t, t_ref, ref)\n",
    "            else:\n",
    "                ref = np.resize(ref, sig.size)\n",
    "\n",
    "        # sampling rate\n",
    "        fs = 1.0 / float(np.nanmedian(np.diff(t))) if t.size > 2 else np.nan\n",
    "\n",
    "        # optional digital trigger overlay\n",
    "        trig_time = None\n",
    "        trig = None\n",
    "        if trigger_name:\n",
    "            if \"DigitalIO\" in base and trigger_name in base[\"DigitalIO\"]:\n",
    "                dio = base[\"DigitalIO\"]\n",
    "                trig = np.asarray(dio[trigger_name][()], float)\n",
    "                trig_time = np.asarray(dio[\"Time\"][()], float) if \"Time\" in dio else None\n",
    "\n",
    "                # if lengths mismatch, interpolate signals to trigger time (like your Doric logic)\n",
    "                if trig_time is not None and trig_time.size and trig_time.size != t.size:\n",
    "                    sig = np.interp(trig_time, t, sig)\n",
    "                    ref = np.interp(trig_time, t, ref)\n",
    "                    t = trig_time\n",
    "                    fs = 1.0 / float(np.nanmedian(np.diff(t))) if t.size > 2 else fs\n",
    "\n",
    "    out = {\"time\": t, \"sig465\": sig, \"ref405\": ref, \"fs\": fs}\n",
    "    if trig is not None and trig_time is not None:\n",
    "        out[\"trig_time\"] = trig_time\n",
    "        out[\"trig\"] = trig\n",
    "    return out\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "\n",
    "def _nan_interp_1d(y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Linearly interpolate NaNs in a 1D array.\n",
    "    Edge NaNs are filled with nearest valid value.\n",
    "    \"\"\"\n",
    "    y = np.asarray(y, float).copy()\n",
    "    n = y.size\n",
    "    if n == 0:\n",
    "        return y\n",
    "\n",
    "    isnan = ~np.isfinite(y)\n",
    "    if not np.any(isnan):\n",
    "        return y\n",
    "\n",
    "    x = np.arange(n)\n",
    "    good = np.isfinite(y)\n",
    "    if np.sum(good) == 0:\n",
    "        # nothing to interpolate from\n",
    "        return y\n",
    "\n",
    "    y[isnan] = np.interp(x[isnan], x[good], y[good])\n",
    "    return y\n",
    "\n",
    "\n",
    "def adaptive_mad_artifact_mask(\n",
    "    y: np.ndarray,\n",
    "    fs: float,\n",
    "    *,\n",
    "    k: float = 6.0,\n",
    "    window_s: float = 1.0,\n",
    "    pad_s: float = 0.2,\n",
    "    use_derivative: bool = True,\n",
    "    min_mad: float = 1e-12,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build an artifact mask using Adaptive MAD (windowed).\n",
    "\n",
    "    Detection is performed on dx=diff(y) if use_derivative=True, else directly on y.\n",
    "    Within each non-overlapping window, compute median and MAD, then flag samples where:\n",
    "        |x - median| > k * MAD\n",
    "\n",
    "    Mask is returned at signal sample resolution (len(y)).\n",
    "    \"\"\"\n",
    "    y = np.asarray(y, float)\n",
    "    n = y.size\n",
    "    if n == 0:\n",
    "        return np.zeros((0,), dtype=bool)\n",
    "\n",
    "    if not np.isfinite(fs) or fs <= 0:\n",
    "        raise ValueError(f\"adaptive_mad_artifact_mask: invalid fs={fs}\")\n",
    "\n",
    "    x = np.diff(y) if use_derivative else y.copy()\n",
    "    # x length is n-1 if derivative else n\n",
    "    nx = x.size\n",
    "    if nx == 0:\n",
    "        return np.zeros((n,), dtype=bool)\n",
    "\n",
    "    win = int(round(window_s * fs))\n",
    "    win = max(5, win)  # avoid tiny windows\n",
    "\n",
    "    flagged_x = np.zeros((nx,), dtype=bool)\n",
    "\n",
    "    # Process non-overlapping windows (fast, “adaptive” across time)\n",
    "    for start in range(0, nx, win):\n",
    "        stop = min(start + win, nx)\n",
    "        seg = x[start:stop]\n",
    "\n",
    "        # Ignore non-finite values in stats\n",
    "        seg_f = seg[np.isfinite(seg)]\n",
    "        if seg_f.size < 5:\n",
    "            continue\n",
    "\n",
    "        med = np.median(seg_f)\n",
    "        mad = np.median(np.abs(seg_f - med))\n",
    "        mad = max(float(mad), float(min_mad))\n",
    "\n",
    "        flagged_x[start:stop] = np.abs(seg - med) > (k * mad)\n",
    "\n",
    "    # Map flagged_x back to signal sample mask (len(y))\n",
    "    mask = np.zeros((n,), dtype=bool)\n",
    "    if use_derivative:\n",
    "        # A large dx affects both samples around the step\n",
    "        hit = np.where(flagged_x)[0]\n",
    "        mask[hit] = True\n",
    "        mask[hit + 1] = True\n",
    "    else:\n",
    "        mask[:nx] = flagged_x  # nx == n in this mode\n",
    "\n",
    "    # Pad mask by pad_s seconds\n",
    "    pad_n = int(round(pad_s * fs))\n",
    "    if pad_n > 0 and np.any(mask):\n",
    "        kernel = np.ones((2 * pad_n + 1,), dtype=int)\n",
    "        mask = (np.convolve(mask.astype(int), kernel, mode=\"same\") > 0)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def remove_artifacts_adaptive_mad(\n",
    "    time: np.ndarray,\n",
    "    sig465: np.ndarray,\n",
    "    ref405: np.ndarray,\n",
    "    fs: float = None,\n",
    "    *,\n",
    "    k: float = 6.0,\n",
    "    window_s: float = 1.0,\n",
    "    pad_s: float = 0.2,\n",
    "    union_channels: bool = True,\n",
    "    use_derivative: bool = True,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Detect + remove artifacts using adaptive MAD (windowed) with padding.\n",
    "\n",
    "    By default, artifacts are detected on BOTH channels and unioned (recommended),\n",
    "    then removed from BOTH channels consistently.\n",
    "\n",
    "    Returns a dict:\n",
    "      {\n",
    "        \"time\": time,\n",
    "        \"sig465_clean\": ...,\n",
    "        \"ref405_clean\": ...,\n",
    "        \"artifact_mask\": ...,\n",
    "        \"artifact_regions_s\": [(t0,t1), ...]\n",
    "      }\n",
    "    \"\"\"\n",
    "    t = np.asarray(time, float)\n",
    "    s = np.asarray(sig465, float)\n",
    "    r = np.asarray(ref405, float)\n",
    "\n",
    "    n = min(t.size, s.size, r.size)\n",
    "    t, s, r = t[:n], s[:n], r[:n]\n",
    "\n",
    "    if fs is None:\n",
    "        fs = 1.0 / float(np.nanmedian(np.diff(t))) if t.size > 2 else np.nan\n",
    "    if not np.isfinite(fs) or fs <= 0:\n",
    "        raise ValueError(f\"remove_artifacts_adaptive_mad: invalid fs={fs}\")\n",
    "\n",
    "    m_s = adaptive_mad_artifact_mask(s, fs, k=k, window_s=window_s, pad_s=pad_s, use_derivative=use_derivative)\n",
    "    m_r = adaptive_mad_artifact_mask(r, fs, k=k, window_s=window_s, pad_s=pad_s, use_derivative=use_derivative)\n",
    "\n",
    "    mask = (m_s | m_r) if union_channels else m_s\n",
    "\n",
    "    s_clean = s.copy()\n",
    "    r_clean = r.copy()\n",
    "    s_clean[mask] = np.nan\n",
    "    r_clean[mask] = np.nan\n",
    "\n",
    "    s_clean = _nan_interp_1d(s_clean)\n",
    "    r_clean = _nan_interp_1d(r_clean)\n",
    "\n",
    "    # Build contiguous regions in seconds (useful for reporting / exporting)\n",
    "    regions = []\n",
    "    if np.any(mask):\n",
    "        idx = np.where(mask)[0]\n",
    "        # segment mask into contiguous runs\n",
    "        breaks = np.where(np.diff(idx) > 1)[0]\n",
    "        starts = np.r_[idx[0], idx[breaks + 1]]\n",
    "        ends   = np.r_[idx[breaks], idx[-1]]\n",
    "        for a, b in zip(starts, ends):\n",
    "            regions.append((float(t[a]), float(t[b])))\n",
    "\n",
    "    return {\n",
    "        \"time\": t,\n",
    "        \"sig465_clean\": s_clean,\n",
    "        \"ref405_clean\": r_clean,\n",
    "        \"artifact_mask\": mask,\n",
    "        \"artifact_regions_s\": regions,\n",
    "        \"fs\": fs,\n",
    "    }\n",
    "\n",
    "def ols_fit(x, y):\n",
    "    x = np.asarray(x, float)\n",
    "    y = np.asarray(y, float)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    if np.sum(m) < 10:\n",
    "        return 1.0, 0.0\n",
    "    X = np.vstack([x[m], np.ones(np.sum(m))]).T\n",
    "    coef, *_ = np.linalg.lstsq(X, y[m], rcond=None)\n",
    "    return float(coef[0]), float(coef[1])\n",
    "def preprocess_signal(sig, fs_raw, target_fs=100, lpf_cutoff=3):\n",
    "    \"\"\"\n",
    "    1\\) Low-pass filter (Butterworth, lpf_cutoff Hz)\n",
    "    2\\) Decimate to target sampling rate (target_fs Hz)\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * fs_raw\n",
    "    normal_cutoff = lpf_cutoff / nyquist\n",
    "    b, a = butter(N=2, Wn=normal_cutoff, btype=\"low\", analog=False)\n",
    "    sig_filtered = filtfilt(b, a, sig)\n",
    "\n",
    "    q = int(fs_raw / target_fs)\n",
    "    if q > 1:\n",
    "        sig_downsampled = decimate(sig_filtered, q)\n",
    "        real_fs = fs_raw / q\n",
    "    else:\n",
    "        sig_downsampled = sig_filtered\n",
    "        real_fs = fs_raw\n",
    "\n",
    "    return sig_downsampled, real_fs\n",
    "\n",
    "\n",
    "def compute_arpls_baselines(\n",
    "    baseline_fitter,\n",
    "    sig_f,\n",
    "    ref_f,\n",
    "    lam=1e9,\n",
    "    diff_order=2,\n",
    "    max_iter=50,\n",
    "    tol=1e-3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute arPLS baselines for signal and reference.\n",
    "\n",
    "    Parameters:\n",
    "        baseline_fitter: pybaselines.Baseline instance, already set up with x_data.\n",
    "        sig_f: 1D array-like, preprocessed signal channel.\n",
    "        ref_f: 1D array-like, preprocessed reference channel.\n",
    "        lam: smoothing parameter.\n",
    "        diff_order: difference order for the penalty.\n",
    "        max_iter: maximum iterations for arPLS.\n",
    "        tol: convergence tolerance.\n",
    "\n",
    "    Returns:\n",
    "        b_sig_arpls, b_ref_arpls\n",
    "    \"\"\"\n",
    "    b_sig_arpls, _ = baseline_fitter.arpls(\n",
    "        sig_f, lam=lam, diff_order=diff_order,\n",
    "        max_iter=max_iter, tol=tol\n",
    "    )\n",
    "    b_ref_arpls, _ = baseline_fitter.arpls(\n",
    "        ref_f, lam=lam, diff_order=diff_order,\n",
    "        max_iter=max_iter, tol=tol\n",
    "    )\n",
    "    return b_sig_arpls, b_ref_arpls\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def compute_motion_corrected_dff_robust(sig_f, ref_f, b_sig, b_ref):\n",
    "    \"\"\"\n",
    "    Computes motion-corrected dF/F using dF/F-first strategy and Robust Regression.\n",
    "    \"\"\"\n",
    "    # --- 1. Calculate raw dF/F for each channel ---\n",
    "    # Safe division\n",
    "    den_sig = np.asarray(b_sig, float).copy()\n",
    "    den_sig[np.abs(den_sig) < 1e-12] = np.nan\n",
    "    dff_sig_raw = (sig_f - b_sig) / den_sig\n",
    "\n",
    "    den_ref = np.asarray(b_ref, float).copy()\n",
    "    den_ref[np.abs(den_ref) < 1e-12] = np.nan\n",
    "    dff_ref_raw = (ref_f - b_ref) / den_ref\n",
    "\n",
    "    # Handle NaNs created by division (optional but recommended)\n",
    "    valid_mask = ~np.isnan(dff_sig_raw) & ~np.isnan(dff_ref_raw)\n",
    "\n",
    "    # --- 2. Fit Reference to Signal using Robust Linear Model (IRLS) ---\n",
    "    # Prepare data for statsmodels (needs constant for intercept)\n",
    "    X = dff_ref_raw[valid_mask]\n",
    "    Y = dff_sig_raw[valid_mask]\n",
    "    X_const = sm.add_constant(X)\n",
    "\n",
    "    # RLM with HuberT weighting reduces impact of calcium spikes\n",
    "    model = sm.RLM(Y, X_const, M=sm.robust.norms.HuberT())\n",
    "    results = model.fit()\n",
    "\n",
    "    b_fit, a_fit = results.params  # Intercept (b), Slope (a)\n",
    "\n",
    "    # --- 3. Subtract Fitted Reference ---\n",
    "    # fitted_ref = slope * ref + intercept\n",
    "    fitted_ref = a_fit * dff_ref_raw + b_fit\n",
    "    dff_mc = dff_sig_raw - fitted_ref\n",
    "    from scipy.stats import zscore\n",
    "    zcored_dff = zscore(dff_mc)\n",
    "\n",
    "    return {\n",
    "        \"sig_det\": dff_sig_raw,\n",
    "        \"ref_det\": dff_ref_raw,\n",
    "        \"a\": a_fit,\n",
    "        \"b\": b_fit,\n",
    "        \"dff\": dff_mc,\n",
    "        \"zscore\": zcored_dff\n",
    "    }\n",
    "\n",
    "def list_doric_files(folder_path):\n",
    "    \"\"\"\n",
    "    Return a list of full paths to all .doric files in the given folder.\n",
    "    \"\"\"\n",
    "    doric_files = []\n",
    "    for fname in os.listdir(folder_path):\n",
    "        if fname.lower().endswith(\".doric\"):\n",
    "            doric_files.append(os.path.join(folder_path, fname))\n",
    "    return doric_files\n",
    "def list_labels_files(folder_path):\n",
    "    \"\"\"\n",
    "    Return a list of full paths to all .doric files in the given folder.\n",
    "    \"\"\"\n",
    "    doric_files = []\n",
    "    for fname in os.listdir(folder_path):\n",
    "        if fname.lower().endswith(\".csv\"):\n",
    "            doric_files.append(os.path.join(folder_path, fname))\n",
    "    return doric_files\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def qc_sig_ref_correlation(sig, ref, title=\"\", max_points=8000, ax=None):\n",
    "    \"\"\"\n",
    "    Scatter sig vs ref with OLS fit + Pearson R, R^2.\n",
    "    Downsamples points for plotting but computes stats on full data.\n",
    "    Returns dict with r, r2, slope, intercept, n.\n",
    "    \"\"\"\n",
    "    sig = np.asarray(sig, float)\n",
    "    ref = np.asarray(ref, float)\n",
    "\n",
    "    m = np.isfinite(sig) & np.isfinite(ref)\n",
    "    sig = sig[m]\n",
    "    ref = ref[m]\n",
    "    n = int(sig.size)\n",
    "\n",
    "    out = {\"r\": np.nan, \"r2\": np.nan, \"slope\": np.nan, \"intercept\": np.nan, \"n\": n}\n",
    "\n",
    "    if n < 10:\n",
    "        return out\n",
    "\n",
    "    # Pearson R\n",
    "    s0 = sig - np.mean(sig)\n",
    "    r0 = ref - np.mean(ref)\n",
    "    denom = np.sqrt(np.sum(s0**2) * np.sum(r0**2))\n",
    "    if denom > 0:\n",
    "        r = float(np.sum(s0 * r0) / denom)\n",
    "    else:\n",
    "        r = np.nan\n",
    "    out[\"r\"] = r\n",
    "    out[\"r2\"] = float(r**2) if np.isfinite(r) else np.nan\n",
    "\n",
    "    # OLS fit sig = a*ref + b\n",
    "    X = np.vstack([ref, np.ones_like(ref)]).T\n",
    "    coef, *_ = np.linalg.lstsq(X, sig, rcond=None)\n",
    "    a, b = float(coef[0]), float(coef[1])\n",
    "    out[\"slope\"] = a\n",
    "    out[\"intercept\"] = b\n",
    "\n",
    "    # Plot\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(4.2, 3.6))\n",
    "\n",
    "\n",
    "    xs, ys = ref, sig\n",
    "\n",
    "    ax.scatter(xs, ys, s=6, alpha=0.25, edgecolors=\"none\")\n",
    "\n",
    "    # fit line over displayed x-range\n",
    "    xlo, xhi = np.nanpercentile(ref, [1, 99])\n",
    "    xx = np.linspace(xlo, xhi, 200)\n",
    "    yy = a * xx + b\n",
    "    ax.plot(xx, yy, lw=1.8)\n",
    "\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    ax.set_xlabel(\"Reference 405 (a.u.)\")\n",
    "    ax.set_ylabel(\"Signal 465 (a.u.)\")\n",
    "\n",
    "    # cosmetics\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.grid(True, alpha=0.15)\n",
    "\n",
    "    ax.text(\n",
    "        0.02, 0.98,\n",
    "        f\"R = {out['r']:.3f}\\nR² = {out['r2']:.3f}\\na = {a:.3g}\",\n",
    "        transform=ax.transAxes, va=\"top\", ha=\"left\", fontsize=9\n",
    "    )\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1831a43717d24a59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:23:45.225703Z",
     "start_time": "2026-01-05T09:23:45.221618Z"
    }
   },
   "outputs": [],
   "source": [
    "doric_paths = list_doric_files(folder)\n",
    "labels_paths = list_labels_files(folder)\n",
    "print(doric_paths)\n",
    "print(labels_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eacc3b29f3440e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:23:50.359789Z",
     "start_time": "2026-01-05T09:23:45.253395Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Parameters\n",
    "target_fs = 30\n",
    "lpf_cutoff = 3\n",
    "lam = 1e12\n",
    "diff_order = 2\n",
    "max_iter = 50\n",
    "tol = 1e-3\n",
    "\n",
    "# --- Artifact removal parameters (Adaptive MAD windowed) ---\n",
    "art_k = 6.0\n",
    "art_window_s = 1.0\n",
    "art_pad_s = 0.2\n",
    "art_union_channels = True      # detect on both channels and union mask (recommended)\n",
    "art_use_derivative = False      # detect on dx (recommended)\n",
    "\n",
    "# ---- user option: plot only a specific time window (seconds) ----\n",
    "plot_window = [0, 40]  # e.g., [start_s, end_s]\n",
    "# plot_window = None\n",
    "\n",
    "def apply_plot_window(t: np.ndarray, *series: np.ndarray, plot_window=None):\n",
    "    if plot_window is None:\n",
    "        mask = np.ones_like(t, dtype=bool)\n",
    "        return (t, *series, mask)\n",
    "\n",
    "    lo, hi = float(plot_window[0]), float(plot_window[1])\n",
    "    if lo > hi:\n",
    "        lo, hi = hi, lo\n",
    "\n",
    "    mask = (t >= lo) & (t <= hi)\n",
    "    t2 = t[mask]\n",
    "    series2 = [s[mask] if s is not None else None for s in series]\n",
    "    return (t2, *series2, mask)\n",
    "result_list=[]\n",
    "qc_list = []  # will store per-recording QC metrics\n",
    "for path in doric_paths:\n",
    "    results = {}\n",
    "    filename = os.path.basename(path)\n",
    "    file_name=os.path.splitext(os.path.basename(path))[0]\n",
    "    animal_id=file_name.split('_')[0]\n",
    "    condition=file_name.split('_')[1]\n",
    "\n",
    "\n",
    "    print(f\"Processing: {filename} -> Animal ID: {animal_id}\")\n",
    "\n",
    "    rec = load_doric(path, trigger_name=\"DIO02\")\n",
    "\n",
    "    # Raw signals/time\n",
    "    t_raw = rec[\"time\"]\n",
    "    sig_raw = rec[\"sig465\"]\n",
    "    ref_raw = rec[\"ref405\"]\n",
    "    fs_raw = rec[\"fs\"]\n",
    "\n",
    "    dio_raw = rec.get(\"trig\", None)\n",
    "    dio_time = rec.get(\"trig_time\", None)\n",
    "\n",
    "    # -------------------- Artifact removal FIRST --------------------\n",
    "    art = remove_artifacts_adaptive_mad(\n",
    "        t_raw, sig_raw, ref_raw, fs_raw,\n",
    "        k=art_k, window_s=art_window_s, pad_s=art_pad_s,\n",
    "        union_channels=art_union_channels,\n",
    "        use_derivative=art_use_derivative\n",
    "    )\n",
    "\n",
    "    # Use cleaned signals for all subsequent preprocessing\n",
    "    sig = art[\"sig465_clean\"]\n",
    "    ref = art[\"ref405_clean\"]\n",
    "    # (time/fs unchanged, but take from art for consistency)\n",
    "    t_raw = art[\"time\"]\n",
    "    fs = art[\"fs\"]\n",
    "\n",
    "    # -------------------- Continue preprocessing --------------------\n",
    "    sig_f, fs_sig = preprocess_signal(sig, fs, target_fs=target_fs, lpf_cutoff=lpf_cutoff)\n",
    "    ref_f, fs_ref = preprocess_signal(ref, fs, target_fs=target_fs, lpf_cutoff=lpf_cutoff)\n",
    "\n",
    " # ---- QC: correlation scatter + fit ----\n",
    "    qc_title = f\"{animal_id} | {condition} | sig_f vs ref_f\"\n",
    "    fig_qc, ax_qc = plt.subplots(figsize=(4.6, 3.8))\n",
    "    qc = qc_sig_ref_correlation(sig_f, ref_f, title=qc_title, ax=ax_qc)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # store QC metrics\n",
    "    qc.update({\n",
    "        \"animal\": animal_id,\n",
    "        \"condition\": condition,\n",
    "        \"file\": os.path.basename(path),\n",
    "        \"artifact_fraction\": float(np.mean(art[\"artifact_mask\"])) if art[\"artifact_mask\"].size else 0.0,\n",
    "        \"fs_used\": float(fs_sig),\n",
    "        \"sig_std\": float(np.nanstd(sig_f)),\n",
    "        \"ref_std\": float(np.nanstd(ref_f)),\n",
    "    })\n",
    "    qc_list.append(qc)\n",
    "\n",
    "    dt_ds = 1.0 / fs_sig\n",
    "    t_ds = np.arange(sig_f.size) * dt_ds\n",
    "\n",
    "    baseline_fitter = Baseline(x_data=t_ds)\n",
    "    b_sig, b_ref = compute_arpls_baselines(\n",
    "        baseline_fitter, sig_f, ref_f,\n",
    "        lam=lam, diff_order=diff_order, max_iter=max_iter, tol=tol\n",
    "    )\n",
    "\n",
    "    dff_results = compute_motion_corrected_dff_robust(sig_f, ref_f, b_sig, b_ref)\n",
    "    dff_mc = dff_results[\"dff\"]\n",
    "\n",
    "    dff_z = (dff_mc - np.nanmean(dff_mc)) / np.nanstd(dff_mc)\n",
    "\n",
    "    if dio_raw is not None and dio_time is not None:\n",
    "        dio_ds = np.interp(t_ds, dio_time, dio_raw)\n",
    "    else:\n",
    "        dio_ds = np.zeros_like(t_ds)\n",
    "\n",
    "    results = {\n",
    "        'animal': animal_id,\n",
    "        'condition': condition,\n",
    "        \"t\": t_ds,\n",
    "        \"dff\": dff_mc,\n",
    "        \"zscore\": dff_z,\n",
    "        \"dio2\": dio_ds,\n",
    "        # Optional: keep artifact info for QA/QC\n",
    "        \"artifact_regions_s\": art[\"artifact_regions_s\"],\n",
    "        \"artifact_fraction\": float(np.mean(art[\"artifact_mask\"])) if art[\"artifact_mask\"].size else 0.0,\n",
    "    }\n",
    "    result_list.append(results)\n",
    "    # ---- apply plot window right before plotting ----\n",
    "    t_plot, dff_z_plot, dio_plot, _mask = apply_plot_window(\n",
    "        t_ds, dff_z, dio_ds, plot_window=plot_window\n",
    "    )\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "    color_z = \"tab:blue\"\n",
    "    ax1.set_xlabel(\"Time (s)\")\n",
    "    ax1.set_ylabel(\"Z-score\", color=color_z)\n",
    "    ax1.plot(t_plot, dff_z_plot, color=color_z, lw=1, label=\"dF/F Z-score\")\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=color_z)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color_dio = \"tab:orange\"\n",
    "    ax2.set_ylabel(\"DIO2\", color=color_dio)\n",
    "    ax2.fill_between(t_plot, dio_plot, color=color_dio, alpha=0.3, step=\"mid\", label=\"DIO2\")\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=color_dio)\n",
    "    ax2.set_ylim(-0.1, 1.5)\n",
    "\n",
    "    if plot_window is not None:\n",
    "        plt.title(f\"Animal: {animal_id} | condition: {condition} | Window: {plot_window[0]}-{plot_window[1]} s\")\n",
    "    else:\n",
    "        plt.title(f\"Animal: {animal_id} | File: {filename}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf11df0f06a5486",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:23:50.696466Z",
     "start_time": "2026-01-05T09:23:50.433418Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Build lookup from your list (recommended)\n",
    "results_by_key = {(r[\"animal\"], r[\"condition\"]): r for r in result_list}\n",
    "\n",
    "# -------------------------\n",
    "# Attach behavior CSVs\n",
    "# -------------------------\n",
    "for path in labels_paths:\n",
    "    behaviors = pd.read_csv(path, delimiter=\",\")  # delimiter updated\n",
    "\n",
    "    file_name = os.path.splitext(os.path.basename(path))[0]  # e.g. \"M01-Adu\"\n",
    "    parts = file_name.split(\"_\")\n",
    "    if len(parts) < 2:\n",
    "        print(f\"Skipping {os.path.basename(path)}: expected 'Animal-Cond.csv'\")\n",
    "        continue\n",
    "\n",
    "    animal_id = parts[0]\n",
    "    condition = parts[1]\n",
    "    key = (animal_id, condition)\n",
    "\n",
    "    if key not in results_by_key:\n",
    "        print(f\"No matching fiber record for {key} from {os.path.basename(path)}\")\n",
    "        continue\n",
    "\n",
    "    results_by_key[key][\"behavior\"] = behaviors\n",
    "\n",
    "# -------------------------\n",
    "# Align fiber to behavior time\n",
    "# -------------------------\n",
    "for (animal_id, condition), rec in results_by_key.items():\n",
    "    if \"behavior\" not in rec:\n",
    "        continue\n",
    "\n",
    "    fiber_time = np.asarray(rec[\"t\"], float)\n",
    "    fiber_z = np.asarray(rec[\"zscore\"], float)\n",
    "\n",
    "    behavior_df = rec[\"behavior\"]\n",
    "    if \"time\" not in behavior_df.columns:\n",
    "        print(f\"{animal_id}-{condition}: behavior missing 'time' column; skipping\")\n",
    "        continue\n",
    "\n",
    "    behavior_time = behavior_df[\"time\"].to_numpy(dtype=float)\n",
    "\n",
    "    print(f\"Aligning {animal_id}-{condition}:\")\n",
    "    print(f\"  Fiber range: {fiber_time[0]:.2f}s to {fiber_time[-1]:.2f}s\")\n",
    "    print(f\"  Behav range: {behavior_time[0]:.2f}s to {behavior_time[-1]:.2f}s\")\n",
    "\n",
    "    interpolator = interp1d(\n",
    "        fiber_time, fiber_z,\n",
    "        kind=\"linear\",\n",
    "        bounds_error=False,\n",
    "        fill_value=np.nan\n",
    "    )\n",
    "\n",
    "    aligned_fiber = interpolator(behavior_time)\n",
    "    rec[\"behavior\"][\"fiber_zscore_aligned\"] = aligned_fiber\n",
    "\n",
    "    print(f\"  New column shape: {rec['behavior']['fiber_zscore_aligned'].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a78d5119ec0cb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:23:52.974140Z",
     "start_time": "2026-01-05T09:23:50.705980Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _binary_runs(time, binary_vec):\n",
    "    \"\"\"\n",
    "    Return list of (t_start, t_end) for contiguous True runs in binary_vec.\n",
    "    time: 1D array\n",
    "    binary_vec: 1D bool array same length as time\n",
    "    \"\"\"\n",
    "    time = np.asarray(time, float)\n",
    "    b = np.asarray(binary_vec, bool)\n",
    "    if time.size == 0 or b.size == 0 or time.size != b.size:\n",
    "        return []\n",
    "\n",
    "    db = np.diff(b.astype(int))\n",
    "    starts = np.where(db == 1)[0] + 1\n",
    "    ends = np.where(db == -1)[0] + 1\n",
    "\n",
    "    if b[0]:\n",
    "        starts = np.r_[0, starts]\n",
    "    if b[-1]:\n",
    "        ends = np.r_[ends, b.size]\n",
    "\n",
    "    runs = []\n",
    "    for s, e in zip(starts, ends):\n",
    "        t0 = time[s]\n",
    "        t1 = time[e - 1] if (e - 1) < time.size else time[-1]\n",
    "        runs.append((float(t0), float(t1)))\n",
    "    return runs\n",
    "\n",
    "\n",
    "# results_by_key should already exist from the previous step:\n",
    "# results_by_key = {(r[\"animal\"], r[\"condition\"]): r for r in result_list}\n",
    "\n",
    "# Optional: set None for full range, or [start,end]\n",
    "xlim = (160, 220)  # set to None to disable\n",
    "\n",
    "for (animal_id, condition), rec in results_by_key.items():\n",
    "    if \"behavior\" not in rec:\n",
    "        continue\n",
    "\n",
    "    beh = rec[\"behavior\"].copy()\n",
    "\n",
    "    # Time and aligned fiber\n",
    "    if \"time\" not in beh.columns or \"fiber_zscore_aligned\" not in beh.columns:\n",
    "        print(f\"Skipping {animal_id}-{condition}: missing 'time' or 'fiber_zscore_aligned'\")\n",
    "        continue\n",
    "\n",
    "    t = beh[\"time\"].to_numpy(dtype=float)\n",
    "    y = beh[\"fiber_zscore_aligned\"].to_numpy(dtype=float)\n",
    "\n",
    "    # Behavior columns: everything except time, aligned fiber, and optional Frames\n",
    "    behavior_cols = [c for c in beh.columns if c not in (\"time\", \"fiber_zscore_aligned\", \"Frames\")]\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 4))\n",
    "    ax.plot(t, y, lw=1.0, label=\"Fiber z-score (aligned)\")\n",
    "\n",
    "    # Colors\n",
    "    color_cycle = plt.rcParams[\"axes.prop_cycle\"].by_key().get(\"color\", [])\n",
    "    if not color_cycle:\n",
    "        color_cycle = [\"C0\",\"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"C8\",\"C9\"]\n",
    "\n",
    "    legend_handles = []\n",
    "    legend_labels = []\n",
    "\n",
    "    # For duration stats\n",
    "    dt = np.nanmedian(np.diff(t)) if t.size > 2 else np.nan\n",
    "\n",
    "    avg_durations = {}  # behavior -> mean duration (s)\n",
    "    n_bouts = {}        # behavior -> number of bouts\n",
    "\n",
    "    for i, col in enumerate(behavior_cols):\n",
    "        vals = beh[col].to_numpy()\n",
    "\n",
    "        # interpret as binary (robust)\n",
    "        b = np.isfinite(vals) & (vals > 0.5)\n",
    "\n",
    "        runs = _binary_runs(t, b)\n",
    "        if not runs:\n",
    "            continue\n",
    "\n",
    "        color = color_cycle[i % len(color_cycle)]\n",
    "\n",
    "        # shade all bouts\n",
    "        for (t0, t1) in runs:\n",
    "            ax.axvspan(t0, t1, alpha=0.20, color=color)\n",
    "\n",
    "        # legend (one entry per behavior)\n",
    "        legend_handles.append(plt.Line2D([0], [0], color=color, lw=6, alpha=0.35))\n",
    "        legend_labels.append(col)\n",
    "\n",
    "        # duration stats\n",
    "        durations = [(t1 - t0) for (t0, t1) in runs if np.isfinite(t0) and np.isfinite(t1)]\n",
    "        if len(durations) > 0:\n",
    "            avg_durations[col] = float(np.mean(durations))\n",
    "            n_bouts[col] = int(len(durations))\n",
    "\n",
    "    ax.set_title(f\"{animal_id} — {condition} | Fiber aligned to behavior\")\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Fiber z-score\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim[0], xlim[1])\n",
    "\n",
    "    # Put behavior legend outside\n",
    "    if legend_handles:\n",
    "        ax.legend(legend_handles, legend_labels, loc=\"center left\",\n",
    "                  bbox_to_anchor=(1.01, 0.5), title=\"Behaviors\")\n",
    "    else:\n",
    "        ax.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ---- print average duration of each behavior ----\n",
    "    if avg_durations:\n",
    "        print(f\"{animal_id}-{condition}: average bout duration (s)\")\n",
    "        for k in sorted(avg_durations.keys()):\n",
    "            print(f\"  {k:>20s}: {avg_durations[k]:.3f}  (n_bouts={n_bouts[k]})\")\n",
    "    else:\n",
    "        print(f\"{animal_id}-{condition}: no behavior bouts found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c391089ddfdc2313",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:26:00.656015Z",
     "start_time": "2026-01-05T09:26:00.642499Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def _compute_psth_matrix(\n",
    "    t: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    event_times: np.ndarray,\n",
    "    window: Tuple[float, float],\n",
    "    baseline_win: Tuple[float, float],\n",
    "    resample_hz: float,\n",
    "    smooth_sigma_s: float = 0.0,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      tvec (relative time), mat (n_events x n_samples) with NaNs if missing\n",
    "    \"\"\"\n",
    "    t = np.asarray(t, float)\n",
    "    y = np.asarray(y, float)\n",
    "    ev = np.asarray(event_times, float)\n",
    "    ev = ev[np.isfinite(ev)]\n",
    "    if ev.size == 0:\n",
    "        return np.array([], float), np.zeros((0, 0), float)\n",
    "\n",
    "    dt = 1.0 / float(resample_hz)\n",
    "    tvec = np.arange(window[0], window[1] + 0.5 * dt, dt)\n",
    "\n",
    "    mat = np.full((ev.size, tvec.size), np.nan, float)\n",
    "\n",
    "    for i, et in enumerate(ev):\n",
    "        # baseline\n",
    "        bmask = (t >= et + baseline_win[0]) & (t <= et + baseline_win[1])\n",
    "        base = y[bmask]\n",
    "        if base.size < 5 or not np.any(np.isfinite(base)):\n",
    "            continue\n",
    "        bmean = np.nanmean(base)\n",
    "        bstd = np.nanstd(base)\n",
    "        if not np.isfinite(bstd) or bstd <= 1e-12:\n",
    "            bstd = 1.0\n",
    "        bstd = max(bstd, 0.05)\n",
    "\n",
    "\n",
    "\n",
    "        # extract window and interpolate onto tvec\n",
    "        wmask = (t >= et + window[0]) & (t <= et + window[1])\n",
    "        tw = t[wmask] - et\n",
    "        yw = y[wmask]\n",
    "        good = np.isfinite(tw) & np.isfinite(yw)\n",
    "        if np.sum(good) < 5:\n",
    "            continue\n",
    "        # sparse interpolation\n",
    "        mat[i, :] = np.interp(tvec, tw[good], (yw[good] - bmean) / bstd)\n",
    "\n",
    "    if smooth_sigma_s and smooth_sigma_s > 0:\n",
    "        # simple gaussian smoothing along time axis\n",
    "        sigma = smooth_sigma_s * resample_hz\n",
    "        mat = gaussian_filter1d(mat, sigma=sigma, axis=1, mode=\"nearest\")\n",
    "\n",
    "    return tvec, mat\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def extract_events(\n",
    "    time,\n",
    "    binary_vec,\n",
    "    *,\n",
    "    threshold=0.5,\n",
    "    min_isi_s=0,\n",
    "    min_duration_s=0.5,\n",
    "    max_duration_s=None,\n",
    "):\n",
    "\n",
    "    t = np.asarray(time, float)\n",
    "    v = np.asarray(binary_vec, float)\n",
    "\n",
    "    good = np.isfinite(t) & np.isfinite(v)\n",
    "    t = t[good]\n",
    "    v = v[good]\n",
    "\n",
    "    if t.size < 2:\n",
    "        return {\n",
    "            \"onset_s\": np.array([], dtype=float),\n",
    "            \"offset_s\": np.array([], dtype=float),\n",
    "            \"duration_s\": np.array([], dtype=float),\n",
    "            \"order\": np.array([], dtype=int),\n",
    "            \"n_events\": 0,\n",
    "        }\n",
    "\n",
    "    b = v > threshold\n",
    "    if not np.any(b):\n",
    "        return {\n",
    "            \"onset_s\": np.array([], dtype=float),\n",
    "            \"offset_s\": np.array([], dtype=float),\n",
    "            \"duration_s\": np.array([], dtype=float),\n",
    "            \"order\": np.array([], dtype=int),\n",
    "            \"n_events\": 0,\n",
    "        }\n",
    "\n",
    "    # transitions in/out of True\n",
    "    db = np.diff(b.astype(int))\n",
    "    starts = np.where(db == 1)[0] + 1\n",
    "    ends = np.where(db == -1)[0] + 1  # end is exclusive\n",
    "\n",
    "    if b[0]:\n",
    "        starts = np.r_[0, starts]\n",
    "    if b[-1]:\n",
    "        ends = np.r_[ends, b.size]\n",
    "\n",
    "    on = t[starts]\n",
    "    off_last = t[ends - 1]\n",
    "\n",
    "    # Estimate dt for a better continuous-time offset estimate\n",
    "    dt = float(np.nanmedian(np.diff(t))) if t.size > 2 else 0.0\n",
    "    off = off_last + dt\n",
    "    dur = off - on\n",
    "\n",
    "    # Merge bouts based on onset spacing\n",
    "    if min_isi_s and on.size > 1:\n",
    "        merged_on = [on[0]]\n",
    "        merged_off = [off[0]]\n",
    "\n",
    "        for i in range(1, on.size):\n",
    "            if (on[i] - merged_on[-1]) < float(min_isi_s):\n",
    "                merged_off[-1] = max(merged_off[-1], off[i])\n",
    "            else:\n",
    "                merged_on.append(on[i])\n",
    "                merged_off.append(off[i])\n",
    "\n",
    "        on = np.asarray(merged_on, float)\n",
    "        off = np.asarray(merged_off, float)\n",
    "        dur = off - on\n",
    "\n",
    "    # Duration filtering\n",
    "    keep = np.ones_like(dur, dtype=bool)\n",
    "    if min_duration_s is not None:\n",
    "        keep &= dur >= float(min_duration_s)\n",
    "    if max_duration_s is not None:\n",
    "        keep &= dur <= float(max_duration_s)\n",
    "\n",
    "    on = on[keep]\n",
    "    off = off[keep]\n",
    "    dur = dur[keep]\n",
    "\n",
    "    # Event order (chronological)\n",
    "    order = np.arange(on.size, dtype=int)\n",
    "\n",
    "    return {\n",
    "        \"onset_s\": on,\n",
    "        \"offset_s\": off,\n",
    "        \"duration_s\": dur,\n",
    "        \"order\": order,\n",
    "        \"n_events\": int(on.size),\n",
    "    }\n",
    "\n",
    "\n",
    "def get_behavior_cols_for_animal(animal_id):\n",
    "    cols_union, seen = [], set()\n",
    "    for cond in cond_order:\n",
    "        rec = results_by_key.get((animal_id, cond))\n",
    "        if rec is None or \"behavior\" not in rec:\n",
    "            continue\n",
    "        beh = rec[\"behavior\"]\n",
    "        cols = [c for c in beh.columns if c not in (\"time\", \"fiber_zscore_aligned\", \"Frames\")]\n",
    "        for c in cols:\n",
    "            if c not in seen:\n",
    "                cols_union.append(c)\n",
    "                seen.add(c)\n",
    "    return cols_union\n",
    "\n",
    "def plot_heatmap(ax, tvec, mat, title, show_ylabel=False):\n",
    "    im = ax.imshow(\n",
    "        mat,\n",
    "        aspect=\"auto\",\n",
    "        origin=\"lower\",\n",
    "        extent=[tvec[0], tvec[-1], 0, mat.shape[0]],\n",
    "        cmap=cmap,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        interpolation=\"nearest\",\n",
    "    )\n",
    "    ax.axvline(0, color=\"w\", linestyle=\"--\", alpha=0.9, lw=1)\n",
    "    ax.set_title(title, fontsize=10, pad=4)\n",
    "    if show_ylabel:\n",
    "        ax.set_ylabel(\"Trial\", fontsize=9)\n",
    "    ax.tick_params(axis=\"both\", labelsize=8, length=2)\n",
    "    return im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2721e099b285e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:44:39.347435Z",
     "start_time": "2026-01-05T09:44:31.695174Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# Parameters\n",
    "# -----------------------------\n",
    "window = (-3, 5)\n",
    "baseline_win = (-3, 0)\n",
    "smooth_sigma_s = 0.1\n",
    "\n",
    "vmin, vmax = -3, 3\n",
    "cmap = \"viridis\"\n",
    "min_trials = 2\n",
    "\n",
    "# Duration filter for events (seconds)\n",
    "min_duration_s = 0.1   # <- you used 0.1 in your snippet; change as needed\n",
    "max_duration_s = None\n",
    "\n",
    "# Layout\n",
    "figsize_base = (20, 2.25)  # (width, height_per_behavior_row)\n",
    "mean_ylim = (-2, 2)\n",
    "\n",
    "# Condition order & colors\n",
    "cond_order = [\"Adu\", \"Juv\", \"Fem\"]\n",
    "cond_colors = {\"Adu\": \"tab:blue\", \"Juv\": \"tab:green\", \"Fem\": \"tab:pink\"}\n",
    "cond_alpha_line = 0.9\n",
    "cond_alpha_fill = 0.25\n",
    "\n",
    "# Storage dict (NEW)\n",
    "psth_store = {}\n",
    "\n",
    "# -----------------------------\n",
    "# Plot: per animal\n",
    "# -----------------------------\n",
    "animals = sorted(set([k[0] for k in results_by_key.keys()]))\n",
    "\n",
    "for animal_id in animals:\n",
    "    behavior_cols = get_behavior_cols_for_animal(animal_id)\n",
    "    if not behavior_cols:\n",
    "        print(f\"{animal_id}: no behavior columns found in any condition.\")\n",
    "        continue\n",
    "\n",
    "    n_beh = len(behavior_cols)\n",
    "    fig_w = figsize_base[0]\n",
    "    fig_h = max(4, figsize_base[1] * n_beh)\n",
    "    fig = plt.figure(figsize=(fig_w, fig_h), constrained_layout=False)\n",
    "\n",
    "    gs = fig.add_gridspec(\n",
    "        nrows=n_beh, ncols=4,\n",
    "        width_ratios=[1.05, 1.05, 1.05, 1.25],\n",
    "        wspace=0.35, hspace=0.60\n",
    "    )\n",
    "\n",
    "    fig.suptitle(f\"{animal_id} — PSTH heatmaps per condition + mean overlay\", y=0.995, fontsize=14)\n",
    "\n",
    "    heatmap_images = []\n",
    "    any_plotted_anywhere = False\n",
    "\n",
    "    for r, beh_name in enumerate(behavior_cols):\n",
    "        ax_hm = {cond: fig.add_subplot(gs[r, c]) for c, cond in enumerate(cond_order)}\n",
    "        ax_mean = fig.add_subplot(gs[r, 3])\n",
    "\n",
    "        # Mean axis styling\n",
    "        ax_mean.axvline(0, color=\"k\", linestyle=\"--\", alpha=0.5, lw=1)\n",
    "        ax_mean.axhline(0, color=\"gray\", linestyle=\":\", alpha=0.7)\n",
    "        ax_mean.set_title(f\"{beh_name} — mean\", fontsize=10, pad=4)\n",
    "        ax_mean.set_ylabel(\"Z\", fontsize=9)\n",
    "        ax_mean.set_ylim(*mean_ylim)\n",
    "        ax_mean.grid(True, alpha=0.15)\n",
    "        ax_mean.tick_params(axis=\"both\", labelsize=8, length=2)\n",
    "\n",
    "        # Condition headers only on first row\n",
    "        if r == 0:\n",
    "            for cond in cond_order:\n",
    "                ax_hm[cond].set_title(cond, fontsize=11, pad=6)\n",
    "\n",
    "        ax_hm[\"Adu\"].set_ylabel(f\"{beh_name}\\nTrial\", fontsize=9)\n",
    "\n",
    "        any_cond_plotted = False\n",
    "        tvec_ref = None\n",
    "\n",
    "        for cond in cond_order:\n",
    "            rec = results_by_key.get((animal_id, cond), None)\n",
    "            ax = ax_hm[cond]\n",
    "\n",
    "            if rec is None or \"behavior\" not in rec:\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            beh = rec[\"behavior\"]\n",
    "            if (\"time\" not in beh.columns) or (\"fiber_zscore_aligned\" not in beh.columns) or (beh_name not in beh.columns):\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            fiber_time = beh[\"time\"].to_numpy(dtype=float)\n",
    "            fiber_trace = beh[\"fiber_zscore_aligned\"].to_numpy(dtype=float)\n",
    "\n",
    "            # ---- Use event dictionary ----\n",
    "            ev = extract_events(\n",
    "                fiber_time, beh[beh_name].to_numpy(),\n",
    "                threshold=0,\n",
    "                min_isi_s=0,\n",
    "                min_duration_s=min_duration_s,\n",
    "                max_duration_s=max_duration_s,\n",
    "            )\n",
    "            onsets = np.asarray(ev[\"onset_s\"], float)\n",
    "\n",
    "            # Store events even if not enough trials (NEW, useful for QA)\n",
    "            psth_store[(animal_id, cond, beh_name)] = {\n",
    "                \"tvec\": None,\n",
    "                \"psth_matrix\": None,\n",
    "                \"mean\": None,\n",
    "                \"sem\": None,\n",
    "                \"n_trials\": 0,\n",
    "                \"events\": ev,\n",
    "                \"params\": {\n",
    "                    \"window\": window,\n",
    "                    \"baseline_win\": baseline_win,\n",
    "                    \"smooth_sigma_s\": smooth_sigma_s,\n",
    "                    \"min_trials\": min_trials,\n",
    "                    \"min_duration_s\": min_duration_s,\n",
    "                    \"max_duration_s\": max_duration_s,\n",
    "                },\n",
    "            }\n",
    "\n",
    "            if onsets.size < min_trials:\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            # PSTH\n",
    "            tvec, mat = _compute_psth_matrix(\n",
    "                fiber_time, fiber_trace, onsets,\n",
    "                window=window, baseline_win=baseline_win, smooth_sigma_s=smooth_sigma_s, resample_hz=60\n",
    "            )\n",
    "            mat = mat[~np.isnan(mat).all(axis=1)]\n",
    "            if mat.shape[0] < min_trials:\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            # Compute summary\n",
    "            mean_trace = np.nanmean(mat, axis=0)\n",
    "            sem_trace = np.nanstd(mat, axis=0) / np.sqrt(mat.shape[0])\n",
    "\n",
    "            # Store PSTH data (NEW)\n",
    "            psth_store[(animal_id, cond, beh_name)].update({\n",
    "                \"tvec\": tvec,\n",
    "                \"psth_matrix\": mat,\n",
    "                \"mean\": mean_trace,\n",
    "                \"sem\": sem_trace,\n",
    "                \"n_trials\": int(mat.shape[0]),\n",
    "            })\n",
    "\n",
    "            any_plotted_anywhere = True\n",
    "            any_cond_plotted = True\n",
    "            if tvec_ref is None:\n",
    "                tvec_ref = tvec\n",
    "\n",
    "            # Heatmap\n",
    "            im = plot_heatmap(\n",
    "                ax, tvec, mat,\n",
    "                title=f\"{cond} (n={mat.shape[0]})\",\n",
    "                show_ylabel=(cond == \"Adu\")\n",
    "            )\n",
    "            heatmap_images.append(im)\n",
    "\n",
    "            # Mean overlay\n",
    "            ax_mean.plot(\n",
    "                tvec, mean_trace,\n",
    "                color=cond_colors[cond],\n",
    "                alpha=cond_alpha_line,\n",
    "                lw=1.4,\n",
    "                label=cond\n",
    "            )\n",
    "            ax_mean.fill_between(\n",
    "                tvec, mean_trace - sem_trace, mean_trace + sem_trace,\n",
    "                color=cond_colors[cond],\n",
    "                alpha=cond_alpha_fill,\n",
    "                linewidth=0\n",
    "            )\n",
    "\n",
    "        # Row formatting\n",
    "        if any_cond_plotted and tvec_ref is not None:\n",
    "            ax_mean.set_xlim(tvec_ref[0], tvec_ref[-1])\n",
    "            ax_mean.legend(frameon=False, fontsize=8, loc=\"upper right\")\n",
    "            ax_mean.set_xlabel(\"Time from onset (s)\", fontsize=9)\n",
    "            for cond in cond_order:\n",
    "                ax_hm[cond].set_xlabel(\"Time (s)\", fontsize=9)\n",
    "        else:\n",
    "            ax_mean.axis(\"off\")\n",
    "            for cond in cond_order:\n",
    "                ax_hm[cond].axis(\"off\")\n",
    "\n",
    "    if not any_plotted_anywhere:\n",
    "        plt.close(fig)\n",
    "        print(f\"{animal_id}: nothing plotted (not enough events after filtering).\")\n",
    "        continue\n",
    "\n",
    "    # Shared colorbar\n",
    "    if heatmap_images:\n",
    "        cbar = fig.colorbar(\n",
    "            heatmap_images[0],\n",
    "            ax=fig.axes,\n",
    "            fraction=0.015,\n",
    "            pad=0.01,\n",
    "            shrink=0.85\n",
    "        )\n",
    "        cbar.set_label(\"Z-score\", fontsize=10)\n",
    "        cbar.ax.tick_params(labelsize=9, length=2)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.985])\n",
    "    plt.show()\n",
    "\n",
    "print(f\"Stored PSTHs in psth_store for {len(psth_store)} (animal, condition, behavior) keys.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "46f3f4cac567795a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:30:04.206730Z",
     "start_time": "2026-01-05T09:30:04.202715Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import ttest_1samp, ttest_rel, friedmanchisquare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9a6ec87239bd8ebd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:30:07.409840Z",
     "start_time": "2026-01-05T09:30:07.401791Z"
    }
   },
   "outputs": [],
   "source": [
    "def strip_spines(ax):\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "def interp_to_grid(tvec, y, tgrid):\n",
    "    tvec = np.asarray(tvec, float)\n",
    "    y = np.asarray(y, float)\n",
    "    m = np.isfinite(tvec) & np.isfinite(y)\n",
    "    if np.sum(m) < 2:\n",
    "        return np.full_like(tgrid, np.nan, dtype=float)\n",
    "    return np.interp(tgrid, tvec[m], y[m], left=np.nan, right=np.nan)\n",
    "\n",
    "def auc_in_window(t, y, lo, hi):\n",
    "    t = np.asarray(t, float)\n",
    "    y = np.asarray(y, float)\n",
    "    m = np.isfinite(t) & np.isfinite(y) & (t >= lo) & (t <= hi)\n",
    "    if np.sum(m) < 2:\n",
    "        return np.nan\n",
    "    return float(np.trapz(y[m], t[m]))\n",
    "\n",
    "def p_to_stars(p):\n",
    "    if not np.isfinite(p):\n",
    "        return \"n/a\"\n",
    "    if p < 1e-3:\n",
    "        return \"***\"\n",
    "    if p < 1e-2:\n",
    "        return \"**\"\n",
    "    if p < 5e-2:\n",
    "        return \"*\"\n",
    "    return \"ns\"\n",
    "\n",
    "def holm_adjust(pvals_dict):\n",
    "    \"\"\"\n",
    "    Holm correction. Input: dict[key -> p]. Output: dict[key -> p_adj].\n",
    "    \"\"\"\n",
    "    keys = list(pvals_dict.keys())\n",
    "    items = [(k, pvals_dict[k]) for k in keys if np.isfinite(pvals_dict[k])]\n",
    "    out = {k: np.nan for k in keys}\n",
    "    if not items:\n",
    "        return out\n",
    "\n",
    "    items = sorted(items, key=lambda kv: kv[1])\n",
    "    m = len(items)\n",
    "    for i, (k, p) in enumerate(items):\n",
    "        out[k] = min(1.0, p * (m - i))\n",
    "\n",
    "    # monotone non-decreasing\n",
    "    running = 0.0\n",
    "    for k, _p in items:\n",
    "        running = max(running, out[k])\n",
    "        out[k] = running\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4952397e92d95caf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:30:11.476806Z",
     "start_time": "2026-01-05T09:30:11.472763Z"
    }
   },
   "outputs": [],
   "source": [
    "# Conditions\n",
    "cond_order = [\"Adu\", \"Juv\", \"Fem\"]\n",
    "cond_colors = {\"Adu\": \"tab:blue\", \"Juv\": \"tab:green\", \"Fem\": \"tab:pink\"}\n",
    "\n",
    "# AUC windows\n",
    "auc_pre = (-2, 0)\n",
    "auc_post = (0, 2)\n",
    "\n",
    "# Heatmap display range (reduced)\n",
    "vmin, vmax = -1, 1\n",
    "cmap = \"viridis\"\n",
    "\n",
    "# Minimum trials per (animal,cond,beh) to include in summary\n",
    "min_trials_for_summary = 2\n",
    "\n",
    "# Time grid for aggregation\n",
    "tgrid = np.linspace(-3, 5, 400)\n",
    "\n",
    "# Exclude behaviors\n",
    "exclude_behaviors = {\"fighting\",\"mounting\"}  # case-insensitive match\n",
    "\n",
    "# Figure layout\n",
    "fig_w = 24\n",
    "row_h = 1.90\n",
    "\n",
    "# columns: Adu hm, Juv hm, Fem hm, GRAND MEAN (bigger), Delta AUC\n",
    "width_ratios = [1.0, 1.0, 1.25, 2, 0.7]  # <-- grand mean column is larger now\n",
    "wspace = 0.18\n",
    "hspace = 0.40\n",
    "\n",
    "# Axis limits\n",
    "mean_ylim = (-1.2, 2.2)\n",
    "mean_xlim = (-3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c599939e90738399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:30:14.793554Z",
     "start_time": "2026-01-05T09:30:14.782954Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collect animals + behaviors from psth_store\n",
    "animals = sorted(set([k[0] for k in psth_store.keys()]))\n",
    "behaviors_all = sorted(set([k[2] for k in psth_store.keys()]))\n",
    "\n",
    "behaviors = []\n",
    "for b in behaviors_all:\n",
    "    if b is None:\n",
    "        continue\n",
    "    if str(b).strip().lower() in exclude_behaviors:\n",
    "        continue\n",
    "    behaviors.append(b)\n",
    "\n",
    "if not animals:\n",
    "    raise RuntimeError(\"No animals found in psth_store.\")\n",
    "if not behaviors:\n",
    "    raise RuntimeError(\"No behaviors left after exclusions.\")\n",
    "\n",
    "# mats[(beh, cond)] = (animal_ids_used, M) where M is (n_animals, len(tgrid))\n",
    "mats = {}\n",
    "# deltas[(beh, cond)] = dict with animals list and delta array\n",
    "deltas = {}\n",
    "\n",
    "for beh in behaviors:\n",
    "    for cond in cond_order:\n",
    "        rows = []\n",
    "        used_animals = []\n",
    "        dA = []\n",
    "\n",
    "        for animal in animals:\n",
    "            key = (animal, cond, beh)\n",
    "            if key not in psth_store:\n",
    "                continue\n",
    "\n",
    "            entry = psth_store[key]\n",
    "            if entry.get(\"mean\") is None or entry.get(\"tvec\") is None:\n",
    "                continue\n",
    "            if int(entry.get(\"n_trials\", 0)) < min_trials_for_summary:\n",
    "                continue\n",
    "\n",
    "            y = interp_to_grid(entry[\"tvec\"], entry[\"mean\"], tgrid)\n",
    "            if np.all(~np.isfinite(y)):\n",
    "                continue\n",
    "\n",
    "            rows.append(y)\n",
    "            used_animals.append(animal)\n",
    "\n",
    "            pre = auc_in_window(tgrid, y, auc_pre[0], auc_pre[1])\n",
    "            post = auc_in_window(tgrid, y, auc_post[0], auc_post[1])\n",
    "            dA.append(post - pre if np.isfinite(pre) and np.isfinite(post) else np.nan)\n",
    "\n",
    "        M = np.vstack(rows) if rows else np.zeros((0, tgrid.size), dtype=float)\n",
    "        mats[(beh, cond)] = (used_animals, M)\n",
    "        deltas[(beh, cond)] = {\"animals\": used_animals, \"delta\": np.asarray(dA, float)}\n",
    "\n",
    "# Drop behaviors with no data in all conditions\n",
    "behaviors_kept = []\n",
    "for beh in behaviors:\n",
    "    if any(mats[(beh, c)][1].shape[0] > 0 for c in cond_order):\n",
    "        behaviors_kept.append(beh)\n",
    "behaviors = behaviors_kept\n",
    "\n",
    "print(f\"Summary prepared for {len(behaviors)} behaviors, {len(animals)} animals.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cbec73f99ae156e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:30:21.113568Z",
     "start_time": "2026-01-05T09:30:21.094010Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_summary_psth_deltaAUC(\n",
    "    behaviors,\n",
    "    mats,\n",
    "    deltas,\n",
    "    *,\n",
    "    tgrid,\n",
    "    cond_order,\n",
    "    cond_colors,\n",
    "    vmin=-1.5,\n",
    "    vmax=1.5,\n",
    "    cmap=\"viridis\",\n",
    "    fig_w=24,\n",
    "    row_h=1.9,\n",
    "    width_ratios=(1,1,1.25,2,0.8),\n",
    "    wspace=0.18,\n",
    "    hspace=0.40,\n",
    "    mean_ylim=(-1.2, 2.2),\n",
    "):\n",
    "    plt.rcParams.update({\n",
    "        \"font.size\": 9,\n",
    "        \"axes.titlesize\": 10,\n",
    "        \"axes.labelsize\": 9,\n",
    "        \"xtick.labelsize\": 8,\n",
    "        \"ytick.labelsize\": 8,\n",
    "    })\n",
    "\n",
    "    nrows = len(behaviors)\n",
    "    fig_h = max(6, row_h * nrows)\n",
    "\n",
    "    fig = plt.figure(figsize=(fig_w, fig_h))\n",
    "    gs = fig.add_gridspec(\n",
    "        nrows=nrows, ncols=5,\n",
    "        width_ratios=list(width_ratios),\n",
    "        wspace=wspace, hspace=hspace\n",
    "    )\n",
    "\n",
    "    # Column headers (top row only)\n",
    "    headers = [\"Adu\", \"Juv\", \"Fem\", \"Grand mean (±SEM)\", \"ΔAUC (post−pre)\"]\n",
    "    for ci, title in enumerate(headers):\n",
    "        axh = fig.add_subplot(gs[0, ci])\n",
    "        axh.set_title(title, pad=10)\n",
    "        axh.axis(\"off\")\n",
    "\n",
    "    heatmap_axes = []\n",
    "    heatmap_mappable = None\n",
    "\n",
    "    for r, beh in enumerate(behaviors):\n",
    "        # -----------------\n",
    "        # Heatmaps: cols 0..2\n",
    "        # -----------------\n",
    "        for c_i, cond in enumerate(cond_order):\n",
    "            ax = fig.add_subplot(gs[r, c_i])\n",
    "            strip_spines(ax)\n",
    "\n",
    "            used_animals, M = mats[(beh, cond)]\n",
    "            if M.shape[0] == 0:\n",
    "                ax.axis(\"off\")\n",
    "                if c_i == 0:\n",
    "                    ax.text(0.0, 0.5, f\"{beh}\\n(no data)\", transform=ax.transAxes,\n",
    "                            ha=\"left\", va=\"center\")\n",
    "                continue\n",
    "\n",
    "            im = ax.imshow(\n",
    "                M, aspect=\"auto\", origin=\"lower\",\n",
    "                extent=[tgrid[0], tgrid[-1], 0, M.shape[0]],\n",
    "                cmap=cmap, vmin=vmin, vmax=vmax, interpolation=\"nearest\"\n",
    "            )\n",
    "            heatmap_mappable = im\n",
    "            heatmap_axes.append(ax)\n",
    "\n",
    "            ax.axvline(0, color=\"w\", linestyle=\"--\", lw=1, alpha=0.9)\n",
    "\n",
    "            if c_i == 0:\n",
    "                ax.set_ylabel(f\"{beh}\\nAnimal\", labelpad=6)\n",
    "            else:\n",
    "                ax.set_yticks([])\n",
    "\n",
    "            if r == nrows - 1:\n",
    "                ax.set_xlabel(\"Time (s)\")\n",
    "            else:\n",
    "                ax.tick_params(labelbottom=False)\n",
    "\n",
    "            ax.tick_params(length=2)\n",
    "\n",
    "        # -----------------\n",
    "        # Grand mean: col 3 (bigger)\n",
    "        # -----------------\n",
    "        axm = fig.add_subplot(gs[r, 3])\n",
    "        strip_spines(axm)\n",
    "        axm.axvline(0, color=\"k\", linestyle=\"--\", lw=1, alpha=0.35)\n",
    "        axm.axhline(0, color=\"gray\", linestyle=\":\", lw=1, alpha=0.6)\n",
    "        axm.grid(True, alpha=0.15)\n",
    "\n",
    "        any_plotted = False\n",
    "        for cond in cond_order:\n",
    "            used_animals, M = mats[(beh, cond)]\n",
    "            if M.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            mu = np.nanmean(M, axis=0)\n",
    "            n_eff = np.sum(np.isfinite(M).any(axis=1))\n",
    "            se = np.nanstd(M, axis=0) / np.sqrt(n_eff) if n_eff > 1 else np.full_like(mu, np.nan)\n",
    "\n",
    "            axm.plot(tgrid, mu, color=cond_colors[cond], lw=2.0, alpha=0.95,\n",
    "                     label=f\"{cond} (n={M.shape[0]})\")\n",
    "            axm.fill_between(tgrid, mu - se, mu + se, color=cond_colors[cond],\n",
    "                             alpha=0.20, linewidth=0)\n",
    "            any_plotted = True\n",
    "\n",
    "        axm.set_xlim(tgrid[0], tgrid[-1])\n",
    "        axm.set_ylim(*mean_ylim)\n",
    "        axm.set_ylabel(\"Z\")\n",
    "\n",
    "        if r == nrows - 1:\n",
    "            axm.set_xlabel(\"Time (s)\")\n",
    "        else:\n",
    "            axm.tick_params(labelbottom=False)\n",
    "\n",
    "        if any_plotted:\n",
    "            axm.legend(frameon=False, fontsize=8, loc=\"upper right\")\n",
    "\n",
    "        # -----------------\n",
    "        # ΔAUC: col 4 with one-sample t-tests vs 0 + Friedman across conditions\n",
    "        # -----------------\n",
    "        axd = fig.add_subplot(gs[r, 4])\n",
    "        strip_spines(axd)\n",
    "        axd.grid(True, axis=\"y\", alpha=0.15)\n",
    "        axd.axhline(0, color=\"gray\", linestyle=\":\", lw=1, alpha=0.7)\n",
    "\n",
    "        x = np.arange(len(cond_order), dtype=float)\n",
    "        rng = np.random.default_rng(0)\n",
    "\n",
    "        # per-condition deltas + one-sample t-test vs 0\n",
    "        means, ns, p_vs0 = [], [], {}\n",
    "        cond_delta = {}\n",
    "\n",
    "        for cond in cond_order:\n",
    "            d = deltas[(beh, cond)][\"delta\"]\n",
    "            d = d[np.isfinite(d)]\n",
    "            cond_delta[cond] = d\n",
    "            ns.append(int(d.size))\n",
    "            means.append(np.nanmean(d) if d.size else np.nan)\n",
    "\n",
    "            if d.size >= 2:\n",
    "                p_vs0[cond] = float(ttest_1samp(d, 0.0, nan_policy=\"omit\").pvalue)\n",
    "            else:\n",
    "                p_vs0[cond] = np.nan\n",
    "\n",
    "        axd.bar(x, means, alpha=0.55, edgecolor=\"none\")\n",
    "\n",
    "        for i, cond in enumerate(cond_order):\n",
    "            d = cond_delta[cond]\n",
    "            if d.size == 0:\n",
    "                continue\n",
    "            jitter = (rng.random(d.size) - 0.5) * 0.16\n",
    "            axd.scatter(x[i] + jitter, d, s=18, color=cond_colors[cond], alpha=0.85, edgecolors=\"none\")\n",
    "\n",
    "            axd.text(\n",
    "                x[i],\n",
    "                (means[i] if np.isfinite(means[i]) else 0.0) + 0.08*np.sign(means[i] if np.isfinite(means[i]) else 1),\n",
    "                f\"{p_to_stars(p_vs0[cond])}\\n(n={ns[i]})\",\n",
    "                ha=\"center\", va=\"bottom\", fontsize=8\n",
    "            )\n",
    "\n",
    "        axd.set_xticks(x)\n",
    "        axd.set_xticklabels(cond_order)\n",
    "        axd.set_ylabel(\"ΔAUC\")\n",
    "\n",
    "        # Friedman (paired across conditions) on complete cases\n",
    "        per_cond_map = {}\n",
    "        sets = []\n",
    "        for cond in cond_order:\n",
    "            a_ids = deltas[(beh, cond)][\"animals\"]\n",
    "            d_vals = deltas[(beh, cond)][\"delta\"]\n",
    "            per_cond_map[cond] = {a: dv for a, dv in zip(a_ids, d_vals) if np.isfinite(dv)}\n",
    "            sets.append(set(per_cond_map[cond].keys()))\n",
    "\n",
    "        common = sorted(list(set.intersection(*sets))) if sets else []\n",
    "        fried_p = np.nan\n",
    "\n",
    "        if len(common) >= 3:\n",
    "            X = np.vstack([[per_cond_map[cond][a] for a in common] for cond in cond_order])\n",
    "            try:\n",
    "                fried_p = float(friedmanchisquare(X[0], X[1], X[2]).pvalue)\n",
    "            except Exception:\n",
    "                fried_p = np.nan\n",
    "\n",
    "            # If Friedman significant, do pairwise paired t-tests with Holm correction\n",
    "            if np.isfinite(fried_p) and fried_p < 0.05:\n",
    "                raw = {}\n",
    "                pairs = [(\"Adu\", \"Juv\"), (\"Adu\", \"Fem\"), (\"Juv\", \"Fem\")]\n",
    "                for a, b in pairs:\n",
    "                    xa = np.array([per_cond_map[a][k] for k in common], float)\n",
    "                    xb = np.array([per_cond_map[b][k] for k in common], float)\n",
    "                    raw[(a, b)] = float(ttest_rel(xa, xb, nan_policy=\"omit\").pvalue)\n",
    "                adj = holm_adjust(raw)\n",
    "\n",
    "                # annotate pairwise brackets compactly\n",
    "                y0 = np.nanmax([m for m in means if np.isfinite(m)] + [0.0]) + 0.25\n",
    "                step = 0.18\n",
    "                idx = {\"Adu\": 0, \"Juv\": 1, \"Fem\": 2}\n",
    "\n",
    "                def bracket(i, j, y, txt):\n",
    "                    axd.plot([i, i, j, j], [y, y+0.04, y+0.04, y], color=\"k\", lw=0.8)\n",
    "                    axd.text((i+j)/2, y+0.045, txt, ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "\n",
    "                kline = 0\n",
    "                for (a, b), p in adj.items():\n",
    "                    if not np.isfinite(p):\n",
    "                        continue\n",
    "                    bracket(idx[a], idx[b], y0 + kline*step, p_to_stars(p))\n",
    "                    kline += 1\n",
    "\n",
    "        # compact title with Friedman p\n",
    "        if np.isfinite(fried_p):\n",
    "            axd.set_title(f\"{beh} | Friedman p={fried_p:.3g}\", fontsize=9, pad=4)\n",
    "        else:\n",
    "            axd.set_title(f\"{beh}\", fontsize=9, pad=4)\n",
    "\n",
    "        if r == nrows - 1:\n",
    "            axd.set_xlabel(\"Condition\")\n",
    "        axd.tick_params(length=2)\n",
    "\n",
    "    # Shared colorbar\n",
    "    if heatmap_mappable is not None and heatmap_axes:\n",
    "        cbar = fig.colorbar(\n",
    "            heatmap_mappable,\n",
    "            ax=heatmap_axes,\n",
    "            fraction=0.02,\n",
    "            pad=0.01,\n",
    "            shrink=0.96\n",
    "        )\n",
    "        cbar.set_label(\"Z-score\")\n",
    "        cbar.ax.tick_params(length=2)\n",
    "\n",
    "    fig.suptitle(\n",
    "        \"Summary across animals: mean PSTH heatmaps, grand means, and ΔAUC (t-tests vs 0)\",\n",
    "        y=0.998\n",
    "    )\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.985])\n",
    "    plt.show()\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b55ddc937211aaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:30:29.227523Z",
     "start_time": "2026-01-05T09:30:28.197404Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plot_summary_psth_deltaAUC(\n",
    "    behaviors,\n",
    "    mats,\n",
    "    deltas,\n",
    "    tgrid=tgrid,\n",
    "    cond_order=cond_order,\n",
    "    cond_colors=cond_colors,\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    cmap=cmap,\n",
    "    fig_w=fig_w,\n",
    "    row_h=row_h,\n",
    "    width_ratios=width_ratios,\n",
    "    wspace=wspace,\n",
    "    hspace=hspace,\n",
    "    mean_ylim=mean_ylim,\n",
    ")\n",
    "\n",
    "# Optional publication export\n",
    "# fig.savefig(\"summary_psth_deltaAUC_ttests.png\", dpi=300, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6c194a738e639b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:31:16.734640Z",
     "start_time": "2026-01-05T09:31:16.710325Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_onset_event_sequence(\n",
    "    beh_df,\n",
    "    behavior_cols,\n",
    "    *,\n",
    "    threshold=0.5,\n",
    "    min_isi_s=0.1,\n",
    "    min_duration_s=None,\n",
    "    max_duration_s=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a sorted event sequence as:\n",
    "      times: np.ndarray shape (n_events,)\n",
    "      labels: np.ndarray shape (n_events,) dtype=object\n",
    "    using extract_events(...) (event dictionary).\n",
    "    \"\"\"\n",
    "    if \"time\" not in beh_df.columns:\n",
    "        return np.array([]), np.array([], dtype=object)\n",
    "\n",
    "    t = beh_df[\"time\"].to_numpy(dtype=float)\n",
    "\n",
    "    all_times = []\n",
    "    all_labels = []\n",
    "\n",
    "    for col in behavior_cols:\n",
    "        if col not in beh_df.columns:\n",
    "            continue\n",
    "        ev = extract_events(\n",
    "            t, beh_df[col].to_numpy(),\n",
    "            threshold=threshold,\n",
    "            min_isi_s=min_isi_s,\n",
    "            min_duration_s=min_duration_s,\n",
    "            max_duration_s=max_duration_s,\n",
    "        )\n",
    "        on = np.asarray(ev[\"onset_s\"], float)\n",
    "        if on.size == 0:\n",
    "            continue\n",
    "        all_times.append(on)\n",
    "        all_labels.append(np.array([col] * on.size, dtype=object))\n",
    "\n",
    "    if not all_times:\n",
    "        return np.array([]), np.array([], dtype=object)\n",
    "\n",
    "    times = np.concatenate(all_times)\n",
    "    labels = np.concatenate(all_labels)\n",
    "\n",
    "    order = np.argsort(times)\n",
    "    return times[order], labels[order]\n",
    "\n",
    "\n",
    "def transition_counts_and_probs(\n",
    "    event_times,\n",
    "    event_labels,\n",
    "    behavior_cols,\n",
    "    *,\n",
    "    max_dt_s=1.0,\n",
    "    drop_self=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute transition counts and row-normalized probabilities.\n",
    "    Transition = next onset within <= max_dt_s.\n",
    "\n",
    "    Returns:\n",
    "      counts: (B,B)\n",
    "      probs:  (B,B) row-normalized (rows sum to 1 when row has outgoing transitions)\n",
    "      row_totals: (B,) number of outgoing transitions per behavior\n",
    "    \"\"\"\n",
    "    B = len(behavior_cols)\n",
    "    idx = {b: i for i, b in enumerate(behavior_cols)}\n",
    "\n",
    "    counts = np.zeros((B, B), dtype=int)\n",
    "\n",
    "    if event_times.size < 2:\n",
    "        probs = np.zeros((B, B), dtype=float)\n",
    "        return counts, probs, np.zeros((B,), dtype=int)\n",
    "\n",
    "    for i in range(len(event_times) - 1):\n",
    "        t0, t1 = float(event_times[i]), float(event_times[i + 1])\n",
    "        if not np.isfinite(t0) or not np.isfinite(t1):\n",
    "            continue\n",
    "        dt = t1 - t0\n",
    "        if dt <= 0 or dt > max_dt_s:\n",
    "            continue\n",
    "\n",
    "        a = event_labels[i]\n",
    "        b = event_labels[i + 1]\n",
    "        if (a not in idx) or (b not in idx):\n",
    "            continue\n",
    "        ia, ib = idx[a], idx[b]\n",
    "        if drop_self and ia == ib:\n",
    "            continue\n",
    "        counts[ia, ib] += 1\n",
    "\n",
    "    row_totals = counts.sum(axis=1)\n",
    "    probs = np.zeros_like(counts, dtype=float)\n",
    "    nz = row_totals > 0\n",
    "    probs[nz, :] = counts[nz, :] / row_totals[nz, None]\n",
    "    return counts, probs, row_totals\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Compute for each (animal, condition)\n",
    "# -------------------------\n",
    "cond_order = [\"Adu\", \"Juv\", \"Fem\"]\n",
    "exclude_cols = {\"time\", \"fiber_zscore_aligned\", \"Frames\"}\n",
    "\n",
    "transition_results = {}  # (animal, cond) -> dict(counts, probs, behaviors, row_totals, n_events)\n",
    "\n",
    "# optional filters for event extraction\n",
    "min_duration_s = None\n",
    "max_duration_s = None\n",
    "\n",
    "max_dt_s = 0.5   # transition window (<=1s)\n",
    "drop_self = False  # set True if you want to ignore A->A\n",
    "\n",
    "for (animal, cond), rec in results_by_key.items():\n",
    "    if cond not in cond_order:\n",
    "        continue\n",
    "    if \"behavior\" not in rec:\n",
    "        continue\n",
    "\n",
    "    beh_df = rec[\"behavior\"]\n",
    "    behavior_cols = [c for c in beh_df.columns if c not in exclude_cols]\n",
    "    if len(behavior_cols) == 0:\n",
    "        continue\n",
    "\n",
    "    times, labels = build_onset_event_sequence(\n",
    "        beh_df, behavior_cols,\n",
    "        threshold=0.5,\n",
    "        min_isi_s=0.1,\n",
    "        min_duration_s=min_duration_s,\n",
    "        max_duration_s=max_duration_s,\n",
    "    )\n",
    "\n",
    "    counts, probs, row_totals = transition_counts_and_probs(\n",
    "        times, labels, behavior_cols,\n",
    "        max_dt_s=max_dt_s,\n",
    "        drop_self=drop_self\n",
    "    )\n",
    "\n",
    "    transition_results[(animal, cond)] = {\n",
    "        \"behaviors\": behavior_cols,\n",
    "        \"event_times\": times,\n",
    "        \"event_labels\": labels,\n",
    "        \"counts\": counts,\n",
    "        \"probs\": probs,\n",
    "        \"row_totals\": row_totals,\n",
    "        \"n_events\": int(times.size),\n",
    "    }\n",
    "\n",
    "print(f\"Computed transition matrices for {len(transition_results)} (animal, condition) recordings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79686d6cd3d28b9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:31:21.022079Z",
     "start_time": "2026-01-05T09:31:20.733378Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_transition_grid_pretty(\n",
    "    transition_results,\n",
    "    *,\n",
    "    cond_order=(\"Adu\", \"Juv\", \"Fem\"),\n",
    "    animals=None,\n",
    "    global_labels=None,\n",
    "    max_dt_s=None,\n",
    "    title=\"Transition probabilities\",\n",
    "    vmax=None,\n",
    "    vmin=0.0,\n",
    "    cmap=\"viridis\",\n",
    "    show_xticks_on=\"bottom\",   # \"bottom\" or \"all\" or \"none\"\n",
    "    show_yticks_on=\"left\",     # \"left\" or \"all\" or \"none\"\n",
    "    mask_below=None,           # e.g. 0.05 to hide tiny probs\n",
    "    annotate=False,\n",
    "    fontsize=9,\n",
    "    cbar_shrink=0.85,\n",
    "):\n",
    "    keys = list(transition_results.keys())\n",
    "    if animals is None:\n",
    "        animals = sorted(set([a for (a, c) in keys]))\n",
    "    cond_order = list(cond_order)\n",
    "\n",
    "    # Build union label order if not given\n",
    "    if global_labels is None:\n",
    "        seen = set()\n",
    "        global_labels = []\n",
    "        for a in animals:\n",
    "            for c in cond_order:\n",
    "                d = transition_results.get((a, c), None)\n",
    "                if d is None:\n",
    "                    continue\n",
    "                for lab in d.get(\"behaviors\", []):\n",
    "                    if lab not in seen:\n",
    "                        seen.add(lab)\n",
    "                        global_labels.append(lab)\n",
    "\n",
    "    nB = len(global_labels)\n",
    "    if nB == 0:\n",
    "        raise ValueError(\"No behaviors found.\")\n",
    "\n",
    "    # Align matrices to global label set\n",
    "    aligned = {}\n",
    "    all_vals = []\n",
    "    for a in animals:\n",
    "        for c in cond_order:\n",
    "            d = transition_results.get((a, c), None)\n",
    "            if d is None:\n",
    "                continue\n",
    "            probs = np.asarray(d[\"probs\"], float)\n",
    "            labels = list(d[\"behaviors\"])\n",
    "            old_idx = {lab: i for i, lab in enumerate(labels)}\n",
    "            new_idx = {lab: i for i, lab in enumerate(global_labels)}\n",
    "            M = np.full((nB, nB), np.nan, float)\n",
    "            for li in labels:\n",
    "                if li not in new_idx:\n",
    "                    continue\n",
    "                for lj in labels:\n",
    "                    if lj not in new_idx:\n",
    "                        continue\n",
    "                    M[new_idx[li], new_idx[lj]] = probs[old_idx[li], old_idx[lj]]\n",
    "            aligned[(a, c)] = M\n",
    "            if np.isfinite(M).any():\n",
    "                all_vals.append(np.nanmax(M))\n",
    "\n",
    "    # Mean across animals per condition\n",
    "    mean_by_cond = {}\n",
    "    for c in cond_order:\n",
    "        mats = [aligned[(a, c)] for a in animals if (a, c) in aligned]\n",
    "        if mats:\n",
    "            mean_by_cond[c] = np.nanmean(np.stack(mats, axis=0), axis=0)\n",
    "        else:\n",
    "            mean_by_cond[c] = np.full((nB, nB), np.nan, float)\n",
    "\n",
    "    # Color scaling\n",
    "    if vmax is None:\n",
    "        vmax = float(np.nanmax(all_vals)) if all_vals else 1.0\n",
    "        vmax = max(vmax, 1e-6)\n",
    "\n",
    "    # Figure grid\n",
    "    nrows = len(animals) + 1\n",
    "    ncols = len(cond_order)\n",
    "\n",
    "    # size heuristic: widen columns, keep readable labels\n",
    "    fig_w = max(10, 3.1 * ncols + 0.18 * nB)\n",
    "    fig_h = max(7, 1.6 * nrows + 0.12 * nB)\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(fig_w, fig_h), squeeze=False)\n",
    "\n",
    "    # for shared cbar\n",
    "    mappable = None\n",
    "\n",
    "    def _style_ax(ax):\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    def _maybe_mask(M):\n",
    "        if mask_below is None:\n",
    "            return M\n",
    "        Mm = M.copy()\n",
    "        Mm[np.isfinite(Mm) & (Mm < mask_below)] = np.nan\n",
    "        return Mm\n",
    "\n",
    "    # plot rows: animals\n",
    "    for r, a in enumerate(animals):\n",
    "        for ci, c in enumerate(cond_order):\n",
    "            ax = axes[r, ci]\n",
    "            M = aligned.get((a, c), np.full((nB, nB), np.nan))\n",
    "            M = _maybe_mask(M)\n",
    "\n",
    "            im = ax.imshow(M, vmin=vmin, vmax=vmax, cmap=cmap, aspect=\"auto\", interpolation=\"nearest\")\n",
    "            mappable = im\n",
    "\n",
    "            # titles only top row\n",
    "            if r == 0:\n",
    "                ax.set_title(c, fontsize=fontsize+2, pad=6)\n",
    "\n",
    "            # y-label only first col\n",
    "            if ci == 0:\n",
    "                ax.set_ylabel(f\"{a}\\nCurrent\", fontsize=fontsize+1)\n",
    "            else:\n",
    "                ax.set_ylabel(\"\")\n",
    "\n",
    "            # ticks\n",
    "            if show_yticks_on in (\"left\", \"all\") and ci == 0:\n",
    "                ax.set_yticks(np.arange(nB))\n",
    "                ax.set_yticklabels(global_labels, fontsize=fontsize)\n",
    "            elif show_yticks_on == \"all\":\n",
    "                ax.set_yticks(np.arange(nB))\n",
    "                ax.set_yticklabels(global_labels, fontsize=fontsize)\n",
    "            else:\n",
    "                ax.set_yticks([])\n",
    "\n",
    "            if show_xticks_on == \"all\":\n",
    "                ax.set_xticks(np.arange(nB))\n",
    "                ax.set_xticklabels(global_labels, rotation=45, ha=\"right\", fontsize=fontsize)\n",
    "                ax.set_xlabel(\"Next\", fontsize=fontsize+1)\n",
    "            elif show_xticks_on == \"bottom\" and r == (nrows - 1):\n",
    "                ax.set_xticks(np.arange(nB))\n",
    "                ax.set_xticklabels(global_labels, rotation=45, ha=\"right\", fontsize=fontsize)\n",
    "                ax.set_xlabel(\"Next\", fontsize=fontsize+1)\n",
    "            else:\n",
    "                ax.set_xticks([])\n",
    "\n",
    "            # event marker aesthetics: optional diagonal emphasis\n",
    "            ax.axvline(-0.5, color=\"none\")\n",
    "            _style_ax(ax)\n",
    "\n",
    "            if annotate and np.isfinite(M).any():\n",
    "                for i in range(nB):\n",
    "                    for j in range(nB):\n",
    "                        v = M[i, j]\n",
    "                        if np.isfinite(v) and v > 0:\n",
    "                            ax.text(j, i, f\"{v:.2f}\", ha=\"center\", va=\"center\", fontsize=6, color=\"white\")\n",
    "\n",
    "    # last row: mean\n",
    "    mean_r = len(animals)\n",
    "    for ci, c in enumerate(cond_order):\n",
    "        ax = axes[mean_r, ci]\n",
    "        M = _maybe_mask(mean_by_cond[c])\n",
    "        im = ax.imshow(M, vmin=vmin, vmax=vmax, cmap=cmap, aspect=\"auto\", interpolation=\"nearest\")\n",
    "        mappable = im\n",
    "\n",
    "        if ci == 0:\n",
    "            ax.set_ylabel(\"Mean\\nCurrent\", fontsize=fontsize+1)\n",
    "\n",
    "        # show xticks on mean row\n",
    "        ax.set_xticks(np.arange(nB))\n",
    "        ax.set_xticklabels(global_labels, rotation=45, ha=\"right\", fontsize=fontsize)\n",
    "        ax.set_xlabel(\"Next\", fontsize=fontsize+1)\n",
    "\n",
    "        # show yticks only left\n",
    "        if ci == 0:\n",
    "            ax.set_yticks(np.arange(nB))\n",
    "            ax.set_yticklabels(global_labels, fontsize=fontsize)\n",
    "        else:\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        _style_ax(ax)\n",
    "\n",
    "    # shared colorbar\n",
    "    if mappable is not None:\n",
    "        cbar = fig.colorbar(\n",
    "            mappable, ax=axes.ravel().tolist(),\n",
    "            fraction=0.02, pad=0.015, shrink=cbar_shrink\n",
    "        )\n",
    "        cbar.set_label(\"Transition probability\", fontsize=fontsize+1)\n",
    "        cbar.ax.tick_params(labelsize=fontsize)\n",
    "\n",
    "    # super title\n",
    "    if max_dt_s is not None:\n",
    "        fig.suptitle(f\"{title} (transition within ≤{max_dt_s:.1f}s)\", y=0.995, fontsize=fontsize+5)\n",
    "    else:\n",
    "        fig.suptitle(title, y=0.995, fontsize=fontsize+5)\n",
    "\n",
    "    # tighter layout\n",
    "    plt.subplots_adjust(left=0.16, right=0.92, top=0.93, bottom=0.12, wspace=0.12, hspace=0.20)\n",
    "    plt.show()\n",
    "\n",
    "    return {\"global_behaviors\": global_labels, \"aligned\": aligned, \"mean_by_cond\": mean_by_cond}\n",
    "\n",
    "\n",
    "# --- run it ---\n",
    "_ = plot_transition_grid_pretty(\n",
    "    transition_results,\n",
    "    cond_order=[\"Adu\", \"Juv\", \"Fem\"],\n",
    "    max_dt_s=max_dt_s,\n",
    "    mask_below=0.05,          # hides tiny probabilities -> cleaner\n",
    "    annotate=False,\n",
    "    fontsize=9,\n",
    "    title=\"Transition probabilities\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c7c1e549fc9d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:31:28.702354Z",
     "start_time": "2026-01-05T09:31:28.032614Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_bouts(time, binary_vec, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Return bout start/end indices and start/end times for contiguous True runs.\n",
    "    \"\"\"\n",
    "    t = np.asarray(time, float)\n",
    "    v = np.asarray(binary_vec, float)\n",
    "    m = np.isfinite(t) & np.isfinite(v)\n",
    "    t = t[m]\n",
    "    v = v[m]\n",
    "    if t.size < 2:\n",
    "        return []\n",
    "\n",
    "    b = v > threshold\n",
    "    db = np.diff(b.astype(int))\n",
    "    starts = np.where(db == 1)[0] + 1\n",
    "    ends   = np.where(db == -1)[0] + 1\n",
    "\n",
    "    if b[0]:\n",
    "        starts = np.r_[0, starts]\n",
    "    if b[-1]:\n",
    "        ends = np.r_[ends, b.size]\n",
    "\n",
    "    bouts = []\n",
    "    for s, e in zip(starts, ends):\n",
    "        # e is exclusive index\n",
    "        t0 = float(t[s])\n",
    "        t1 = float(t[e-1]) if e-1 < t.size else float(t[-1])\n",
    "        bouts.append((t0, t1))\n",
    "    return bouts\n",
    "\n",
    "def compute_behavior_summary(beh_df, behavior_cols, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Returns dict with:\n",
    "      freq: number of bouts\n",
    "      cum_dur: sum of bout durations (s)\n",
    "      mean_bout_dur: mean bout duration (s)\n",
    "    \"\"\"\n",
    "    t = beh_df[\"time\"].to_numpy(dtype=float)\n",
    "    out = {\"freq\": {}, \"cum_dur\": {}, \"mean_bout_dur\": {}}\n",
    "\n",
    "    for bname in behavior_cols:\n",
    "        bouts = extract_bouts(t, beh_df[bname].to_numpy(), threshold=threshold)\n",
    "        freq = len(bouts)\n",
    "        durs = np.array([max(0.0, (t1 - t0)) for (t0, t1) in bouts], float)\n",
    "        out[\"freq\"][bname] = float(freq)\n",
    "        out[\"cum_dur\"][bname] = float(np.sum(durs)) if durs.size else 0.0\n",
    "        out[\"mean_bout_dur\"][bname] = float(np.mean(durs)) if durs.size else 0.0\n",
    "\n",
    "    return out\n",
    "\n",
    "def plot_behavior_summary_heatmaps(\n",
    "    results_by_key,\n",
    "    *,\n",
    "    cond_order=(\"Adu\",\"Juv\",\"Fem\"),\n",
    "    animals=None,\n",
    "    behavior_cols=None,\n",
    "    exclude=(\"fiber_zscore_aligned\",\"Frames\"),\n",
    "    threshold=0.5,\n",
    "    cmap=\"viridis\",\n",
    "    title=\"Behavior summaries\"\n",
    "):\n",
    "    keys = list(results_by_key.keys())\n",
    "    if animals is None:\n",
    "        animals = sorted(set([a for (a,c) in keys]))\n",
    "    cond_order = list(cond_order)\n",
    "\n",
    "    # build behavior union if not provided\n",
    "    if behavior_cols is None:\n",
    "        seen = set()\n",
    "        behavior_cols = []\n",
    "        for a in animals:\n",
    "            for c in cond_order:\n",
    "                rec = results_by_key.get((a,c), None)\n",
    "                if rec is None or \"behavior\" not in rec:\n",
    "                    continue\n",
    "                beh = rec[\"behavior\"]\n",
    "                cols = [col for col in beh.columns if col not in (\"time\",) + tuple(exclude)]\n",
    "                for col in cols:\n",
    "                    if col not in seen:\n",
    "                        seen.add(col)\n",
    "                        behavior_cols.append(col)\n",
    "\n",
    "    nB = len(behavior_cols)\n",
    "    if nB == 0:\n",
    "        raise ValueError(\"No behavior columns found in results_by_key.\")\n",
    "\n",
    "    metrics = [\"freq\", \"cum_dur\", \"mean_bout_dur\"]\n",
    "    metric_titles = {\n",
    "        \"freq\": \"Frequency (# bouts)\",\n",
    "        \"cum_dur\": \"Cumulative duration (s)\",\n",
    "        \"mean_bout_dur\": \"Mean bout duration (s)\"\n",
    "    }\n",
    "\n",
    "    for cond in cond_order:\n",
    "        # matrices: rows animals + mean, cols behaviors\n",
    "        mats = {m: np.full((len(animals)+1, nB), np.nan, float) for m in metrics}\n",
    "\n",
    "        # fill per animal\n",
    "        for i, a in enumerate(animals):\n",
    "            rec = results_by_key.get((a, cond), None)\n",
    "            if rec is None or \"behavior\" not in rec:\n",
    "                continue\n",
    "            beh_df = rec[\"behavior\"]\n",
    "            if \"time\" not in beh_df.columns:\n",
    "                continue\n",
    "            summ = compute_behavior_summary(beh_df, behavior_cols, threshold=threshold)\n",
    "            for j, bname in enumerate(behavior_cols):\n",
    "                for m in metrics:\n",
    "                    mats[m][i, j] = summ[m].get(bname, np.nan)\n",
    "\n",
    "        # mean row\n",
    "        for m in metrics:\n",
    "            mats[m][-1, :] = np.nanmean(mats[m][0:len(animals), :], axis=0)\n",
    "\n",
    "        # plot: 3 stacked heatmaps for this condition\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(max(10, 0.42*nB + 6), 8.5), sharex=True)\n",
    "        fig.suptitle(f\"{title} — {cond}\", y=0.995, fontsize=14)\n",
    "\n",
    "        for k, m in enumerate(metrics):\n",
    "            ax = axes[k]\n",
    "            M = mats[m]\n",
    "\n",
    "            # choose vmax per metric for readability\n",
    "            vmax = np.nanpercentile(M[np.isfinite(M)], 98) if np.isfinite(M).any() else 1.0\n",
    "            vmax = max(vmax, 1e-6)\n",
    "\n",
    "            im = ax.imshow(M, aspect=\"auto\", cmap=cmap, vmin=0, vmax=vmax, interpolation=\"nearest\")\n",
    "\n",
    "            # y ticks: animals + Mean\n",
    "            ylabels = animals + [\"Mean\"]\n",
    "            ax.set_yticks(np.arange(len(ylabels)))\n",
    "            ax.set_yticklabels(ylabels, fontsize=8)\n",
    "            ax.set_title(metric_titles[m], fontsize=11, pad=6)\n",
    "\n",
    "            ax.spines[\"top\"].set_visible(False)\n",
    "            ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "            cbar = fig.colorbar(im, ax=ax, fraction=0.02, pad=0.01)\n",
    "            cbar.ax.tick_params(labelsize=8)\n",
    "\n",
    "        axes[-1].set_xticks(np.arange(nB))\n",
    "        axes[-1].set_xticklabels(behavior_cols, rotation=45, ha=\"right\", fontsize=8)\n",
    "        axes[-1].set_xlabel(\"Behavior\", fontsize=10)\n",
    "\n",
    "        plt.subplots_adjust(left=0.16, right=0.92, top=0.93, bottom=0.18, hspace=0.35)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# --- run it ---\n",
    "# Requires results_by_key[(animal, cond)][\"behavior\"] exists.\n",
    "plot_behavior_summary_heatmaps(\n",
    "    results_by_key,\n",
    "    cond_order=[\"Adu\", \"Juv\", \"Fem\"],\n",
    "    title=\"Behavior summary heatmaps\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1922288fd57d80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:31:43.710101Z",
     "start_time": "2026-01-05T09:31:43.455743Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# User parameters\n",
    "# -----------------------------\n",
    "transition_dt_s = 0.5        # transition window (<=1s)\n",
    "prob_threshold = 0.4          # only keep pairs with P(B|A) > 0.5\n",
    "min_transitions = 2           # minimum number of transition events to plot PSTH\n",
    "\n",
    "# PSTH parameters\n",
    "window = (-3, 5)\n",
    "baseline_win = (-3, 0)\n",
    "smooth_sigma_s = 0.1\n",
    "\n",
    "# Heatmap scaling\n",
    "vmin, vmax = -3, 3\n",
    "cmap = \"viridis\"\n",
    "\n",
    "# Optional duration filtering for event extraction (behavior bouts)\n",
    "min_duration_s = None\n",
    "max_duration_s = None\n",
    "\n",
    "# Layout\n",
    "figsize_base = (20, 2.0)      # (width, height_per_row); total height scales with #pairs\n",
    "mean_ylim = (-2.2, 2.2)\n",
    "\n",
    "# Conditions + requested colors\n",
    "cond_order = [\"Adu\", \"Juv\", \"Fem\"]\n",
    "cond_colors = {\"Adu\": \"tab:blue\", \"Juv\": \"tab:green\", \"Fem\": \"tab:pink\"}\n",
    "cond_alpha_line = 0.9\n",
    "cond_alpha_fill = 0.25\n",
    "\n",
    "exclude_cols = {\"time\", \"fiber_zscore_aligned\", \"Frames\"}\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def get_behavior_cols_for_animal(animal_id):\n",
    "    cols_union, seen = [], set()\n",
    "    for cond in cond_order:\n",
    "        rec = results_by_key.get((animal_id, cond))\n",
    "        if rec is None or \"behavior\" not in rec:\n",
    "            continue\n",
    "        beh = rec[\"behavior\"]\n",
    "        cols = [c for c in beh.columns if c not in exclude_cols]\n",
    "        for c in cols:\n",
    "            if c not in seen:\n",
    "                cols_union.append(c)\n",
    "                seen.add(c)\n",
    "    return cols_union\n",
    "\n",
    "def build_event_sequence_from_df(beh_df, behavior_cols):\n",
    "    \"\"\"\n",
    "    Build a chronological sequence of behavior onset events.\n",
    "    Returns (times, labels) sorted by time.\n",
    "    \"\"\"\n",
    "    if \"time\" not in beh_df.columns:\n",
    "        return np.array([]), np.array([], dtype=object)\n",
    "\n",
    "    t = beh_df[\"time\"].to_numpy(dtype=float)\n",
    "\n",
    "    all_times = []\n",
    "    all_labels = []\n",
    "\n",
    "    for b in behavior_cols:\n",
    "        if b not in beh_df.columns:\n",
    "            continue\n",
    "        ev = extract_events(\n",
    "            t, beh_df[b].to_numpy(),\n",
    "            threshold=0.5,\n",
    "            min_isi_s=0.1,\n",
    "            min_duration_s=min_duration_s,\n",
    "            max_duration_s=max_duration_s,\n",
    "        )\n",
    "        on = np.asarray(ev[\"onset_s\"], float)\n",
    "        if on.size == 0:\n",
    "            continue\n",
    "        all_times.append(on)\n",
    "        all_labels.append(np.array([b] * on.size, dtype=object))\n",
    "\n",
    "    if not all_times:\n",
    "        return np.array([]), np.array([], dtype=object)\n",
    "\n",
    "    times = np.concatenate(all_times)\n",
    "    labels = np.concatenate(all_labels)\n",
    "    order = np.argsort(times)\n",
    "    return times[order], labels[order]\n",
    "\n",
    "def transition_counts_probs_and_times(event_times, event_labels, behavior_cols, max_dt_s=1.0):\n",
    "    \"\"\"\n",
    "    Using the chronological event list, compute:\n",
    "      - counts[A,B]\n",
    "      - probs[A,B] = counts[A,B]/sum_B counts[A,B]\n",
    "      - transition_times[(A,B)] = list of times at which transition occurs (here: onset time of B)\n",
    "    Transition is only between consecutive events with dt <= max_dt_s.\n",
    "    \"\"\"\n",
    "    B = len(behavior_cols)\n",
    "    idx = {b: i for i, b in enumerate(behavior_cols)}\n",
    "\n",
    "    counts = np.zeros((B, B), dtype=int)\n",
    "    trans_times = {}  # (A,B) -> list of B-onset times\n",
    "\n",
    "    if event_times.size < 2:\n",
    "        probs = np.zeros((B, B), dtype=float)\n",
    "        return counts, probs, trans_times\n",
    "\n",
    "    for i in range(event_times.size - 1):\n",
    "        t0 = float(event_times[i])\n",
    "        t1 = float(event_times[i + 1])\n",
    "        if not (np.isfinite(t0) and np.isfinite(t1)):\n",
    "            continue\n",
    "        dt = t1 - t0\n",
    "        if dt <= 0 or dt > max_dt_s:\n",
    "            continue\n",
    "\n",
    "        A = event_labels[i]\n",
    "        Bn = event_labels[i + 1]\n",
    "        if A not in idx or Bn not in idx:\n",
    "            continue\n",
    "\n",
    "        ia, ib = idx[A], idx[Bn]\n",
    "        counts[ia, ib] += 1\n",
    "        trans_times.setdefault((A, Bn), []).append(t1)  # center on onset of next behavior\n",
    "\n",
    "    row_totals = counts.sum(axis=1)\n",
    "    probs = np.zeros_like(counts, dtype=float)\n",
    "    nz = row_totals > 0\n",
    "    probs[nz, :] = counts[nz, :] / row_totals[nz, None]\n",
    "\n",
    "    return counts, probs, trans_times\n",
    "\n",
    "def plot_heatmap(ax, tvec, mat, title, show_ylabel=False):\n",
    "    im = ax.imshow(\n",
    "        mat,\n",
    "        aspect=\"auto\",\n",
    "        origin=\"lower\",\n",
    "        extent=[tvec[0], tvec[-1], 0, mat.shape[0]],\n",
    "        cmap=cmap,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        interpolation=\"nearest\",\n",
    "    )\n",
    "    ax.axvline(0, color=\"w\", linestyle=\"--\", alpha=0.9, lw=1)\n",
    "    ax.set_title(title, fontsize=10, pad=4)\n",
    "    if show_ylabel:\n",
    "        ax.set_ylabel(\"Trial\", fontsize=9)\n",
    "    ax.tick_params(axis=\"both\", labelsize=8, length=2)\n",
    "    return im\n",
    "\n",
    "# -----------------------------\n",
    "# Plot: per animal, rows = high-probability transitions (A->B)\n",
    "# -----------------------------\n",
    "animals = sorted(set([k[0] for k in results_by_key.keys()]))\n",
    "\n",
    "for animal_id in animals:\n",
    "    behavior_cols = get_behavior_cols_for_animal(animal_id)\n",
    "    if not behavior_cols:\n",
    "        print(f\"{animal_id}: no behaviors available.\")\n",
    "        continue\n",
    "\n",
    "    # For each condition, compute transition probs + transition times\n",
    "    cond_stats = {}\n",
    "    candidate_pairs = set()\n",
    "\n",
    "    for cond in cond_order:\n",
    "        rec = results_by_key.get((animal_id, cond), None)\n",
    "        if rec is None or \"behavior\" not in rec:\n",
    "            continue\n",
    "\n",
    "        beh_df = rec[\"behavior\"]\n",
    "        # Need aligned fiber too for PSTH\n",
    "        if (\"time\" not in beh_df.columns) or (\"fiber_zscore_aligned\" not in beh_df.columns):\n",
    "            continue\n",
    "\n",
    "        event_times, event_labels = build_event_sequence_from_df(beh_df, behavior_cols)\n",
    "        counts, probs, trans_times = transition_counts_probs_and_times(\n",
    "            event_times, event_labels, behavior_cols, max_dt_s=transition_dt_s\n",
    "        )\n",
    "\n",
    "        cond_stats[cond] = {\n",
    "            \"beh_df\": beh_df,\n",
    "            \"counts\": counts,\n",
    "            \"probs\": probs,\n",
    "            \"trans_times\": trans_times,\n",
    "        }\n",
    "\n",
    "        # Collect pairs exceeding probability threshold in this condition\n",
    "        for (A, Bn), times in trans_times.items():\n",
    "            ia = behavior_cols.index(A)\n",
    "            ib = behavior_cols.index(Bn)\n",
    "            if probs[ia, ib] > prob_threshold:\n",
    "                candidate_pairs.add((A, Bn))\n",
    "\n",
    "    if not candidate_pairs:\n",
    "        print(f\"{animal_id}: no transitions with P(B|A) > {prob_threshold} in any condition.\")\n",
    "        continue\n",
    "\n",
    "    # Sort pairs for stable display (by source then dest)\n",
    "    candidate_pairs = sorted(candidate_pairs, key=lambda x: (x[0], x[1]))\n",
    "    n_pairs = len(candidate_pairs)\n",
    "\n",
    "    fig_w = figsize_base[0]\n",
    "    fig_h = max(4, figsize_base[1] * n_pairs)\n",
    "    fig = plt.figure(figsize=(fig_w, fig_h), constrained_layout=False)\n",
    "\n",
    "    gs = fig.add_gridspec(\n",
    "        nrows=n_pairs, ncols=4,\n",
    "        width_ratios=[1.05, 1.05, 1.05, 1.25],\n",
    "        wspace=0.35, hspace=0.70\n",
    "    )\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"{animal_id} — Transition-aligned PSTHs (dt ≤ {transition_dt_s:.1f}s, P> {prob_threshold})\",\n",
    "        y=0.995, fontsize=14\n",
    "    )\n",
    "\n",
    "    heatmap_images = []\n",
    "    any_plotted = False\n",
    "\n",
    "    for r, (A, Bn) in enumerate(candidate_pairs):\n",
    "        pair_label = f\"{A} → {Bn}\"\n",
    "\n",
    "        # axes\n",
    "        ax_hm = {cond: fig.add_subplot(gs[r, c]) for c, cond in enumerate(cond_order)}\n",
    "        ax_mean = fig.add_subplot(gs[r, 3])\n",
    "\n",
    "        # Mean axis styling\n",
    "        ax_mean.axvline(0, color=\"k\", linestyle=\"--\", alpha=0.5, lw=1)\n",
    "        ax_mean.axhline(0, color=\"gray\", linestyle=\":\", alpha=0.7)\n",
    "        ax_mean.set_title(f\"{pair_label} — mean\", fontsize=10, pad=4)\n",
    "        ax_mean.set_ylabel(\"Z\", fontsize=9)\n",
    "        ax_mean.set_ylim(*mean_ylim)\n",
    "        ax_mean.grid(True, alpha=0.15)\n",
    "        ax_mean.tick_params(axis=\"both\", labelsize=8, length=2)\n",
    "\n",
    "        # condition headers only on first row\n",
    "        if r == 0:\n",
    "            for cond in cond_order:\n",
    "                ax_hm[cond].set_title(cond, fontsize=11, pad=6)\n",
    "\n",
    "        # leftmost y label includes pair label\n",
    "        ax_hm[\"Adu\"].set_ylabel(f\"{pair_label}\\nTrial\", fontsize=9)\n",
    "\n",
    "        tvec_ref = None\n",
    "        any_cond_row = False\n",
    "\n",
    "        for cond in cond_order:\n",
    "            ax = ax_hm[cond]\n",
    "            if cond not in cond_stats:\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            beh_df = cond_stats[cond][\"beh_df\"]\n",
    "            probs = cond_stats[cond][\"probs\"]\n",
    "            trans_times = cond_stats[cond][\"trans_times\"]\n",
    "\n",
    "            # must have this transition in this condition and exceed threshold\n",
    "            times = np.asarray(trans_times.get((A, Bn), []), float)\n",
    "            if times.size < min_transitions:\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            ia = behavior_cols.index(A)\n",
    "            ib = behavior_cols.index(Bn)\n",
    "            p_ab = float(probs[ia, ib])\n",
    "            if p_ab <= prob_threshold:\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            # fiber on behavior timebase\n",
    "            fiber_time = beh_df[\"time\"].to_numpy(dtype=float)\n",
    "            fiber_trace = beh_df[\"fiber_zscore_aligned\"].to_numpy(dtype=float)\n",
    "\n",
    "            # PSTH centered on transition time (onset of B)\n",
    "            tvec, mat = _compute_psth_matrix(\n",
    "                fiber_time, fiber_trace, times,\n",
    "                window=window, baseline_win=baseline_win, smooth_sigma_s=smooth_sigma_s, resample_hz=60\n",
    "            )\n",
    "            mat = mat[~np.isnan(mat).all(axis=1)]\n",
    "            if mat.shape[0] < min_transitions:\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            any_plotted = True\n",
    "            any_cond_row = True\n",
    "            if tvec_ref is None:\n",
    "                tvec_ref = tvec\n",
    "\n",
    "            # heatmap + title includes n and P\n",
    "            im = plot_heatmap(\n",
    "                ax, tvec, mat,\n",
    "                title=f\"{cond} (n={mat.shape[0]}, P={p_ab:.2f})\",\n",
    "                show_ylabel=(cond == \"Adu\")\n",
    "            )\n",
    "            heatmap_images.append(im)\n",
    "\n",
    "            # mean overlay\n",
    "            mean_trace = np.nanmean(mat, axis=0)\n",
    "            sem_trace = np.nanstd(mat, axis=0) / np.sqrt(mat.shape[0])\n",
    "\n",
    "            ax_mean.plot(\n",
    "                tvec, mean_trace,\n",
    "                color=cond_colors[cond],\n",
    "                alpha=cond_alpha_line,\n",
    "                lw=1.4,\n",
    "                label=cond\n",
    "            )\n",
    "            ax_mean.fill_between(\n",
    "                tvec, mean_trace - sem_trace, mean_trace + sem_trace,\n",
    "                color=cond_colors[cond],\n",
    "                alpha=cond_alpha_fill,\n",
    "                linewidth=0\n",
    "            )\n",
    "\n",
    "        if any_cond_row and tvec_ref is not None:\n",
    "            ax_mean.set_xlim(tvec_ref[0], tvec_ref[-1])\n",
    "            ax_mean.legend(frameon=False, fontsize=8, loc=\"upper right\")\n",
    "\n",
    "            # x labels on every row (transitions list is often shorter; clarity > compactness)\n",
    "            ax_mean.set_xlabel(\"Time from transition (s)\", fontsize=9)\n",
    "            for cond in cond_order:\n",
    "                if ax_hm[cond].axison:\n",
    "                    ax_hm[cond].set_xlabel(\"Time (s)\", fontsize=9)\n",
    "        else:\n",
    "            ax_mean.axis(\"off\")\n",
    "            for cond in cond_order:\n",
    "                ax_hm[cond].axis(\"off\")\n",
    "\n",
    "    if not any_plotted:\n",
    "        plt.close(fig)\n",
    "        print(f\"{animal_id}: no transition PSTHs plotted (not enough transitions after filtering).\")\n",
    "        continue\n",
    "\n",
    "    # shared colorbar\n",
    "    if heatmap_images:\n",
    "        cbar = fig.colorbar(\n",
    "            heatmap_images[0],\n",
    "            ax=fig.axes,\n",
    "            fraction=0.015,\n",
    "            pad=0.01,\n",
    "            shrink=0.85\n",
    "        )\n",
    "        cbar.set_label(\"Z-score\", fontsize=10)\n",
    "        cbar.ax.tick_params(labelsize=9, length=2)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.985])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530fe10b14a11d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, linregress\n",
    "\n",
    "# =============================================================================\n",
    "# Global Correlation Analysis: Pooled Data (All Animals)\n",
    "# =============================================================================\n",
    "\n",
    "# Settings\n",
    "AUC_WINDOW = (-5, 5)  # Window for AUC calculation (seconds)\n",
    "\n",
    "# Containers for pooled data\n",
    "all_lick_counts = []\n",
    "all_auc_values = []\n",
    "animal_colors = [] # Optional: to color-code points by animal\n",
    "\n",
    "# Setup colormap for distinguishing animals in the scatter\n",
    "cmap = plt.get_cmap('tab10')\n",
    "animal_ids = sorted(psth_results.keys())\n",
    "\n",
    "print(f\"Aggregating data for Global Correlation ({AUC_WINDOW[0]}s to {AUC_WINDOW[1]}s)...\")\n",
    "\n",
    "for i, animal_id in enumerate(animal_ids):\n",
    "    # 1. Retrieve Data\n",
    "    psth_data = psth_results[animal_id]\n",
    "    mat = psth_data[\"psth_matrix\"]\n",
    "    tvec = psth_data[\"time_vector\"]\n",
    "\n",
    "    # Estimate sampling rate from time vector\n",
    "    fs = 1.0 / np.nanmedian(np.diff(tvec))\n",
    "\n",
    "    # 2. Retrieve & Filter Behavioral Data\n",
    "    # Get raw arrays\n",
    "    raw_burst_sizes = per_animal[animal_id][\"burst_sizes\"]\n",
    "    raw_lick_onsets = per_animal[animal_id][\"lick_onset\"]\n",
    "\n",
    "    # Apply the same filter used to generate the PSTH events:\n",
    "    # Keep only bursts that had a valid \"2nd lick\" timestamp (i.e., not NaN)\n",
    "    valid_behavior_mask = ~np.isnan(raw_lick_onsets)\n",
    "    trial_lick_counts = raw_burst_sizes[valid_behavior_mask]\n",
    "\n",
    "    # 3. Align Behavioral Data with PSTH Matrix\n",
    "    # The PSTH matrix might be shorter if trials at the very end of the recording\n",
    "    # were dropped due to window boundaries.\n",
    "    n_psth_trials = mat.shape[0]\n",
    "    n_behavior_trials = len(trial_lick_counts)\n",
    "\n",
    "    # We assume chronological order, so we truncate the longer array to match the shorter one.\n",
    "    n_valid = min(n_psth_trials, n_behavior_trials)\n",
    "\n",
    "    # Truncate\n",
    "    trial_lick_counts = trial_lick_counts[:n_valid]\n",
    "    mat_aligned = mat[:n_valid, :]\n",
    "\n",
    "    # 4. Calculate AUC for valid trials\n",
    "    # Find indices for the integration window\n",
    "    idx_start = np.searchsorted(tvec, AUC_WINDOW[0])\n",
    "    idx_end = np.searchsorted(tvec, AUC_WINDOW[1])\n",
    "\n",
    "    # Compute AUC using Trapezoidal rule along axis 1 (time)\n",
    "    auc_values = np.trapz(mat_aligned[:, idx_start:idx_end], dx=1/fs, axis=1)\n",
    "\n",
    "    # 5. Append to Global Lists\n",
    "    all_lick_counts.extend(trial_lick_counts)\n",
    "    all_auc_values.extend(auc_values)\n",
    "\n",
    "    # Store color index for this batch of points\n",
    "    animal_colors.extend([i] * n_valid)\n",
    "\n",
    "# Convert to numpy arrays for analysis\n",
    "all_lick_counts = np.array(all_lick_counts)\n",
    "all_auc_values = np.array(all_auc_values)\n",
    "animal_colors = np.array(animal_colors)\n",
    "\n",
    "print(f\"Total Trials Analyzed: {len(all_lick_counts)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Statistical Analysis & Plotting\n",
    "# =============================================================================\n",
    "\n",
    "if len(all_lick_counts) > 5:\n",
    "    # 1. Pearson Correlation\n",
    "    r_val, p_val = pearsonr(all_lick_counts, all_auc_values)\n",
    "\n",
    "    # 2. Linear Regression (for the fit line)\n",
    "    slope, intercept, _, _, _ = linregress(all_lick_counts, all_auc_values)\n",
    "\n",
    "    # 3. Plotting\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Scatter Plot (Color-coded by animal)\n",
    "    scatter = plt.scatter(all_lick_counts, all_auc_values,\n",
    "                          c=animal_colors, cmap='tab10',\n",
    "                          alpha=0.6, s=25, edgecolor='w', linewidth=0.5)\n",
    "\n",
    "    # Regression Line\n",
    "    x_range = np.linspace(all_lick_counts.min(), all_lick_counts.max(), 100)\n",
    "    y_fit = slope * x_range + intercept\n",
    "\n",
    "    plt.plot(x_range, y_fit, color='black', linestyle='--', linewidth=2.5,\n",
    "             label=f\"Linear Fit\\ny = {slope:.2f}x + {intercept:.2f}\")\n",
    "\n",
    "    # Aesthetics\n",
    "    plt.title(f\"Global Correlation: Lick Count vs. Dopamine AUC\\n(n={len(animal_ids)} Animals, {len(all_lick_counts)} Trials)\", fontsize=14)\n",
    "    plt.xlabel(\"Number of Licks per Burst\", fontsize=12)\n",
    "    plt.ylabel(f\"PSTH AUC (Z-score * sec)\\nWindow: {AUC_WINDOW[0]}s to {AUC_WINDOW[1]}s\", fontsize=12)\n",
    "\n",
    "    # Legend for Statistics\n",
    "    stats_text = f\"Pearson r = {r_val:.3f}\\np-value = {p_val:.2e}\"\n",
    "    plt.text(0.05, 0.95, stats_text, transform=plt.gca().transAxes,\n",
    "             fontsize=12, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True, linestyle=':', alpha=0.6)\n",
    "\n",
    "    # Optional: Create a custom legend for animals\n",
    "    # handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=cmap(i), label=aid) for i, aid in enumerate(animal_ids)]\n",
    "    # plt.legend(handles=handles, title=\"Animal ID\", loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Insufficient data for correlation analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e2bd84b14bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, linregress\n",
    "\n",
    "# =============================================================================\n",
    "# Animal-Level Correlation: Mean Licks vs. Mean AUC\n",
    "# =============================================================================\n",
    "\n",
    "# Settings\n",
    "AUC_WINDOW = (-1, 4)  # Window for AUC calculation (seconds)\n",
    "\n",
    "# Containers for animal-level means\n",
    "mean_licks_per_animal = []\n",
    "mean_auc_per_animal = []\n",
    "animal_ids_list = []\n",
    "\n",
    "print(f\"Computing per-animal averages for Correlation ({AUC_WINDOW[0]}s to {AUC_WINDOW[1]}s)...\")\n",
    "\n",
    "for animal_id in sorted(psth_results.keys()):\n",
    "    # 1. Retrieve Data\n",
    "    psth_data = psth_results[animal_id]\n",
    "    mat = psth_data[\"psth_matrix\"]\n",
    "    tvec = psth_data[\"time_vector\"]\n",
    "\n",
    "    # 2. Compute Mean AUC for this animal\n",
    "    # Method: Calculate AUC for the *average trace* (more robust to noise)\n",
    "    # Alternatively, you could calc AUC per trial then mean, but for Z-scores, linear operations are commutative.\n",
    "\n",
    "    # Calculate Mean Trace first\n",
    "    mean_trace = np.nanmean(mat, axis=0)\n",
    "\n",
    "    # Estimate sampling rate\n",
    "    fs = 1.0 / np.nanmedian(np.diff(tvec))\n",
    "\n",
    "    # Find indices for integration\n",
    "    idx_start = np.searchsorted(tvec, AUC_WINDOW[0])\n",
    "    idx_end = np.searchsorted(tvec, AUC_WINDOW[1])\n",
    "\n",
    "    # Compute AUC of the mean trace\n",
    "    animal_auc = np.trapz(mean_trace[idx_start:idx_end], dx=1/fs)\n",
    "\n",
    "    # 3. Compute Mean Licks for this animal\n",
    "    # Retrieve raw burst sizes\n",
    "    raw_burst_sizes = per_animal[animal_id][\"burst_sizes\"]\n",
    "\n",
    "    # Filter for valid bursts only (same filter as PSTH events)\n",
    "    raw_lick_onsets = per_animal[animal_id][\"lick_onset\"]\n",
    "    valid_mask = ~np.isnan(raw_lick_onsets)\n",
    "    valid_burst_sizes = raw_burst_sizes[valid_mask]\n",
    "\n",
    "    # Calculate mean lick count\n",
    "    if len(valid_burst_sizes) > 0:\n",
    "        animal_mean_licks = np.mean(valid_burst_sizes)\n",
    "    else:\n",
    "        print(f\"Warning: No valid bursts for {animal_id}\")\n",
    "        continue\n",
    "\n",
    "    # 4. Store Data\n",
    "    mean_licks_per_animal.append(animal_mean_licks)\n",
    "    mean_auc_per_animal.append(animal_auc)\n",
    "    animal_ids_list.append(animal_id)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "x_vals = np.array(mean_licks_per_animal)\n",
    "y_vals = np.array(mean_auc_per_animal)\n",
    "\n",
    "# =============================================================================\n",
    "# Plotting & Statistics\n",
    "# =============================================================================\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "if len(x_vals) > 1:\n",
    "    # 1. Linear Regression\n",
    "    slope, intercept, r_val, p_val, std_err = linregress(x_vals, y_vals)\n",
    "\n",
    "    # 2. Plot Points\n",
    "    # Use a distinct color/marker for each animal\n",
    "    for i, aid in enumerate(animal_ids_list):\n",
    "        plt.scatter(x_vals[i], y_vals[i], s=150, zorder=3, label=aid, edgecolor='k')\n",
    "        # Annotate ID next to dot\n",
    "        plt.text(x_vals[i], y_vals[i], f\"  {aid}\", verticalalignment='center', fontsize=9)\n",
    "\n",
    "    # 3. Plot Fit Line\n",
    "    x_range = np.array([x_vals.min() * 0.9, x_vals.max() * 1.1])\n",
    "    plt.plot(x_range, slope * x_range + intercept, 'k--', alpha=0.5, zorder=2,\n",
    "             label=f\"Fit (r={r_val:.2f})\")\n",
    "\n",
    "    # 4. Stats Text\n",
    "    stats_msg = f\"Pearson r = {r_val:.3f}\\np = {p_val:.3f}\"\n",
    "    plt.text(0.05, 0.95, stats_msg, transform=plt.gca().transAxes,\n",
    "             fontsize=12, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "\n",
    "else:\n",
    "    plt.scatter(x_vals, y_vals, s=100)\n",
    "    print(\"Not enough points for regression.\")\n",
    "\n",
    "# Aesthetics\n",
    "plt.title(\"Animal-Level Correlation\\n(Mean Licks vs. Mean AUC)\", fontsize=14)\n",
    "plt.xlabel(\"Average Licks per Burst\", fontsize=12)\n",
    "plt.ylabel(f\"Average PSTH AUC (Z-score)\\nWindow: {AUC_WINDOW[0]}s to {AUC_WINDOW[1]}s\", fontsize=12)\n",
    "plt.grid(True, linestyle=':', alpha=0.6)\n",
    "plt.legend(title=\"Animal ID\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print Data for verification\n",
    "print(\"\\n--- Summary Data ---\")\n",
    "for aid, licks, auc in zip(animal_ids_list, x_vals, y_vals):\n",
    "    print(f\"{aid}: {licks:.2f} licks/burst | {auc:.2f} AUC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74350d2b24b76aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================================================================\n",
    "# Aggregation and Plotting using Pre-Computed 'psth_results'\n",
    "# =============================================================================\n",
    "\n",
    "# Container for animal averages\n",
    "animal_mean_traces = []\n",
    "animal_ids_list = []\n",
    "common_tvec = None\n",
    "\n",
    "print(\"Aggregating pre-computed per-animal averages...\")\n",
    "\n",
    "# Ensure psth_results exists\n",
    "if 'psth_results' not in locals():\n",
    "    print(\"Error: 'psth_results' dictionary not found. Please run the PSTH computation script first.\")\n",
    "else:\n",
    "    for animal_id, data in psth_results.items():\n",
    "        # 1. Retrieve Pre-computed Mean Trace\n",
    "        mean_trace = data.get(\"mean_trace\")\n",
    "        tvec = data.get(\"time_vector\")\n",
    "\n",
    "        if mean_trace is None or tvec is None:\n",
    "            print(f\"  Warning: Missing data for {animal_id}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # 2. Check for length consistency\n",
    "        # Initialize common_tvec with the first valid animal\n",
    "        if common_tvec is None:\n",
    "            common_tvec = tvec\n",
    "            expected_length = len(tvec)\n",
    "\n",
    "        # Ensure alignment (simple length check)\n",
    "        if len(mean_trace) != expected_length:\n",
    "            print(f\"  Warning: Length mismatch for {animal_id} ({len(mean_trace)} vs {expected_length}). Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # 3. Store\n",
    "        animal_mean_traces.append(mean_trace)\n",
    "        animal_ids_list.append(animal_id)\n",
    "\n",
    "    # --- Plotting ---\n",
    "\n",
    "    if len(animal_mean_traces) > 0:\n",
    "        # Stack into matrix: (n_animals x n_timepoints)\n",
    "        grand_matrix = np.vstack(animal_mean_traces)\n",
    "        n_animals = grand_matrix.shape[0]\n",
    "\n",
    "        # Compute Grand Average and SEM across animals\n",
    "        grand_mean = np.nanmean(grand_matrix, axis=0)\n",
    "        grand_sem = np.nanstd(grand_matrix, axis=0) / np.sqrt(n_animals)\n",
    "\n",
    "        print(f\"Averaging across {n_animals} animals.\")\n",
    "\n",
    "        # Create figure with 2 subplots\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), sharex=True, gridspec_kw={'height_ratios': [2, 1]})\n",
    "\n",
    "        # --- Subplot 1: Heatmap (Each line is an animal) ---\n",
    "        # Extent controls the axis values: [x_min, x_max, y_min, y_max]\n",
    "        # We set y to range from -0.5 to n_animals-0.5 so ticks align with integers\n",
    "        im = ax1.imshow(grand_matrix, aspect='auto', origin='lower',\n",
    "                        extent=[common_tvec[0], common_tvec[-1], -0.5, n_animals - 0.5],\n",
    "                        cmap='viridis', vmin=-2, vmax=2) # Adjust vmin/vmax for Z-score visibility\n",
    "\n",
    "        ax1.set_yticks(range(n_animals))\n",
    "        ax1.set_yticklabels(animal_ids_list)\n",
    "        ax1.set_ylabel(\"Animal ID\")\n",
    "        ax1.set_title(\"Mean Response per Animal (Heatmap)\")\n",
    "        ax1.axvline(0, color='w', linestyle='--', alpha=0.7)\n",
    "        plt.colorbar(im, ax=ax1, label=\"Z-score\")\n",
    "\n",
    "        # --- Subplot 2: Grand Average Trace ---\n",
    "        # Plot individual animal traces (faint lines)\n",
    "        for i in range(n_animals):\n",
    "            ax2.plot(common_tvec, grand_matrix[i, :], color='gray', alpha=0.3, lw=1)\n",
    "\n",
    "        # Plot Grand Mean + SEM\n",
    "        ax2.plot(common_tvec, grand_mean, color='k', lw=2, label=f\"Grand Mean (n={n_animals})\")\n",
    "        ax2.fill_between(common_tvec, grand_mean - grand_sem, grand_mean + grand_sem,\n",
    "                        color='k', alpha=0.2, label=\"SEM\")\n",
    "\n",
    "        ax2.axvline(0, color='r', linestyle='--', alpha=0.7, label=\"2nd Lick Onset\")\n",
    "        ax2.set_xlabel(\"Time from Lick Onset (s)\")\n",
    "        ax2.set_ylabel(\"Z-score\")\n",
    "        ax2.set_title(\"Average PSTH Across Animals\")\n",
    "        ax2.set_xlim(common_tvec[0], common_tvec[-1])\n",
    "        ax2.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No valid data to average.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d08e4b49f285d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
